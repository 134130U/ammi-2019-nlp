{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "### Goal: compute a probabilty distribution over all possible sentences:\n",
    "\n",
    "\n",
    "### $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
    "\n",
    "### This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
    "\n",
    "### $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
    "\n",
    "### If we have K sentences, where the j-th sentence has T_j words for all j frmo 1 to K, then we want to max:\n",
    "\n",
    "### $$log p(W) = \\sum_{j = 1}^K \\sum_{i=1}^{T_j} log p(w_i | w_{<i})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model\n",
    "\n",
    "### Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
    "\n",
    "### Given a sequence of words $w$, we want to compute\n",
    "\n",
    "###  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
    "\n",
    "### Where $w_i$ is the i-th word of the sequence.\n",
    "\n",
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
    "\n",
    "### Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities\n",
    "\n",
    "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('utils/')\n",
    "from utils import ngram_utils as ngram_utils\n",
    "import utils.global_variables as gl\n",
    "import torch\n",
    "import random\n",
    "from utils.ngram_utils import NgramLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H20pktPiA63a",
    "outputId": "fb38d897-e889-4451-df77-9ca98eb266a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd7d0b902b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from .txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/small_train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/small_valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_data), len(train_data), \\\n",
    "# type(train_data[0]), len(train_data[0]), \\\n",
    "# type(train_data[0][0]), len(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " 't')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f391cc2294c4ac786b45628f1ab48c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06b093d0c7d4c359ebe9513c911b5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
    "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10832,\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'tutu',\n",
       "  'and',\n",
       "  'at',\n",
       "  'a',\n",
       "  'really',\n",
       "  'great',\n",
       "  'price',\n",
       "  '.'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Number of All Tokens\n",
    "# len(all_tokens_train), all_tokens_train[0], \\\n",
    "len(train_data_tokenized), train_data_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_lm = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing=None)\n",
    "valid_ngram_lm = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.9, 165996)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_lm.n, train_ngram_lm.frac_vocab, train_ngram_lm.num_all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['thbis', 'mistake', 'ipods'],\n",
       " ['got',\n",
       "  'this',\n",
       "  'as',\n",
       "  'a',\n",
       "  'gift',\n",
       "  'for',\n",
       "  'my',\n",
       "  'husband',\n",
       "  'and',\n",
       "  'we',\n",
       "  'both',\n",
       "  'love',\n",
       "  'them',\n",
       "  '.'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocabulary[:3], valid_ngram_lm.raw_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'), ('<sos>', '<sos>', 'i'), ('<sos>', '<sos>', 'the')),\n",
       " (1370, 357, 148))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_ngram[:3], valid_ngram_lm.count_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.',), ('the',), ('i',)), (1470, 1026, 815))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_unigram[:3], valid_ngram_lm.count_unigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'), ('<sos>', 'i'), ('<sos>', 'the')), (1370, 357, 148))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_bigram[:3], valid_ngram_lm.count_bigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'), ('<sos>', 'i'), ('<sos>', 'the')), (1370, 357, 148))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_prev_ngram[:3], valid_ngram_lm.count_prev_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<unk>',\n",
       " '<sos>',\n",
       " '<eos>',\n",
       " ('.', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'i'),\n",
       " ('<sos>', '<sos>', 'the'),\n",
       " ('!', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'it'),\n",
       " ('<sos>', '<sos>', 'this')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.id2token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id[('.', '<eos>', '<eos>')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 7710 words\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
    "vocabulary = train_ngram_lm.vocabulary\n",
    "print('Word vocabulary size: {} words'.format(len(vocabulary)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS ANALYSIS (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tokens in the Corpus Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Tokens  165996\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All Tokens \", train_ngram_lm.num_all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All UNIQUE Tokens  7710\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All UNIQUE Tokens \", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences in the Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences  10832\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Sentences \", len(train_ngram_lm.raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = train_ngram_lm.padded_data\n",
    "train_ngram = train_ngram_lm.ngram_data\n",
    "vocab_ngram = train_ngram_lm.vocab_ngram\n",
    "count_ngram = train_ngram_lm.count_ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '<sos>',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tutu',\n",
       " 'and',\n",
       " 'at',\n",
       " 'a',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " '.',\n",
       " '<eos>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for finding all N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<sos>', '<sos>', 'this'),\n",
       " ('<sos>', 'this', 'is'),\n",
       " ('this', 'is', 'a'),\n",
       " ('is', 'a', 'great'),\n",
       " ('a', 'great', 'tutu'),\n",
       " ('great', 'tutu', 'and'),\n",
       " ('tutu', 'and', 'at'),\n",
       " ('and', 'at', 'a'),\n",
       " ('at', 'a', 'really'),\n",
       " ('a', 'really', 'great'),\n",
       " ('really', 'great', 'price'),\n",
       " ('great', 'price', '.'),\n",
       " ('price', '.', '<eos>'),\n",
       " ('.', '<eos>', '<eos>')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.', '<eos>', '<eos>')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9630"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_ngram = train_ngram_lm.trie_ngram\n",
    "# trie_ngram\n",
    "# trie_prev_ngram = train_ngram_lm.trie_prev_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9630"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_ngram['./<eos>/<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trie_ngram  # (ngram, number_of_times_ngram_appears_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_ngram = train_ngram_lm.id2token\n",
    "token2id_ngram = train_ngram_lm.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 91753 ; token ('an', 'older', 'coat')\n",
      "Token ('an', 'older', 'coat'); token id 91753\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
    "random_token = id2token_ngram[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Count & Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the words for which the pd is nonzero !!! -- more intuitive than a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', '<sos>', 'the'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'they'),\n",
       "  ('<sos>', '<sos>', 'it'),\n",
       "  ('.', '.', '.'),\n",
       "  ('<sos>', '<sos>', 'this'),\n",
       "  ('.', '.', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'these')),\n",
       " (9630, 2692, 893, 840, 635, 543, 501, 411, 385, 374))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[:10], count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.25, 0.25, 0.25, 0.0, 1.0)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('an', 'older', 'coat'))\n",
    "p = train_ngram_lm.get_ngram_prob(('an', 'older', 'coat'))\n",
    "\n",
    "p1 = train_ngram_lm.get_ngram_prob(('an', 'older', 'pc'))\n",
    "p2 = train_ngram_lm.get_ngram_prob(('an', 'older', 'lady'))\n",
    "p3 = train_ngram_lm.get_ngram_prob(('an', 'older', 'watch'))\n",
    "\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('an', 'older'))\n",
    "\n",
    "c, p, p1, p2, p3, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.14285714285714285, 1.0000000000000002)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great', 'price'))\n",
    "p = train_ngram_lm.get_ngram_prob(('really', 'great', 'price'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('really', 'great'))\n",
    "\n",
    "c, p, sum(pd)#, pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9630, 1.0, 1.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<eos>', '<eos>'))\n",
    "p = train_ngram_lm.get_ngram_prob(('.', '<eos>', '<eos>'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('.', '<eos>'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<sos>', '<sos>'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 1.0)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "p = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0.0703125, 1.0)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'this'))\n",
    "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'this'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 0.09885931558935361, 1.0000000000000007)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('is', 'a', 'great'))\n",
    "p = train_ngram_lm.get_ngram_prob(('is', 'a', 'great'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('is', 'a'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1.0, 0)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('send', 'it', 'back'))\n",
    "p = train_ngram_lm.get_ngram_prob(('send', 'it', 'back'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('send', 'it', 'back'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'these', 'pictures'))\n",
    "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'these', 'pictures'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like', 'these'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{1 + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014402995823131211"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<sos>', '<sos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001414227124876255"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'pandas'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001414227124876255"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'this'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00028776978417266187"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('really', 'great', 'price'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00043196544276457883"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('send', 'it', 'back'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5811259277137513"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<eos>', '<eos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{\\delta + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\delta\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014402995823131211"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<sos>', '<sos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013890818169190166"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'pandas'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026392554521461314"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'this'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00043122035360068997"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('really', 'great', 'price'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007197351374694113"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('send', 'it', 'back'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7350685036064573"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9327605745667988"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6065295017854105"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arge delta --> closer to add-one smoothing (0.58)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.9)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation Smoothing (Jelinek-Mercer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\alpha_n P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) + (1 - \\alpha_n) P(w|w_{i−n+2}, ..., w_{i−2}, w_{i−1})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<sos>', '<sos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'pandas'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05625"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'this'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11428571428571428"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('really', 'great', 'price'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('send', 'it', 'back'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation with Absolute Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
    "\n",
    "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
    "\n",
    "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
    "\n",
    "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
    "\n",
    "\n",
    "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
    "\n",
    "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
    "\n",
    "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
    "\n",
    "### V is the number of words in the vocabulary\n",
    "\n",
    "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to check that probabilities sum up to one:\n",
    "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567.685815486679"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = \"m\"\n",
    "x = \"'\"\n",
    "\n",
    "z = train_ngram_lm.get_p_bi(y, x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<sos>', '<sos>', 'this'),\n",
       "  ('<sos>', 'this', 'is'),\n",
       "  ('this', 'is', 'a'),\n",
       "  ('is', 'a', 'great'),\n",
       "  ('a', 'great', 'tutu'),\n",
       "  ('great', 'tutu', 'and'),\n",
       "  ('tutu', 'and', 'at'),\n",
       "  ('and', 'at', 'a'),\n",
       "  ('at', 'a', 'really'),\n",
       "  ('a', 'really', 'great'),\n",
       "  ('really', 'great', 'price'),\n",
       "  ('great', 'price', '.'),\n",
       "  ('price', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'it'),\n",
       "  ('<sos>', 'it', 'doesn'),\n",
       "  ('it', 'doesn', \"'\"),\n",
       "  ('doesn', \"'\", 't'),\n",
       "  (\"'\", 't', 'look'),\n",
       "  ('t', 'look', 'cheap'),\n",
       "  ('look', 'cheap', 'at'),\n",
       "  ('cheap', 'at', 'all'),\n",
       "  ('at', 'all', '.'),\n",
       "  ('all', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', 'i', \"'\"),\n",
       "  ('i', \"'\", 'm'),\n",
       "  (\"'\", 'm', 'so'),\n",
       "  ('m', 'so', 'glad'),\n",
       "  ('so', 'glad', 'i'),\n",
       "  ('glad', 'i', 'looked'),\n",
       "  ('i', 'looked', 'on'),\n",
       "  ('looked', 'on', 'amazon'),\n",
       "  ('on', 'amazon', 'and'),\n",
       "  ('amazon', 'and', 'found'),\n",
       "  ('and', 'found', 'such'),\n",
       "  ('found', 'such', 'an'),\n",
       "  ('such', 'an', 'affordable'),\n",
       "  ('an', 'affordable', 'tutu'),\n",
       "  ('affordable', 'tutu', 'that'),\n",
       "  ('tutu', 'that', 'isn'),\n",
       "  ('that', 'isn', \"'\"),\n",
       "  ('isn', \"'\", 't'),\n",
       "  (\"'\", 't', 'made'),\n",
       "  ('t', 'made', 'poorly'),\n",
       "  ('made', 'poorly', '.'),\n",
       "  ('poorly', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')]]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Smoothing (best to use in practice!) http://smithamilli.com/blog/kneser-ney/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM\n",
    "###  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood of a Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
    "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
    "\n",
    "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i can\n",
      "i can see\n",
      "i can see better\n",
      "i can see better ,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i can see better ,'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covered\n",
      "covered elastic\n",
      "covered elastic legs\n",
      "covered elastic legs and\n",
      "covered elastic legs and they\n",
      "covered elastic legs and they '\n",
      "covered elastic legs and they ' re\n",
      "covered elastic legs and they ' re wearing\n",
      "covered elastic legs and they ' re wearing body\n",
      "covered elastic legs and they ' re wearing body armor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"covered elastic legs and they ' re wearing body armor\""
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i love\n",
      "i love the\n",
      "i love the two\n",
      "i love the two outer\n",
      "i love the two outer pockets\n",
      "i love the two outer pockets .\n",
      "i love the two outer pockets . <\n",
      "i love the two outer pockets . < 65\n",
      "i love the two outer pockets . < 65 word\n",
      "i love the two outer pockets . < 65 word onlinel\n",
      "i love the two outer pockets . < 65 word onlinel camo\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop wears\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop wears mymerrell\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop wears mymerrell tissues\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop wears mymerrell tissues with\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop wears mymerrell tissues with lbs\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop wears mymerrell tissues with lbs hands\n",
      "i love the two outer pockets . < 65 word onlinel camo hightop wears mymerrell tissues with lbs hands snuggly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i love the two outer pockets . < 65 word onlinel camo hightop wears mymerrell tissues with lbs hands snuggly'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoes\n",
      "shoes .\n",
      "shoes . <\n",
      "shoes . < antenna\n",
      "shoes . < antenna teva\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shoes . < antenna teva'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currency\n",
      "currency compartment\n",
      "currency compartment there\n",
      "currency compartment there are\n",
      "currency compartment there are only\n",
      "currency compartment there are only two\n",
      "currency compartment there are only two factors\n",
      "currency compartment there are only two factors which\n",
      "currency compartment there are only two factors which keep\n",
      "currency compartment there are only two factors which keep the\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'currency compartment there are only two factors which keep the'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picture\n",
      "picture and\n",
      "picture and very\n",
      "picture and very handy\n",
      "picture and very handy for\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'picture and very handy for'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more\n",
      "more modules\n",
      "more modules is\n",
      "more modules is really\n",
      "more modules is really too\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'more modules is really too'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'will', 'buy'))\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n",
      "like the\n",
      "like the way\n",
      "like the way i\n",
      "like the way i could\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'like the way i could'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have\n",
      "have short\n",
      "have short hair\n",
      "have short hair and\n",
      "have short hair and i\n",
      "have short hair and i have\n",
      "have short hair and i have to\n",
      "have short hair and i have to start\n",
      "have short hair and i have to start my\n",
      "have short hair and i have to start my shopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'have short hair and i have to start my shopping'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "' ve\n",
      "' ve ever\n",
      "' ve ever owned\n",
      "' ve ever owned .\n",
      "' ve ever owned . <\n",
      "' ve ever owned . < ecco\n",
      "' ve ever owned . < ecco sunglasses\n",
      "' ve ever owned . < ecco sunglasses spec\n",
      "' ve ever owned . < ecco sunglasses spec hiking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"' ve ever owned . < ecco sunglasses spec hiking\""
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('this', 'is', 'the', 'best', 'i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "' ve\n",
      "' ve found\n",
      "' ve found the\n",
      "' ve found the band\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"' ve found the band\""
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('this', 'is', 'the', 'best', 'i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don\n",
      "don '\n",
      "don ' t\n",
      "don ' t just\n",
      "don ' t just purchase\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"don ' t just purchase\""
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('this', 'is', 'not', 'what', 'i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Likelihood (n-gram)\n",
    "## $$LL = \\sum_{j=1}^{K} \\sum_{i=1}^{T_j + 1} log p_{bi}(w_{j, i} | w_{j, n - i + 1}, \\cdot, w_{j, i - 2}, w_{j, i - 1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "## $$PP = exp(-\\frac{LL}{\\sum_j(T_j + 1)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_train = train_ngram_lm.get_perplexity(train_data_tokenized)\n",
    "ppl_valid = train_ngram_lm.get_perplexity(valid_data_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.003496405825398e+17, 725.1099435816803)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_valid, ppl_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Compare Different Smoothing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.003496405825398e+17, 725.1099435816803)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No Smoothing\n",
    "train_ngram_lm_no_smoothing = NgramLM(train_data_tokenized, all_tokens_train, n=3)\n",
    "valid_ngram_lm_no_smoothing = NgramLM(valid_data_tokenized, all_tokens_valid, n=3)\n",
    "\n",
    "ppl_train_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_smoothing, ppl_train_no_smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2245.2347120600725, 1078.232279802221)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='additive', delta=0.5)\n",
    "valid_ngram_lm_additive = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='additive', delta=0.5)\n",
    "\n",
    "ppl_train_no_additive = train_ngram_lm_additive.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_additive = train_ngram_lm_additive.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_additive, ppl_train_no_additive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1708.6807985656146, 556.8908309552986)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d2 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='additive', delta=0.2)\n",
    "valid_ngram_lm_additive_d2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='additive', delta=0.2)\n",
    "\n",
    "ppl_train_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_additive_d2, ppl_train_no_additive_d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2587.7558131859264, 1468.8550211850015)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d8 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='additive', delta=0.8)\n",
    "valid_ngram_lm_additive_d8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='additive', delta=0.8)\n",
    "\n",
    "ppl_train_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_additive_d8, ppl_train_no_additive_d8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2767.1331172664704, 1685.1666310399155)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_add1 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='add-one')\n",
    "valid_ngram_lm_add1 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='add-one')\n",
    "\n",
    "ppl_train_no_add1 = train_ngram_lm_add1.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_add1 = train_ngram_lm_add1.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_add1, ppl_train_no_add1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.120249201591078e+17, 3260.7947470396057)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a2 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation', alpha=0.2)\n",
    "valid_ngram_lm_interp_a2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation', alpha=0.2)\n",
    "\n",
    "ppl_train_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp_a2, ppl_train_no_interp_a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0194841118222176e+17, 893.1597201353827)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a8 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation', alpha=0.8)\n",
    "valid_ngram_lm_interp_a8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation', alpha=0.8)\n",
    "\n",
    "ppl_train_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp_a8, ppl_train_no_interp_a8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.053367926970881e+17, 1385.4824458368155)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a5 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation', alpha=0.5)\n",
    "valid_ngram_lm_interp_a5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation', alpha=0.5)\n",
    "\n",
    "ppl_train_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp_a5, ppl_train_no_interp_a5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discounted Interpolation Smoothing\n",
    "# train_ngram_lm_discount = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='discounting')\n",
    "# valid_ngram_lm_discount = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='discounting')\n",
    "\n",
    "# ppl_train_no_discount = train_ngram_lm_discount.get_perplexity(train_data_tokenized)\n",
    "# ppl_valid_no_discount = train_ngram_lm_discount.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "# ppl_valid_no_discount, ppl_train_no_discount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary n from ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5296236594505036e+16, 4396.493002816503)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 2\n",
    "train_ngram_lm_interp2 = NgramLM(train_data_tokenized, all_tokens_train, n=2, smoothing='interpolation')\n",
    "valid_ngram_lm_interp2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=2, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp2 = train_ngram_lm_interp2.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp2 = train_ngram_lm_interp2.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp2, ppl_train_no_interp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0194841118222176e+17, 893.1597201353827)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 3\n",
    "train_ngram_lm_interp3 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation')\n",
    "valid_ngram_lm_interp3 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp3 = train_ngram_lm_interp3.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp3 = train_ngram_lm_interp3.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp3, ppl_train_no_interp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1201894610153348e+18, 227.42393815798513)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 5\n",
    "train_ngram_lm_interp5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='interpolation')\n",
    "valid_ngram_lm_interp5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp5 = train_ngram_lm_interp5.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp5 = train_ngram_lm_interp5.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp5, ppl_train_no_interp5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1524271783534917e+18, 196.61911426440474)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 10\n",
    "train_ngram_lm_interp10 = NgramLM(train_data_tokenized, all_tokens_train, n=10, smoothing='interpolation')\n",
    "valid_ngram_lm_interp10 = NgramLM(valid_data_tokenized, all_tokens_valid, n=10, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp10 = train_ngram_lm_interp10.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp10 = train_ngram_lm_interp10.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp10, ppl_train_no_interp10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1552387706052442e+18, 208.770758577245)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 20\n",
    "train_ngram_lm_interp20 = NgramLM(train_data_tokenized, all_tokens_train, n=20, smoothing='interpolation')\n",
    "valid_ngram_lm_interp20 = NgramLM(valid_data_tokenized, all_tokens_valid, n=20, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp20 = train_ngram_lm_interp20.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp20 = train_ngram_lm_interp20.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp20, ppl_train_no_interp20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: do the above dor additive with delta 0.1 or smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7537.898310997279, 1041.5790008573922)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 5\n",
    "train_ngram_lm_add5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='additive', delta=0.1)\n",
    "valid_ngram_lm_add5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='additive', delta=0.1)\n",
    "\n",
    "ppl_train_no_add5 = train_ngram_lm_add5.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_add5 = train_ngram_lm_add5.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_add5, ppl_train_no_add5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp3.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp5.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp10.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4486052229717558e-18"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.735148080988107e-24"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_add5.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definitely\n",
      "definitely not\n",
      "definitely not for\n",
      "definitely not for the\n",
      "definitely not for the airports\n",
      "definitely not for the airports .\n",
      "definitely not for the airports . <\n",
      "definitely not for the airports . < minutes\n",
      "definitely not for the airports . < minutes vintage\n",
      "definitely not for the airports . < minutes vintage polka\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'definitely not for the airports . < minutes vintage polka'"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp5.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but\n",
      "but for\n",
      "but for the\n",
      "but for the rib\n",
      "but for the rib cage\n",
      "but for the rib cage ,\n",
      "but for the rib cage , but\n",
      "but for the rib cage , but the\n",
      "but for the rib cage , but the price\n",
      "but for the rib cage , but the price .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'but for the rib cage , but the price .'"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp3.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i have\n",
      "i have wanted\n",
      "i have wanted to\n",
      "i have wanted to own\n",
      "i have wanted to own one\n",
      "i have wanted to own one so\n",
      "i have wanted to own one so i\n",
      "i have wanted to own one so i bought\n",
      "i have wanted to own one so i bought this\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i have wanted to own one so i bought this'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_additive.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out\n",
      "out of\n",
      "out of the\n",
      "out of the box\n",
      "out of the box ,\n",
      "out of the box , there\n",
      "out of the box , there '\n",
      "out of the box , there ' s\n",
      "out of the box , there ' s no\n",
      "out of the box , there ' s no break\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"out of the box , there ' s no break\""
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i have\n",
      "i have wide\n",
      "i have wide ,\n",
      "i have wide , please\n",
      "i have wide , please even\n",
      "i have wide , please even the\n",
      "i have wide , please even the places\n",
      "i have wide , please even the places to\n",
      "i have wide , please even the places to have\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i have wide , please even the places to have'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp2.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "fit well\n",
      "fit well .\n",
      "fit well . <\n",
      "fit well . < 00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fit well . < 00'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "the band\n",
      "the band fits\n",
      "the band fits perfect\n",
      "the band fits perfect but\n",
      "the band fits perfect but the\n",
      "the band fits perfect but the cup\n",
      "the band fits perfect but the cup size\n",
      "the band fits perfect but the cup size seems\n",
      "the band fits perfect but the cup size seems a\n",
      "the band fits perfect but the cup size seems a tad\n",
      "the band fits perfect but the cup size seems a tad small\n",
      "the band fits perfect but the cup size seems a tad small ,\n",
      "the band fits perfect but the cup size seems a tad small , but\n",
      "the band fits perfect but the cup size seems a tad small , but i\n",
      "the band fits perfect but the cup size seems a tad small , but i don\n",
      "the band fits perfect but the cup size seems a tad small , but i don '\n",
      "the band fits perfect but the cup size seems a tad small , but i don ' t\n",
      "the band fits perfect but the cup size seems a tad small , but i don ' t want\n",
      "the band fits perfect but the cup size seems a tad small , but i don ' t want to\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"the band fits perfect but the cup size seems a tad small , but i don ' t want to\""
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ngram-lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
