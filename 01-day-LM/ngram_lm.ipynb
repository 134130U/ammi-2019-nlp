{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "## Goal: compute a probabilty distribution over all possible sentences:\n",
    "\n",
    "\n",
    "## $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
    "\n",
    "## This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
    "\n",
    "## $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
    "\n",
    "## If we have N sentences, each of them with T words / tokens, then we want to max:\n",
    "\n",
    "## $$log p(W) = \\sum_{n = 1}^N \\sum_{i=1}^{T} log p(w_i | w_{<i})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model\n",
    "\n",
    "## Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
    "\n",
    "## Given a sequence of words $w$, we want to compute\n",
    "\n",
    "##  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
    "\n",
    "## Where $w_i$ is the i-th word of the sequence.\n",
    "\n",
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
    "\n",
    "## Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see this in Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "#: implement the neural LM with concat instead of summation -- so that you have a fixed input etc.\n",
    "# make a separate\n",
    "# create some slides with pictures maybe explaining the model visualizations -- line by line\n",
    "# get google cloud working\n",
    "# make it work on gpu\n",
    "# show them kenlm and how to use to do different stuff with it\n",
    "# use the same sentences to generation and testing etc.\n",
    "# explain perplexity\n",
    "# ngram, ff, rnn, rnn+attention\n",
    "# do sentence generation\n",
    "# do long sentences\n",
    "# compare different n-grams -- 2,3,more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: should we install as needed and import as needed or all at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run if you dont have it installed\n",
    "# !pip install more_itertools\n",
    "# !pip install spacy# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager\\\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCVSciOCAMZb"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/roberta/ParlAI', '/home/roberta/ParlAI', '/home/roberta/ParlAI', '/home/roberta/ammi-2019-nlp/01-day-LM', '/home/roberta/ammi-2019-nlp/01-day-LM', '/home/roberta/playground', '/home/roberta/general-value-function', '/home/roberta/general-value-function/baselines', '/home/roberta/general-value-function/mazebase', '/home/roberta/general-value-function/mazebase/mazebase', '/home/roberta/miniconda3/envs/ammi/lib/python37.zip', '/home/roberta/miniconda3/envs/ammi/lib/python3.7', '/home/roberta/miniconda3/envs/ammi/lib/python3.7/lib-dynload', '', '/home/roberta/miniconda3/envs/ammi/lib/python3.7/site-packages', '/home/roberta/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/extensions', '/home/roberta/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/roberta/ParlAI\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYs6AMs6AIre"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy\n",
    "import itertools\n",
    "from operator import itemgetter \n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "_tqdm = tqdm_notebook\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import re\n",
    "import more_itertools as mit  # not built-in package\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "from torchtext import vocab\n",
    "from collections import Counter\n",
    "import re\n",
    "from torchtext.data import TabularDataset \n",
    "import pandas\n",
    "import altair\n",
    "from parlai.core.torch_agent import TorchAgent, Output\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H20pktPiA63a",
    "outputId": "fb38d897-e889-4451-df77-9ca98eb266a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7dbd84f810>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create .txt files with the reviews\n",
    "\n",
    "# with open('../data/amazon_reviews_clothing_train.txt', 'w') as f:\n",
    "#     for review in train_reviews:\n",
    "#         for token in review:\n",
    "#             f.write(\"%s \" % token) \n",
    "#         f.write(\"\\n\")\n",
    "        \n",
    "# with open('../data/amazon_reviews_clothing_test.txt', 'w') as f:\n",
    "#     for review in test_reviews:\n",
    "#         for token in review:\n",
    "#             f.write(\"%s \" % token) \n",
    "#         f.write(\"\\n\")\n",
    "        \n",
    "# with open('../data/amazon_reviews_clothing_valid.txt', 'w') as f:\n",
    "#     for review in valid_reviews:\n",
    "#         for token in review:\n",
    "#             f.write(\"%s \" % token) \n",
    "#         f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from .txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "# split each review into the tokens that compose it\n",
    "# for review in reviews:\n",
    "#     train_data.append(review.split())\n",
    "    \n",
    "test_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_test.txt', 'r') as f:\n",
    "    test_data = [review for review in f.read().split('\\n') if review]\n",
    "# split each review into the tokens that compose it\n",
    "# for review in reviews:\n",
    "#     test_data.append(review.split())\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "# split each review into the tokens that compose it\n",
    "# for review in reviews:\n",
    "#     valid_data.append(review.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 222919, str, 184, str, 1)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(train_data), len(train_data), \\\n",
    "type(train_data[0]), len(train_data[0]), \\\n",
    "type(train_data[0][0]), len(train_data[0][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " 't')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')               \n",
    "punctuations = string.punctuation\n",
    "# punctuations = '\"#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~' \n",
    "TAG_RE = re.compile(r'<[^>]+>') # get rid off HTML tags from the data\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def lower_case(parsed):\n",
    "    return [token.text.lower() for token in parsed] #and (token.is_stop is False)]\n",
    "\n",
    "def remove_punc(parsed):\n",
    "    return [token.text for token in parsed if (token.text not in punctuations)]\n",
    "\n",
    "def lower_case_remove_punc(parsed):\n",
    "    return [token.text.lower() for token in parsed if (token.text not in punctuations)] #and (token.is_stop is False)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "   # tokenize each sentence -- each tokenized sentence will be an element in token_dataset\n",
    "    token_dataset = []\n",
    "    # tokenize all words -- each token will be an item in all_tokens (in the order given by the list of sentences)\n",
    "    all_tokens = []     # all the tokens -- \n",
    "\n",
    "    for sample in _tqdm(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=1)):\n",
    "#         tokens = lower_case_remove_punc(sample)\n",
    "        tokens = lower_case(sample)       # make words lower case\n",
    "#         tokens = remove_punct(tokens)     # remove punctuation\n",
    "        token_dataset.append(tokens)    \n",
    "        all_tokens += tokens\n",
    "        \n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~', '!', str, 32, str)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations, punctuations[0], \\\n",
    "type(punctuations), len(punctuations), type(punctuations[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'<[^>]+>', re.UNICODE)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAG_RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for now only work with small subset of the data -- switch to all data later\n",
    "train_data = train_data[:80]\n",
    "test_data = test_data[:10]\n",
    "valid_data = valid_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, str, str)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), type(train_data[0]), type(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f0fc13f09b4420adea03a46d49e3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bbfba88ca047b0805014be57ae8d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c8a02b696d4916954691f80aa800d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = tokenize_dataset(train_data)\n",
    "test_data_tokenized, all_tokens_test = tokenize_dataset(test_data)\n",
    "valid_data_tokenized, all_tokens_valid = tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14771,\n",
       " 'this',\n",
       " 80,\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'tutu',\n",
       "  'and',\n",
       "  'at',\n",
       "  'a',\n",
       "  'really',\n",
       "  'great',\n",
       "  'price',\n",
       "  '.',\n",
       "  'it',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'look',\n",
       "  'cheap',\n",
       "  'at',\n",
       "  'all',\n",
       "  '.',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'so',\n",
       "  'glad',\n",
       "  'i',\n",
       "  'looked',\n",
       "  'on',\n",
       "  'amazon',\n",
       "  'and',\n",
       "  'found',\n",
       "  'such',\n",
       "  'an',\n",
       "  'affordable',\n",
       "  'tutu',\n",
       "  'that',\n",
       "  'isn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'made',\n",
       "  'poorly',\n",
       "  '.',\n",
       "  'a',\n",
       "  '+',\n",
       "  '+'])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of All Tokens\n",
    "len(all_tokens_train), all_tokens_train[0], \\\n",
    "len(train_data_tokenized), train_data_tokenized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 2091 words\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
    "voc = list(set(all_tokens_train))\n",
    "print('Word vocabulary size: {} words'.format(len(voc)))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS ANALYSIS (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tokens in the Corpus Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Tokens  14771\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All Tokens \", len(all_tokens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All UNIQUE Tokens  2091\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All UNIQUE Tokens \", len(voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences in the Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences  80\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Sentences \", len(train_data_tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentences(input_list, n):\n",
    "    result_list = []\n",
    "    for l in input_list:\n",
    "        padded = [\"<bos>\" for i in range((n - 1))] + l +[\"<eos>\" for i in range((n - 1))]\n",
    "        result_list.append(padded)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sentences(train_data_tokenized, n)\n",
    "valid_padded = pad_sentences(valid_data_tokenized, n)\n",
    "test_padded = pad_sentences(test_data_tokenized, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_padded[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for finding all N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    result_list = []\n",
    "    for l in input_list:\n",
    "        result_list.append(list(zip(*[l[i:] for i in range(n)])))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ngram[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Getting N-gram counts for already tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_counts(data, n, frac_vocab=0.9):    \n",
    "    all_train_tokens = list(mit.flatten(data))\n",
    "    counted_tokens = Counter(all_train_tokens)\n",
    "    max_vocab_size = int(frac_vocab * len(counted_tokens))\n",
    "\n",
    "    vocab, count = zip(*counted_tokens.most_common(max_vocab_size))\n",
    "    \n",
    "    return vocab, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram = find_ngrams(train_padded, n)\n",
    "vocab_trigram, count_trigram = ngram_counts(train_ngram, n)\n",
    "vocab_trigram, count_trigram = ngram_counts(train_ngram, n)\n",
    "vocab_ngram, count_ngram = ngram_counts(train_ngram, n)\n",
    "# train_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_ngram[:3], count_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1 \n",
    "BOS_IDX = 2\n",
    "EOS_IDX = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Getting N-gram Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_dict(vocab):\n",
    "    PAD_IDX = 0\n",
    "    UNK_IDX = 1 \n",
    "    BOS_IDX = 2\n",
    "    EOS_IDX = 3\n",
    "    \n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(4, 4+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>', '<bos>', '<eos>'] + id2token\n",
    "\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    token2id['<bos>'] = BOS_IDX \n",
    "    token2id['<eos>'] = EOS_IDX\n",
    "\n",
    "    return id2token, token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_ngram, token2id_ngram = ngram_dict(vocab_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<pad>',\n",
       "  '<unk>',\n",
       "  '<bos>',\n",
       "  '<eos>',\n",
       "  ('.', '<eos>', '<eos>'),\n",
       "  ('it', \"'\", 's'),\n",
       "  ('.', '.', '.'),\n",
       "  ('i', \"'\", 'm'),\n",
       "  ('<bos>', '<bos>', 'i'),\n",
       "  ('don', \"'\", 't')],)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token_ngram[:10], \\\n",
    "# token2id_ngram['<unk>'], token2id_ngram['<eos>'], token2id_ngram[('rosetta', 'stone')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 10249 ; token (',', 'hello', ',')\n",
      "Token (',', 'hello', ','); token id 10249\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
    "random_token = id2token_ngram[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _text2id(doc, token2id):\n",
    "    return [token2id[t] if t in token2id else UNK_IDX for t in doc]\n",
    "\n",
    "def _id2text(vec, id2token):\n",
    "    return [id2token[i] for i in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_id(data, token2id):\n",
    "    data_id = []\n",
    "    for d in data:\n",
    "        data_id.append(_text2id(d, token2id))\n",
    "    return data_id\n",
    "\n",
    "def create_data_id_merged(data, token2id, n):\n",
    "    data_id_merged = []\n",
    "    for d in data:\n",
    "        for i in range(len(d) - n):\n",
    "            data_id_merged.append((d[i:i+n], d[i+n]))\n",
    "    return data_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "train_padded_uni = pad_sentences(train_data_tokenized, n)\n",
    "train_unigram = find_ngrams(train_padded_uni, n)\n",
    "vocab_unigram, count_unigram = ngram_counts(train_unigram, n)\n",
    "id2token_unigram, token2id_unigram = ngram_dict(vocab_unigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "data_id = create_data_id(train_unigram, token2id_unigram)\n",
    "data_id_merged = create_data_id_merged(data_id, token2id_unigram, n)\n",
    "\n",
    "train_data_id = data_id\n",
    "train_data_id_merged = data_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram = find_ngrams(valid_padded, n)\n",
    "# valid_data_id = create_data_id(valid_ngram, token2id_ngram)\n",
    "# valid_data_id_merged = create_data_id_merged(valid_data_id, token2id_ngramn, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data_id), data_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data_id_merged), data_id_merged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that combines all the aboce and goes from tokenized data to the ngram dataset\n",
    "def create_id_dataset(data, n):\n",
    "    padded_data = pad_sentences(data, n)\n",
    "    ngram_data = find_ngrams(padded_data, n)\n",
    "    \n",
    "    vocab, count = ngram_counts(ngram_data, n)    \n",
    "    id2token, token2id = ngram_dict(vocab)\n",
    "    \n",
    "    data_id = create_data_id(ngram_data, token2id)\n",
    "    data_id_merged = create_data_id_merged(data_id, token2id, n)\n",
    "    \n",
    "    return data_id, data_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_id, all_data_id_merged = create_id_dataset(train_data_tokenized, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_id[0], all_data_id_merged[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing the probability of an n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('it', \"'\", 's'),\n",
       "  ('.', '.', '.'),\n",
       "  ('i', \"'\", 'm'),\n",
       "  ('<bos>', '<bos>', 'i'),\n",
       "  ('don', \"'\", 't'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('i', \"'\", 've'),\n",
       "  ('.', 'i', \"'\"),\n",
       "  ('you', \"'\", 're')),\n",
       " (59, 40, 33, 26, 23, 23, 14, 14, 13, 13))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[:10], count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_count(ngram, vocab, count):\n",
    "    if ngram in vocab:\n",
    "        ngram_idx = vocab.index(ngram)\n",
    "        return count[ngram_idx] \n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = get_ngram_count(('.', 'i'), vocab_ngram, count_ngram)\n",
    "c\n",
    "\n",
    "# c = get_ngram_count(('baby', 'panda'), vocab_ngram, count_ngram)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = get_ngram_count(('it', \"'\", 's'), vocab_ngram, count_ngram)\n",
    "c\n",
    "\n",
    "\n",
    "# c = get_ngram_count(('baby', 'panda', 'sweet'), vocab_ngram, count_ngram)\n",
    "# c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing the probability of a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w|w_{−n}, ..., w_{−2}, w_{−1}) \\approx \\frac{c(w_{−n}, ..., w_{−2}, w_{−1}, w)}{\\sum_{w \\in V} c(w_{−n}, ..., w_{−2}, w_{−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob(ngram, vocab, count):\n",
    "    c = get_ngram_count(ngram, vocab, count)\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "#             print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    if all_counts > 0:\n",
    "        return c / all_counts\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities\n",
    "\n",
    "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.8846153846153846)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = get_ngram_prob(('rosetta', 'stone'), vocab_ngram, count_ngram)\n",
    "p, 69/(69+2+2+1+1+1+1+1)\n",
    "\n",
    "# p = get_ngram_prob(('i', 'am'), vocab_ngram, count_ngram)\n",
    "# p\n",
    "\n",
    "# p = get_ngram_prob(('it', \"'\", 's'), vocab_ngram, count_ngram)\n",
    "# p\n",
    "\n",
    "# p = get_ngram_prob(('i', \"like\", 'it'), vocab_ngram, count_ngram)\n",
    "# p, 1/(2+1+1+1+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob_add_one_smoothing(ngram, vocab, count):\n",
    "    c = get_ngram_count(ngram, vocab, count) + 1\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "            print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    all_counts += len(voc)\n",
    "    if all_counts > 0:\n",
    "        return c / all_counts\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: show examples\n",
    "p = get_ngram_prob(('am', 'rosetta', 'stone'), vocab_ngram, count_ngram)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00047824007651841227"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = get_ngram_prob_add_one_smoothing(('am', 'rosetta', 'stone'), vocab_ngram, count_ngram)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob_addditive_smoothing(ngram, vocab, count, delta=0.5):\n",
    "    c = get_ngram_count(ngram, vocab, count) + delta*1\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "#             print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    all_counts += delta*len(voc)\n",
    "    if all_counts > 0:\n",
    "        return c / all_counts\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004782400765184122"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = get_ngram_prob_addditive_smoothing(('am', 'rosetta', 'stone'), vocab_ngram, count_ngram, delta=0.1)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob_interpolation_smoothing(ngram, vocab, count, prev_vocab, prev_count, alpha=0.5):\n",
    "    c = get_ngram_count(ngram, vocab, count)\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "#             print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    if all_counts > 0:\n",
    "        prob_ngram = c / all_counts\n",
    "    else:\n",
    "        prob_ngram = 0\n",
    "    \n",
    "    prev_ngram = tuple(list(ngram[1:]))\n",
    "    prev_c = get_ngram_count(prev_ngram, prev_vocab, prev_count)\n",
    "#     print(prev_c)\n",
    "    prev_all_counts = 0\n",
    "    for prev_t in prev_vocab:\n",
    "        if prev_t[:-1] == prev_ngram[:-1]:\n",
    "#             print(prev_t, get_ngram_count(prev_t, prev_vocab, prev_count))\n",
    "            prev_all_counts += get_ngram_count(prev_t, prev_vocab, prev_count)\n",
    "    if prev_all_counts > 0:\n",
    "        prob_prev_ngram = prev_c / prev_all_counts\n",
    "    else:\n",
    "        0\n",
    "    return alpha*(prob_ngram) + (1-alpha)*prob_prev_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sentences(train_data_tokenized, 3)\n",
    "train_trigram = find_ngrams(train_padded, 3)\n",
    "vocab_trigram, count_trigram = ngram_counts(train_trigram, 3)\n",
    "\n",
    "\n",
    "train_padded = pad_sentences(train_data_tokenized, 2)\n",
    "train_bigram = find_ngrams(train_padded, 2)\n",
    "vocab_bigram, count_bigram = ngram_counts(train_bigram, 2)\n",
    "\n",
    "train_padded = pad_sentences(train_data_tokenized, 1)\n",
    "train_unigram = find_ngrams(train_padded, 1)\n",
    "vocab_unigram, count_unigram = ngram_counts(train_unigram, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing: Linear Interpolation with Absolute Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
    "\n",
    "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
    "\n",
    "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
    "\n",
    "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
    "\n",
    "\n",
    "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
    "\n",
    "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
    "\n",
    "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
    "\n",
    "### V is the number of words in the vocabulary\n",
    "\n",
    "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_count(r):\n",
    "    return np.sum([1 for i in range(len(vocab_unigram)) if count_unigram[i] == r])\n",
    "\n",
    "def get_bigram_count(r):\n",
    "    return np.sum([1 for i in range(len(vocab_bigram)) if count_bigram[i] == r])\n",
    "\n",
    "def get_biunigram_count(r, token):\n",
    "    cc = 0\n",
    "    for other_token in vocab_unigram:\n",
    "        bigram = tuple([token] + [other_token])\n",
    "        if bigram in vocab_bigram:\n",
    "            bigram_idx = vocab_bigram.index(bigram) \n",
    "            if count_bigram[bigram_idx] == r:\n",
    "                cc += 1\n",
    "                \n",
    "#     for bigram in vocab_bigram:\n",
    "#         print(token, bigram[0])\n",
    "#         if token == bigram[0]:\n",
    "#             bigram_idx = vocab_bigram.index(bigram) \n",
    "#             if count_bigram[bigram_idx] == r:\n",
    "#                 cc += 1\n",
    "    return cc\n",
    "\n",
    "def get_b_bi():\n",
    "    bbi = get_bigram_count(1) / (get_bigram_count(1) + 2 * get_bigram_count(2))\n",
    "    return bbi\n",
    "    \n",
    "def get_b_uni():\n",
    "    buni = get_unigram_count(1) / (get_unigram_count(1) + 2 * get_unigram_count(2))\n",
    "    return buni\n",
    "\n",
    "def get_p_uni(w):\n",
    "    if w in vocab_unigram:\n",
    "        w_idx = vocab_unigram.index(w)\n",
    "        N_w = count_unigram[w_idx]\n",
    "    else:\n",
    "        N_w = 0\n",
    "        \n",
    "    b_uni = get_b_uni()\n",
    "    \n",
    "    W = len(voc)\n",
    "    N_0 = get_unigram_count(0)\n",
    "    \n",
    "    \n",
    "    N = len(all_tokens_train) # TODO: double check the meaning of N \n",
    "    \n",
    "    p_uni = max((N_w - b_uni / N), 0) + b_uni * (W - N_0) / N * 1 / W\n",
    "    \n",
    "    return p_uni\n",
    "\n",
    "def get_p_bi(w, v):   # w given v\n",
    "    if tuple([v] + [w]) in vocab_bigram:\n",
    "        vw_idx = vocab_bigram.index(tuple([v] + [w]))\n",
    "        N_vw = count_bigram[vw_idx]\n",
    "    else:\n",
    "        N_vw = 0\n",
    "        \n",
    "    if tuple([v]) in vocab_unigram:\n",
    "        v_idx = vocab_unigram.index(tuple([v]))\n",
    "        N_v = count_unigram[v_idx]\n",
    "    else:\n",
    "        N_v = 0  \n",
    "        \n",
    "    b_bi = get_b_bi()\n",
    "    b_uni = get_b_uni()\n",
    "    \n",
    "    p_uni = get_p_uni(tuple([w]))\n",
    "    \n",
    "    W = len(voc)\n",
    "    N_0 = get_biunigram_count(0, v)\n",
    "    \n",
    "    \n",
    "    p_bi =  max((N_vw - b_bi) / N_v,  0) + \\\n",
    "         b_bi * (W - N_0) / N_v * p_uni\n",
    "    \n",
    "    return p_bi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1744.7693023255813"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'stone'\n",
    "y = 'rosetta'\n",
    "\n",
    "z = get_p_bi(y, x)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check that the probabilities sum up to one\n",
    "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram LM\n",
    "##  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood of a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_sentence(sentence, vocab, count):\n",
    "    padded_sentence = pad_sentences(sentence, n)  # needs a list\n",
    "#     print(padded_sentence)\n",
    "    ngram_sentence = find_ngrams(padded_sentence, n)[0] # only one element in list\n",
    "#     print(ngram_sentence)\n",
    "    prob = 1\n",
    "    for ngram in ngram_sentence:\n",
    "        prob_ngram = get_ngram_prob(ngram, vocab, count)\n",
    "#         print(ngram, prob_ngram)\n",
    "        prob *= prob_ngram\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.', 'it', 'doesn', \"'\", 't', 'look', 'cheap', 'at', 'all', '.', 'i', \"'\", 'm', 'so', 'glad', 'i', 'looked', 'on', 'amazon', 'and', 'found', 'such', 'an', 'affordable', 'tutu', 'that', 'isn', \"'\", 't', 'made', 'poorly', '.', 'a', '+', '+']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0055998183675866e-17"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [train_data_tokenized[0]]\n",
    "# sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = get_prob_sentence(sentence, vocab_ngram, count_ngram)\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
    "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
    "\n",
    "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example -- where this approach usually fails\n",
    "\n",
    "### Bigram LM: $$ p(john \\; went \\; to \\; the \\; moon) = p(john|\\cdot) p(went|john) p(to|went) p(the|to) p(moon|the)$$ \n",
    "\n",
    "### Trigram LM: $$ pp(john \\; went \\; to \\; the \\; moon = p(john|\\cdot, \\cdot) p(went|\\cdot, john) p(to|john, went) p(the|went, to) p(moon|to, the)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_distr_ngram(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=False):\n",
    "    pd = [0 for v in voc]\n",
    "    for idx, token in enumerate(voc):\n",
    "#         print(\"token: \", token)\n",
    "#         print(\"prev ngram: \", prev_tokens)\n",
    "#         print(\"both: \", tuple(list(prev_tokens) + [token]))\n",
    "#         print(\"\")\n",
    "        token_ngram = tuple(list(prev_tokens) + [token])\n",
    "        pd[idx] = get_ngram_prob(token_ngram, vocab_ngram, count_ngram)\n",
    "#         if pd[idx] > 0 and print_nonzero_probs:\n",
    "#             print(token_ngram, \" \", pd[idx])\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"'\", 'm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prob distr for the word following prev_tokens (i.e. tutu) \n",
    "# over all the words in the vocabulary \n",
    "\n",
    "# prev_tokens = train_data_tokenized[0][4] #[0]\n",
    "prev_tokens = vocab_ngram[3][1:] #[0]   # need frmo 1 on so that this is a correct prev token\n",
    "print(prev_tokens)\n",
    "pd = get_prob_distr_ngram(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=True)\n",
    "sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_pd(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=False):\n",
    "    pd = get_prob_distr_ngram(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=print_nonzero_probs)\n",
    "    idx_next_token = np.random.choice(len(voc), 1, p=pd)[0]\n",
    "    return voc[idx_next_token]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"'\", 'm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'not'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prev_tokens)\n",
    "next_token = sample_from_pd(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=True)\n",
    "next_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(num_tokens, vocab_ngram, count_ngram, voc, n):\n",
    "    sentence = []\n",
    "    prev_tokens = tuple(['<bos>'] * (n - 1))\n",
    "#     print(prev_tokens)\n",
    "    for i in range(num_tokens):\n",
    "        next_token = sample_from_pd(prev_tokens, vocab_ngram, count_ngram, voc)\n",
    "#         print(i, next_token)\n",
    "#         print(i, prev_tokens[1:])\n",
    "        prev_tokens = tuple(list(prev_tokens[1:]) + [next_token])\n",
    "#         print(i, prev_tokens)\n",
    "        sentence.append(next_token)\n",
    "        print(' '.join(sentence))\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never\n",
      "never having\n",
      "never having studied\n",
      "never having studied italian\n",
      "never having studied italian before\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'never having studied italian before'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = generate_sentence(num_tokens, vocab_ngram, count_ngram, voc, n)\n",
    "generated_sentence\n",
    "\n",
    "# TODO: make this owkr for general ngram -- double check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the sums\n",
    "# show rank for each word in a sentence\n",
    "# explain perplexity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Likelihood\n",
    "### $LL = \\sum_{k=1}^{K} \\sum_{n=1}^{N_k + 1} log p_{bi}(w_{k,n} | w_{k,n-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $PP = exp(-\\frac{LL}{\\sum_k(N_k + 1)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(test_sentences, vocab_ngram, count_ngram):\n",
    "    ll = 0\n",
    "    num_tokens = 0\n",
    "    for s in (test_sentences):\n",
    "        ll += get_prob_sentence([s], vocab_ngram, count_ngram)\n",
    "        num_tokens += len(s) + 1\n",
    "\n",
    "    ppl = np.exp(-ll/num_tokens)\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_test = get_perplexity(test_data_tokenized, vocab_ngram, count_ngram)\n",
    "ppl_valid = get_perplexity(valid_data_tokenized, vocab_ngram, count_ngram)\n",
    "ppl_train = get_perplexity(train_data_tokenized, vocab_ngram, count_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.9999999993885841)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_test, ppl_valid, ppl_train\n",
    "# TODO check whether this makes sense -- maybe it seems too good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at some examples and see if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a PyTorch Dataset out of our set of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, data_list, max_inp_length=None, use_cuda=True):\n",
    "        \"\"\"\n",
    "        data_list is a list of tuples: (x,y) where x is a list of ids and y is a label\n",
    "        \"\"\"\n",
    "        self.data = data_list\n",
    "        self.max_len = max_inp_length\n",
    "        self.data_tensors = []\n",
    "        device = torch.device(\"cuda\" if (torch.cuda.is_available() and use_cuda) else \"cpu\")\n",
    "        for (i, t) in tqdm_notebook(self.data):\n",
    "            print(i, t)\n",
    "            self.data_tensors.append((torch.LongTensor(i[:self.max_len]).to(device), \\\n",
    "                                        torch.LongTensor([t]).to(device)))\n",
    "                \n",
    "    def __getitem__(self, key):\n",
    "        (inp, tgt) = self.data_tensors[key]\n",
    "        \n",
    "        return inp, tgt, len(inp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def pad(tensor, length, dim=0, pad=0):\n",
    "    \"\"\"Pad tensor to a specific length.\n",
    "    :param tensor: vector to pad\n",
    "    :param length: new length\n",
    "    :param dim: (default 0) dimension to pad\n",
    "    :returns: padded tensor if the tensor is shorter than length\n",
    "    \"\"\"\n",
    "    if tensor.size(dim) < length:\n",
    "        return torch.cat(\n",
    "            [tensor, tensor.new(*tensor.size()[:dim],\n",
    "                                length - tensor.size(dim),\n",
    "                                *tensor.size()[dim + 1:]).fill_(pad)],\n",
    "            dim=dim)\n",
    "    else:\n",
    "        return tensor\n",
    "    \n",
    "def batchify(batch):\n",
    "    maxlen = max(batch, key = itemgetter(2))[-1]\n",
    "    batch_list = []\n",
    "    target_list = []\n",
    "    for b in batch:\n",
    "        batch_list.append(pad(b[0], maxlen, dim=0, pad=PAD_IDX))\n",
    "        target_list.append(b[1])\n",
    "    input_batch = torch.stack(batch_list, 0)\n",
    "    target_batch = torch.stack(target_list, 0)\n",
    "    \n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_id(data, token2id):\n",
    "    data_id = []\n",
    "    for d in data:\n",
    "        data_id.append(_text2id(d, token2id))\n",
    "    return data_id\n",
    "\n",
    "def create_data_id_merged(data, token2id, n):\n",
    "    data_id_merged = []\n",
    "    for d in data:\n",
    "        for i in range(len(d) - n):\n",
    "            data_id_merged.append((d[i:i+n], d[i+n]))\n",
    "    return data_id_merged\n",
    "\n",
    "n = 1\n",
    "train_padded_uni = pad_sentences(train_data_tokenized, n)\n",
    "train_unigram = find_ngrams(train_padded_uni, n)\n",
    "train_vocab_unigram, train_count_unigram = ngram_counts(train_unigram, n)\n",
    "train_id2token_unigram, train_token2id_unigram = ngram_dict(train_vocab_unigram)\n",
    "\n",
    "n = 1\n",
    "valid_padded_uni = pad_sentences(valid_data_tokenized, n)\n",
    "valid_unigram = find_ngrams(valid_padded_uni, n)\n",
    "valid_vocab_unigram, count_unigram = ngram_counts(valid_unigram, n)\n",
    "valid_id2token_unigram, valid_token2id_unigram = ngram_dict(valid_vocab_unigram)\n",
    "\n",
    "N = 10\n",
    "train_data_id = create_data_id(train_unigram, train_token2id_unigram)\n",
    "train_data_id_merged = create_data_id_merged(train_data_id, train_token2id_unigram, N)\n",
    "\n",
    "valid_data_id = create_data_id(valid_unigram, valid_token2id_unigram)\n",
    "valid_data_id_merged = create_data_id_merged(valid_data_id, valid_token2id_unigram, N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd4a815d96f46718f94ee5da3c8cee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 14, 10, 65, 184, 9, 49, 10, 70, 65] 73\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-587-026ea1f04733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmazonDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_id_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_inp_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmazonDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_id_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_inp_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-584-6d9099452832>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_list, max_inp_length, use_cuda)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             self.data_tensors.append((torch.LongTensor(i[:self.max_len]).to(device), \\\n\u001b[0m\u001b[1;32m     13\u001b[0m                                         torch.LongTensor([t]).to(device)))\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "train_dataset = AmazonDataset(train_data_id_merged, max_inp_length=None, use_cuda=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, collate_fn=batchify, shuffle=True)\n",
    "\n",
    "valid_dataset = AmazonDataset(valid_data_id_merged, max_inp_length=None, use_cuda=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, collate_fn=batchify, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([16, 14, 10, 65, 184, 9, 49, 10, 70, 65], 73),\n",
       " ([14, 10, 65, 184, 9, 49, 10, 70, 65, 73], 4),\n",
       " ([10, 65, 184, 9, 49, 10, 70, 65, 73, 4], 11),\n",
       " ([65, 184, 9, 49, 10, 70, 65, 73, 4, 11], 259),\n",
       " ([184, 9, 49, 10, 70, 65, 73, 4, 11, 259], 12),\n",
       " ([9, 49, 10, 70, 65, 73, 4, 11, 259, 12], 30),\n",
       " ([49, 10, 70, 65, 73, 4, 11, 259, 12, 30], 445),\n",
       " ([10, 70, 65, 73, 4, 11, 259, 12, 30, 445], 386),\n",
       " ([70, 65, 73, 4, 11, 259, 12, 30, 445, 386], 49),\n",
       " ([65, 73, 4, 11, 259, 12, 30, 445, 386, 49], 80),\n",
       " ([73, 4, 11, 259, 12, 30, 445, 386, 49, 80], 4),\n",
       " ([4, 11, 259, 12, 30, 445, 386, 49, 80, 4], 7),\n",
       " ([11, 259, 12, 30, 445, 386, 49, 80, 4, 7], 12),\n",
       " ([259, 12, 30, 445, 386, 49, 80, 4, 7, 12], 81),\n",
       " ([12, 30, 445, 386, 49, 80, 4, 7, 12, 81], 36),\n",
       " ([30, 445, 386, 49, 80, 4, 7, 12, 81, 36], 704),\n",
       " ([445, 386, 49, 80, 4, 7, 12, 81, 36, 704], 7),\n",
       " ([386, 49, 80, 4, 7, 12, 81, 36, 704, 7], 446),\n",
       " ([49, 80, 4, 7, 12, 81, 36, 704, 7, 446], 24),\n",
       " ([80, 4, 7, 12, 81, 36, 704, 7, 446, 24], 202),\n",
       " ([4, 7, 12, 81, 36, 704, 7, 446, 24, 202], 9),\n",
       " ([7, 12, 81, 36, 704, 7, 446, 24, 202, 9], 174),\n",
       " ([12, 81, 36, 704, 7, 446, 24, 202, 9, 174], 387),\n",
       " ([81, 36, 704, 7, 446, 24, 202, 9, 174, 387], 63),\n",
       " ([36, 704, 7, 446, 24, 202, 9, 174, 387, 63], 1009),\n",
       " ([704, 7, 446, 24, 202, 9, 174, 387, 63, 1009], 184),\n",
       " ([7, 446, 24, 202, 9, 174, 387, 63, 1009, 184], 20),\n",
       " ([446, 24, 202, 9, 174, 387, 63, 1009, 184, 20], 325),\n",
       " ([24, 202, 9, 174, 387, 63, 1009, 184, 20, 325], 12),\n",
       " ([202, 9, 174, 387, 63, 1009, 184, 20, 325, 12], 30),\n",
       " ([9, 174, 387, 63, 1009, 184, 20, 325, 12, 30], 102),\n",
       " ([174, 387, 63, 1009, 184, 20, 325, 12, 30, 102], 1010),\n",
       " ([387, 63, 1009, 184, 20, 325, 12, 30, 102, 1010], 4),\n",
       " ([63, 1009, 184, 20, 325, 12, 30, 102, 1010, 4], 10),\n",
       " ([1009, 184, 20, 325, 12, 30, 102, 1010, 4, 10], 203),\n",
       " ([184, 20, 325, 12, 30, 102, 1010, 4, 10, 203], 203),\n",
       " ([7, 153, 16, 15, 22, 108, 447, 117, 185, 15], 1011),\n",
       " ([153, 16, 15, 22, 108, 447, 117, 185, 15, 1011], 260),\n",
       " ([16, 15, 22, 108, 447, 117, 185, 15, 1011, 260], 5),\n",
       " ([15, 22, 108, 447, 117, 185, 15, 1011, 260, 5], 93),\n",
       " ([22, 108, 447, 117, 185, 15, 1011, 260, 5, 93], 388),\n",
       " ([108, 447, 117, 185, 15, 1011, 260, 5, 93, 388], 11),\n",
       " ([447, 117, 185, 15, 1011, 260, 5, 93, 388, 11], 705),\n",
       " ([117, 185, 15, 1011, 260, 5, 93, 388, 11, 705], 15),\n",
       " ([185, 15, 1011, 260, 5, 93, 388, 11, 705, 15], 6),\n",
       " ([15, 1011, 260, 5, 93, 388, 11, 705, 15, 6], 74),\n",
       " ([1011, 260, 5, 93, 388, 11, 705, 15, 6, 74], 64),\n",
       " ([260, 5, 93, 388, 11, 705, 15, 6, 74, 64], 9),\n",
       " ([5, 93, 388, 11, 705, 15, 6, 74, 64, 9], 6),\n",
       " ([93, 388, 11, 705, 15, 6, 74, 64, 9, 6], 706),\n",
       " ([388, 11, 705, 15, 6, 74, 64, 9, 6, 706], 242),\n",
       " ([11, 705, 15, 6, 74, 64, 9, 6, 706, 242], 11),\n",
       " ([705, 15, 6, 74, 64, 9, 6, 706, 242, 11], 23),\n",
       " ([15, 6, 74, 64, 9, 6, 706, 242, 11, 23], 448),\n",
       " ([6, 74, 64, 9, 6, 706, 242, 11, 23, 448], 4),\n",
       " ([74, 64, 9, 6, 706, 242, 11, 23, 448, 4], 7),\n",
       " ([64, 9, 6, 706, 242, 11, 23, 448, 4, 7], 153),\n",
       " ([9, 6, 706, 242, 11, 23, 448, 4, 7, 153], 16),\n",
       " ([6, 706, 242, 11, 23, 448, 4, 7, 153, 16], 8),\n",
       " ([706, 242, 11, 23, 448, 4, 7, 153, 16, 8], 175),\n",
       " ([242, 11, 23, 448, 4, 7, 153, 16, 8, 175], 19),\n",
       " ([11, 23, 448, 4, 7, 153, 16, 8, 175, 19], 10),\n",
       " ([23, 448, 4, 7, 153, 16, 8, 175, 19, 10], 544),\n",
       " ([448, 4, 7, 153, 16, 8, 175, 19, 10, 544], 707),\n",
       " ([4, 7, 153, 16, 8, 175, 19, 10, 544, 707], 243),\n",
       " ([7, 153, 16, 8, 175, 19, 10, 544, 707, 243], 1012),\n",
       " ([153, 16, 8, 175, 19, 10, 544, 707, 243, 1012], 1013),\n",
       " ([16, 8, 175, 19, 10, 544, 707, 243, 1012, 1013], 9),\n",
       " ([8, 175, 19, 10, 544, 707, 243, 1012, 1013, 9], 23),\n",
       " ([175, 19, 10, 544, 707, 243, 1012, 1013, 9, 23], 261),\n",
       " ([19, 10, 544, 707, 243, 1012, 1013, 9, 23, 261], 6),\n",
       " ([10, 544, 707, 243, 1012, 1013, 9, 23, 261, 6], 389),\n",
       " ([544, 707, 243, 1012, 1013, 9, 23, 261, 6, 389], 1014),\n",
       " ([707, 243, 1012, 1013, 9, 23, 261, 6, 389, 1014], 51),\n",
       " ([243, 1012, 1013, 9, 23, 261, 6, 389, 1014, 51], 65),\n",
       " ([1012, 1013, 9, 23, 261, 6, 389, 1014, 51, 65], 4),\n",
       " ([1013, 9, 23, 261, 6, 389, 1014, 51, 65, 4], 73),\n",
       " ([9, 23, 261, 6, 389, 1014, 51, 65, 4, 73], 23),\n",
       " ([23, 261, 6, 389, 1014, 51, 65, 4, 73, 23], 67),\n",
       " ([261, 6, 389, 1014, 51, 65, 4, 73, 23, 67], 71),\n",
       " ([6, 389, 1014, 51, 65, 4, 73, 23, 67, 71], 109),\n",
       " ([389, 1014, 51, 65, 4, 73, 23, 67, 71, 109], 142),\n",
       " ([1014, 51, 65, 4, 73, 23, 67, 71, 109, 142], 75),\n",
       " ([51, 65, 4, 73, 23, 67, 71, 109, 142, 75], 17),\n",
       " ([65, 4, 73, 23, 67, 71, 109, 142, 75, 17], 286),\n",
       " ([4, 73, 23, 67, 71, 109, 142, 75, 17, 286], 175),\n",
       " ([73, 23, 67, 71, 109, 142, 75, 17, 286, 175], 15),\n",
       " ([23, 67, 71, 109, 142, 75, 17, 286, 175, 15], 154),\n",
       " ([67, 71, 109, 142, 75, 17, 286, 175, 15, 154], 186),\n",
       " ([71, 109, 142, 75, 17, 286, 175, 15, 154, 186], 545),\n",
       " ([109, 142, 75, 17, 286, 175, 15, 154, 186, 545], 4),\n",
       " ([142, 75, 17, 286, 175, 15, 154, 186, 545, 4], 1015),\n",
       " ([75, 17, 286, 175, 15, 154, 186, 545, 4, 1015], 708),\n",
       " ([17, 286, 175, 15, 154, 186, 545, 4, 1015, 708], 4),\n",
       " ([57, 44, 7, 103, 4, 4, 4, 22, 709, 26], 11),\n",
       " ([44, 7, 103, 4, 4, 4, 22, 709, 26, 11], 18),\n",
       " ([7, 103, 4, 4, 4, 22, 709, 26, 11, 18], 1016),\n",
       " ([103, 4, 4, 4, 22, 709, 26, 11, 18, 1016], 5),\n",
       " ([4, 4, 4, 22, 709, 26, 11, 18, 1016, 5], 710),\n",
       " ([4, 4, 22, 709, 26, 11, 18, 1016, 5, 710], 5),\n",
       " ([4, 22, 709, 26, 11, 18, 1016, 5, 710, 5], 546),\n",
       " ([22, 709, 26, 11, 18, 1016, 5, 710, 5, 546], 9),\n",
       " ([709, 26, 11, 18, 1016, 5, 710, 5, 546, 9], 223),\n",
       " ([26, 11, 18, 1016, 5, 710, 5, 546, 9, 223], 9),\n",
       " ([11, 18, 1016, 5, 710, 5, 546, 9, 223, 9], 7),\n",
       " ([18, 1016, 5, 710, 5, 546, 9, 223, 9, 7], 96),\n",
       " ([1016, 5, 710, 5, 546, 9, 223, 9, 7, 96], 1017),\n",
       " ([5, 710, 5, 546, 9, 223, 9, 7, 96, 1017], 8),\n",
       " ([710, 5, 546, 9, 223, 9, 7, 96, 1017, 8], 155),\n",
       " ([5, 546, 9, 223, 9, 7, 96, 1017, 8, 155], 15),\n",
       " ([546, 9, 223, 9, 7, 96, 1017, 8, 155, 15], 59),\n",
       " ([9, 223, 9, 7, 96, 1017, 8, 155, 15, 59], 6),\n",
       " ([223, 9, 7, 96, 1017, 8, 155, 15, 59, 6], 1018),\n",
       " ([9, 7, 96, 1017, 8, 155, 15, 59, 6, 1018], 46),\n",
       " ([7, 96, 1017, 8, 155, 15, 59, 6, 1018, 46], 4),\n",
       " ([96, 1017, 8, 155, 15, 59, 6, 1018, 46, 4], 11),\n",
       " ([1017, 8, 155, 15, 59, 6, 1018, 46, 4, 11], 14),\n",
       " ([8, 155, 15, 59, 6, 1018, 46, 4, 11, 14], 10),\n",
       " ([155, 15, 59, 6, 1018, 46, 4, 11, 14, 10], 67),\n",
       " ([15, 59, 6, 1018, 46, 4, 11, 14, 10, 67], 71),\n",
       " ([59, 6, 1018, 46, 4, 11, 14, 10, 67, 71], 72),\n",
       " ([6, 1018, 46, 4, 11, 14, 10, 67, 71, 72], 15),\n",
       " ([1018, 46, 4, 11, 14, 10, 67, 71, 72, 15], 1019),\n",
       " ([46, 4, 11, 14, 10, 67, 71, 72, 15, 1019], 10),\n",
       " ([4, 11, 14, 10, 67, 71, 72, 15, 1019, 10], 1020),\n",
       " ([11, 14, 10, 67, 71, 72, 15, 1019, 10, 1020], 390),\n",
       " ([14, 10, 67, 71, 72, 15, 1019, 10, 1020, 390], 99),\n",
       " ([10, 67, 71, 72, 15, 1019, 10, 1020, 390, 99], 65),\n",
       " ([67, 71, 72, 15, 1019, 10, 1020, 390, 99, 65], 389),\n",
       " ([71, 72, 15, 1019, 10, 1020, 390, 99, 65, 389], 5),\n",
       " ([72, 15, 1019, 10, 1020, 390, 99, 65, 389, 5], 262),\n",
       " ([15, 1019, 10, 1020, 390, 99, 65, 389, 5, 262], 5),\n",
       " ([1019, 10, 1020, 390, 99, 65, 389, 5, 262, 5], 287),\n",
       " ([10, 1020, 390, 99, 65, 389, 5, 262, 5, 287], 65),\n",
       " ([1020, 390, 99, 65, 389, 5, 262, 5, 287, 65], 5),\n",
       " ([390, 99, 65, 389, 5, 262, 5, 287, 65, 5], 122),\n",
       " ([99, 65, 389, 5, 262, 5, 287, 65, 5, 122], 8),\n",
       " ([65, 389, 5, 262, 5, 287, 65, 5, 122, 8], 176),\n",
       " ([389, 5, 262, 5, 287, 65, 5, 122, 8, 176], 5),\n",
       " ([5, 262, 5, 287, 65, 5, 122, 8, 176, 5], 1021),\n",
       " ([262, 5, 287, 65, 5, 122, 8, 176, 5, 1021], 9),\n",
       " ([5, 287, 65, 5, 122, 8, 176, 5, 1021, 9], 82),\n",
       " ([287, 65, 5, 122, 8, 176, 5, 1021, 9, 82], 244),\n",
       " ([65, 5, 122, 8, 176, 5, 1021, 9, 82, 244], 204),\n",
       " ([5, 122, 8, 176, 5, 1021, 9, 82, 244, 204], 11),\n",
       " ([122, 8, 176, 5, 1021, 9, 82, 244, 204, 11], 4),\n",
       " ([8, 176, 5, 1021, 9, 82, 244, 204, 11, 4], 7),\n",
       " ([176, 5, 1021, 9, 82, 244, 204, 11, 4, 7], 90),\n",
       " ([5, 1021, 9, 82, 244, 204, 11, 4, 7, 90], 11),\n",
       " ([1021, 9, 82, 244, 204, 11, 4, 7, 90, 11], 14),\n",
       " ([9, 82, 244, 204, 11, 4, 7, 90, 11, 14], 10),\n",
       " ([82, 244, 204, 11, 4, 7, 90, 11, 14, 10], 65),\n",
       " ([244, 204, 11, 4, 7, 90, 11, 14, 10, 65], 155),\n",
       " ([204, 11, 4, 7, 90, 11, 14, 10, 65, 155], 15),\n",
       " ([11, 4, 7, 90, 11, 14, 10, 65, 155, 15], 1022),\n",
       " ([4, 7, 90, 11, 14, 10, 65, 155, 15, 1022], 9),\n",
       " ([7, 90, 11, 14, 10, 65, 155, 15, 1022, 9], 224),\n",
       " ([90, 11, 14, 10, 65, 155, 15, 1022, 9, 224], 109),\n",
       " ([11, 14, 10, 65, 155, 15, 1022, 9, 224, 109], 4),\n",
       " ([164, 153, 263, 264, 49, 265, 5, 9, 59, 33], 118),\n",
       " ([153, 263, 264, 49, 265, 5, 9, 59, 33, 118], 143),\n",
       " ([263, 264, 49, 265, 5, 9, 59, 33, 118, 143], 391),\n",
       " ([264, 49, 265, 5, 9, 59, 33, 118, 143, 391], 4),\n",
       " ([49, 265, 5, 9, 59, 33, 118, 143, 391, 4], 1023),\n",
       " ([265, 5, 9, 59, 33, 118, 143, 391, 4, 1023], 9),\n",
       " ([5, 9, 59, 33, 118, 143, 391, 4, 1023, 9], 1024),\n",
       " ([9, 59, 33, 118, 143, 391, 4, 1023, 9, 1024], 76),\n",
       " ([59, 33, 118, 143, 391, 4, 1023, 9, 1024, 76], 21),\n",
       " ([33, 118, 143, 391, 4, 1023, 9, 1024, 76, 21], 102),\n",
       " ([118, 143, 391, 4, 1023, 9, 1024, 76, 21, 102], 4),\n",
       " ([143, 391, 4, 1023, 9, 1024, 76, 21, 102, 4], 6),\n",
       " ([391, 4, 1023, 9, 1024, 76, 21, 102, 4, 6], 244),\n",
       " ([4, 1023, 9, 1024, 76, 21, 102, 4, 6, 244], 26),\n",
       " ([1023, 9, 1024, 76, 21, 102, 4, 6, 244, 26], 266),\n",
       " ([9, 1024, 76, 21, 102, 4, 6, 244, 26, 266], 449),\n",
       " ([1024, 76, 21, 102, 4, 6, 244, 26, 266, 449], 156),\n",
       " ([76, 21, 102, 4, 6, 244, 26, 266, 449, 156], 711),\n",
       " ([21, 102, 4, 6, 244, 26, 266, 449, 156, 711], 5),\n",
       " ([102, 4, 6, 244, 26, 266, 449, 156, 711, 5], 450),\n",
       " ([4, 6, 244, 26, 266, 449, 156, 711, 5, 450], 119),\n",
       " ([6, 244, 26, 266, 449, 156, 711, 5, 450, 119], 8),\n",
       " ([244, 26, 266, 449, 156, 711, 5, 450, 119, 8], 224),\n",
       " ([26, 266, 449, 156, 711, 5, 450, 119, 8, 224], 5),\n",
       " ([266, 449, 156, 711, 5, 450, 119, 8, 224, 5], 9),\n",
       " ([449, 156, 711, 5, 450, 119, 8, 224, 5, 9], 6),\n",
       " ([156, 711, 5, 450, 119, 8, 224, 5, 9, 6], 264),\n",
       " ([711, 5, 450, 119, 8, 224, 5, 9, 6, 264], 26),\n",
       " ([5, 450, 119, 8, 224, 5, 9, 6, 264, 26], 1025),\n",
       " ([450, 119, 8, 224, 5, 9, 6, 264, 26, 1025], 51),\n",
       " ([119, 8, 224, 5, 9, 6, 264, 26, 1025, 51], 76),\n",
       " ([8, 224, 5, 9, 6, 264, 26, 1025, 51, 76], 4),\n",
       " ([224, 5, 9, 6, 264, 26, 1025, 51, 76, 4], 267),\n",
       " ([5, 9, 6, 264, 26, 1025, 51, 76, 4, 267], 6),\n",
       " ([9, 6, 264, 26, 1025, 51, 76, 4, 267, 6], 132),\n",
       " ([6, 264, 26, 1025, 51, 76, 4, 267, 6, 132], 21),\n",
       " ([264, 26, 1025, 51, 76, 4, 267, 6, 132, 21], 447),\n",
       " ([26, 1025, 51, 76, 4, 267, 6, 132, 21, 447], 117),\n",
       " ([1025, 51, 76, 4, 267, 6, 132, 21, 447, 117], 144),\n",
       " ([51, 76, 4, 267, 6, 132, 21, 447, 117, 144], 6),\n",
       " ([76, 4, 267, 6, 132, 21, 447, 117, 144, 6], 157),\n",
       " ([4, 267, 6, 132, 21, 447, 117, 144, 6, 157], 21),\n",
       " ([267, 6, 132, 21, 447, 117, 144, 6, 157, 21], 447),\n",
       " ([6, 132, 21, 447, 117, 144, 6, 157, 21, 447], 117),\n",
       " ([132, 21, 447, 117, 144, 6, 157, 21, 447, 117], 76),\n",
       " ([21, 447, 117, 144, 6, 157, 21, 447, 117, 76], 4),\n",
       " ([447, 117, 144, 6, 157, 21, 447, 117, 76, 4], 1026),\n",
       " ([117, 144, 6, 157, 21, 447, 117, 76, 4, 1026], 712),\n",
       " ([144, 6, 157, 21, 447, 117, 76, 4, 1026, 712], 17),\n",
       " ([6, 157, 21, 447, 117, 76, 4, 1026, 712, 17], 288),\n",
       " ([157, 21, 447, 117, 76, 4, 1026, 712, 17, 288], 8),\n",
       " ([21, 447, 117, 76, 4, 1026, 712, 17, 288, 8], 547),\n",
       " ([447, 117, 76, 4, 1026, 712, 17, 288, 8, 547], 4),\n",
       " ([117, 76, 4, 1026, 712, 17, 288, 8, 547, 4], 58),\n",
       " ([76, 4, 1026, 712, 17, 288, 8, 547, 4, 58], 1027),\n",
       " ([4, 1026, 712, 17, 288, 8, 547, 4, 58, 1027], 14),\n",
       " ([1026, 712, 17, 288, 8, 547, 4, 58, 1027, 14], 20),\n",
       " ([712, 17, 288, 8, 547, 4, 58, 1027, 14, 20], 91),\n",
       " ([17, 288, 8, 547, 4, 58, 1027, 14, 20, 91], 6),\n",
       " ([288, 8, 547, 4, 58, 1027, 14, 20, 91, 6], 713),\n",
       " ([8, 547, 4, 58, 1027, 14, 20, 91, 6, 713], 714),\n",
       " ([547, 4, 58, 1027, 14, 20, 91, 6, 713, 714], 145),\n",
       " ([4, 58, 1027, 14, 20, 91, 6, 713, 714, 145], 6),\n",
       " ([58, 1027, 14, 20, 91, 6, 713, 714, 145, 6], 264),\n",
       " ([1027, 14, 20, 91, 6, 713, 714, 145, 6, 264], 5),\n",
       " ([14, 20, 91, 6, 713, 714, 145, 6, 264, 5], 6),\n",
       " ([20, 91, 6, 713, 714, 145, 6, 264, 5, 6], 1028),\n",
       " ([91, 6, 713, 714, 145, 6, 264, 5, 6, 1028], 715),\n",
       " ([6, 713, 714, 145, 6, 264, 5, 6, 1028, 715], 451),\n",
       " ([713, 714, 145, 6, 264, 5, 6, 1028, 715, 451], 1029),\n",
       " ([714, 145, 6, 264, 5, 6, 1028, 715, 451, 1029], 5),\n",
       " ([145, 6, 264, 5, 6, 1028, 715, 451, 1029, 5], 9),\n",
       " ([6, 264, 5, 6, 1028, 715, 451, 1029, 5, 9], 63),\n",
       " ([264, 5, 6, 1028, 715, 451, 1029, 5, 9, 63], 716),\n",
       " ([5, 6, 1028, 715, 451, 1029, 5, 9, 63, 716], 77),\n",
       " ([6, 1028, 715, 451, 1029, 5, 9, 63, 716, 77], 8),\n",
       " ([1028, 715, 451, 1029, 5, 9, 63, 716, 77, 8], 1030),\n",
       " ([715, 451, 1029, 5, 9, 63, 716, 77, 8, 1030], 21),\n",
       " ([451, 1029, 5, 9, 63, 716, 77, 8, 1030, 21], 1031),\n",
       " ([1029, 5, 9, 63, 716, 77, 8, 1030, 21, 1031], 4),\n",
       " ([5, 9, 63, 716, 77, 8, 1030, 21, 1031, 4], 25),\n",
       " ([9, 63, 716, 77, 8, 1030, 21, 1031, 4, 25], 16),\n",
       " ([63, 716, 77, 8, 1030, 21, 1031, 4, 25, 16], 14),\n",
       " ([716, 77, 8, 1030, 21, 1031, 4, 25, 16, 14], 37),\n",
       " ([77, 8, 1030, 21, 1031, 4, 25, 16, 14, 37], 1032),\n",
       " ([8, 1030, 21, 1031, 4, 25, 16, 14, 37, 1032], 4),\n",
       " ([1033, 13, 1034, 1035, 65, 94, 15, 82, 244, 4], 22),\n",
       " ([13, 1034, 1035, 65, 94, 15, 82, 244, 4, 22], 65),\n",
       " ([1034, 1035, 65, 94, 15, 82, 244, 4, 22, 65], 717),\n",
       " ([1035, 65, 94, 15, 82, 244, 4, 22, 65, 717], 709),\n",
       " ([65, 94, 15, 82, 244, 4, 22, 65, 717, 709], 204),\n",
       " ([94, 15, 82, 244, 4, 22, 65, 717, 709, 204], 286),\n",
       " ([15, 82, 244, 4, 22, 65, 717, 709, 204, 286], 184),\n",
       " ([82, 244, 4, 22, 65, 717, 709, 204, 286, 184], 12),\n",
       " ([244, 4, 22, 65, 717, 709, 204, 286, 184, 12], 34),\n",
       " ([4, 22, 65, 717, 709, 204, 286, 184, 12, 34], 4),\n",
       " ([22, 65, 717, 709, 204, 286, 184, 12, 34, 4], 60),\n",
       " ([65, 717, 709, 204, 286, 184, 12, 34, 4, 60], 155),\n",
       " ([717, 709, 204, 286, 184, 12, 34, 4, 60, 155], 55),\n",
       " ([709, 204, 286, 184, 12, 34, 4, 60, 155, 55], 62),\n",
       " ([204, 286, 184, 12, 34, 4, 60, 155, 55, 62], 16),\n",
       " ([286, 184, 12, 34, 4, 60, 155, 55, 62, 16], 1036),\n",
       " ([184, 12, 34, 4, 60, 155, 55, 62, 16, 1036], 4),\n",
       " ([12, 34, 4, 60, 155, 55, 62, 16, 1036, 4], 102),\n",
       " ([34, 4, 60, 155, 55, 62, 16, 1036, 4, 102], 76),\n",
       " ([4, 60, 155, 55, 62, 16, 1036, 4, 102, 76], 9),\n",
       " ([60, 155, 55, 62, 16, 1036, 4, 102, 76, 9], 548),\n",
       " ([155, 55, 62, 16, 1036, 4, 102, 76, 9, 548], 24),\n",
       " ([55, 62, 16, 1036, 4, 102, 76, 9, 548, 24], 6),\n",
       " ([62, 16, 1036, 4, 102, 76, 9, 548, 24, 6], 244),\n",
       " ([16, 1036, 4, 102, 76, 9, 548, 24, 6, 244], 4),\n",
       " ([1036, 4, 102, 76, 9, 548, 24, 6, 244, 4], 549),\n",
       " ([4, 102, 76, 9, 548, 24, 6, 244, 4, 549], 15),\n",
       " ([102, 76, 9, 548, 24, 6, 244, 4, 549, 15], 10),\n",
       " ([76, 9, 548, 24, 6, 244, 4, 549, 15, 10], 65),\n",
       " ([9, 548, 24, 6, 244, 4, 549, 15, 10, 65], 94),\n",
       " ([548, 24, 6, 244, 4, 549, 15, 10, 65, 94], 4),\n",
       " ([24, 6, 244, 4, 549, 15, 10, 65, 94, 4], 120),\n",
       " ([6, 244, 4, 549, 15, 10, 65, 94, 4, 120], 155),\n",
       " ([244, 4, 549, 15, 10, 65, 94, 4, 120, 155], 62),\n",
       " ([4, 549, 15, 10, 65, 94, 4, 120, 155, 62], 326),\n",
       " ([549, 15, 10, 65, 94, 4, 120, 155, 62, 326], 51),\n",
       " ([15, 10, 65, 94, 4, 120, 155, 62, 326, 51], 550),\n",
       " ([10, 65, 94, 4, 120, 155, 62, 326, 51, 550], 4),\n",
       " ([65, 94, 4, 120, 155, 62, 326, 51, 550, 4], 4),\n",
       " ([94, 4, 120, 155, 62, 326, 51, 550, 4, 4], 4),\n",
       " ([4, 120, 155, 62, 326, 51, 550, 4, 4, 4], 4),\n",
       " ([120, 155, 62, 326, 51, 550, 4, 4, 4, 4], 4),\n",
       " ([155, 62, 326, 51, 550, 4, 4, 4, 4, 4], 4),\n",
       " ([62, 326, 51, 550, 4, 4, 4, 4, 4, 4], 4),\n",
       " ([326, 51, 550, 4, 4, 4, 4, 4, 4, 4], 4),\n",
       " ([51, 550, 4, 4, 4, 4, 4, 4, 4, 4], 7),\n",
       " ([550, 4, 4, 4, 4, 4, 4, 4, 4, 7], 60),\n",
       " ([4, 4, 4, 4, 4, 4, 4, 4, 7, 60], 155),\n",
       " ([4, 4, 4, 4, 4, 4, 4, 7, 60, 155], 55),\n",
       " ([4, 4, 4, 4, 4, 4, 7, 60, 155, 55], 31),\n",
       " ([4, 4, 4, 4, 4, 7, 60, 155, 55, 31], 243),\n",
       " ([4, 4, 4, 4, 7, 60, 155, 55, 31, 243], 31),\n",
       " ([4, 4, 4, 7, 60, 155, 55, 31, 243, 31], 7),\n",
       " ([4, 4, 7, 60, 155, 55, 31, 243, 31, 7], 97),\n",
       " ([4, 7, 60, 155, 55, 31, 243, 31, 7, 97], 12),\n",
       " ([7, 60, 155, 55, 31, 243, 31, 7, 97, 12], 30),\n",
       " ([60, 155, 55, 31, 243, 31, 7, 97, 12, 30], 155),\n",
       " ([155, 55, 31, 243, 31, 7, 97, 12, 30, 155], 62),\n",
       " ([55, 31, 243, 31, 7, 97, 12, 30, 155, 62], 144),\n",
       " ([31, 243, 31, 7, 97, 12, 30, 155, 62, 144], 327),\n",
       " ([243, 31, 7, 97, 12, 30, 155, 62, 144, 327], 328),\n",
       " ([31, 7, 97, 12, 30, 155, 62, 144, 327, 328], 123),\n",
       " ([7, 97, 12, 30, 155, 62, 144, 327, 328, 123], 326),\n",
       " ([97, 12, 30, 155, 62, 144, 327, 328, 123, 326], 51),\n",
       " ([12, 30, 155, 62, 144, 327, 328, 123, 326, 51], 550),\n",
       " ([30, 155, 62, 144, 327, 328, 123, 326, 51, 550], 144),\n",
       " ([155, 62, 144, 327, 328, 123, 326, 51, 550, 144], 327),\n",
       " ([62, 144, 327, 328, 123, 326, 51, 550, 144, 327], 328),\n",
       " ([144, 327, 328, 123, 326, 51, 550, 144, 327, 328], 123),\n",
       " ([327, 328, 123, 326, 51, 550, 144, 327, 328, 123], 7),\n",
       " ([328, 123, 326, 51, 550, 144, 327, 328, 123, 7], 120),\n",
       " ([123, 326, 51, 550, 144, 327, 328, 123, 7, 120], 718),\n",
       " ([326, 51, 550, 144, 327, 328, 123, 7, 120, 718], 12),\n",
       " ([51, 550, 144, 327, 328, 123, 7, 120, 718, 12], 177),\n",
       " ([550, 144, 327, 328, 123, 7, 120, 718, 12, 177], 45),\n",
       " ([144, 327, 328, 123, 7, 120, 718, 12, 177, 45], 551),\n",
       " ([327, 328, 123, 7, 120, 718, 12, 177, 45, 551], 18),\n",
       " ([328, 123, 7, 120, 718, 12, 177, 45, 551, 18], 1037),\n",
       " ([123, 7, 120, 718, 12, 177, 45, 551, 18, 1037], 4),\n",
       " ([7, 120, 718, 12, 177, 45, 551, 18, 1037, 4], 58),\n",
       " ([120, 718, 12, 177, 45, 551, 18, 1037, 4, 58], 718),\n",
       " ([718, 12, 177, 45, 551, 18, 1037, 4, 58, 718], 12),\n",
       " ([12, 177, 45, 551, 18, 1037, 4, 58, 718, 12], 177),\n",
       " ([177, 45, 551, 18, 1037, 4, 58, 718, 12, 177], 223),\n",
       " ([45, 551, 18, 1037, 4, 58, 718, 12, 177, 223], 5),\n",
       " ([551, 18, 1037, 4, 58, 718, 12, 177, 223, 5], 6),\n",
       " ([18, 1037, 4, 58, 718, 12, 177, 223, 5, 6], 719),\n",
       " ([1037, 4, 58, 718, 12, 177, 223, 5, 6, 719], 46),\n",
       " ([4, 58, 718, 12, 177, 223, 5, 6, 719, 46], 23),\n",
       " ([58, 718, 12, 177, 223, 5, 6, 719, 46, 23], 720),\n",
       " ([718, 12, 177, 223, 5, 6, 719, 46, 23, 720], 4),\n",
       " ([12, 177, 223, 5, 6, 719, 46, 23, 720, 4], 1038),\n",
       " ([177, 223, 5, 6, 719, 46, 23, 720, 4, 1038], 14),\n",
       " ([223, 5, 6, 719, 46, 23, 720, 4, 1038, 14], 10),\n",
       " ([5, 6, 719, 46, 23, 720, 4, 1038, 14, 10], 1039),\n",
       " ([6, 719, 46, 23, 720, 4, 1038, 14, 10, 1039], 145),\n",
       " ([719, 46, 23, 720, 4, 1038, 14, 10, 1039, 145], 4),\n",
       " ([46, 23, 720, 4, 1038, 14, 10, 1039, 145, 4], 1040),\n",
       " ([23, 720, 4, 1038, 14, 10, 1039, 145, 4, 1040], 8),\n",
       " ([720, 4, 1038, 14, 10, 1039, 145, 4, 1040, 8], 205),\n",
       " ([4, 1038, 14, 10, 1039, 145, 4, 1040, 8, 205], 71),\n",
       " ([1038, 14, 10, 1039, 145, 4, 1040, 8, 205, 71], 24),\n",
       " ([14, 10, 1039, 145, 4, 1040, 8, 205, 71, 24], 268),\n",
       " ([10, 1039, 145, 4, 1040, 8, 205, 71, 24, 268], 4),\n",
       " ([1039, 145, 4, 1040, 8, 205, 71, 24, 268, 4], 4),\n",
       " ([145, 4, 1040, 8, 205, 71, 24, 268, 4, 4], 4),\n",
       " ([4, 1040, 8, 205, 71, 24, 268, 4, 4, 4], 4),\n",
       " ([1040, 8, 205, 71, 24, 268, 4, 4, 4, 4], 4),\n",
       " ([8, 205, 71, 24, 268, 4, 4, 4, 4, 4], 4),\n",
       " ([205, 71, 24, 268, 4, 4, 4, 4, 4, 4], 452),\n",
       " ([71, 24, 268, 4, 4, 4, 4, 4, 4, 452], 1041),\n",
       " ([24, 268, 4, 4, 4, 4, 4, 4, 452, 1041], 4),\n",
       " ([7, 453, 16, 705, 9, 7, 12, 81, 37, 10], 1042),\n",
       " ([453, 16, 705, 9, 7, 12, 81, 37, 10, 1042], 17),\n",
       " ([16, 705, 9, 7, 12, 81, 37, 10, 1042, 17], 11),\n",
       " ([705, 9, 7, 12, 81, 37, 10, 1042, 17, 11], 25),\n",
       " ([9, 7, 12, 81, 37, 10, 1042, 17, 11, 25], 22),\n",
       " ([7, 12, 81, 37, 10, 1042, 17, 11, 25, 22], 185),\n",
       " ([12, 81, 37, 10, 1042, 17, 11, 25, 22, 185], 14),\n",
       " ([81, 37, 10, 1042, 17, 11, 25, 22, 185, 14], 7),\n",
       " ([37, 10, 1042, 17, 11, 25, 22, 185, 14, 7], 242),\n",
       " ([10, 1042, 17, 11, 25, 22, 185, 14, 7, 242], 11),\n",
       " ([1042, 17, 11, 25, 22, 185, 14, 7, 242, 11], 52),\n",
       " ([17, 11, 25, 22, 185, 14, 7, 242, 11, 52], 48),\n",
       " ([11, 25, 22, 185, 14, 7, 242, 11, 52, 48], 1043),\n",
       " ([25, 22, 185, 14, 7, 242, 11, 52, 48, 1043], 31),\n",
       " ([22, 185, 14, 7, 242, 11, 52, 48, 1043, 31], 11),\n",
       " ([185, 14, 7, 242, 11, 52, 48, 1043, 31, 11], 287),\n",
       " ([14, 7, 242, 11, 52, 48, 1043, 31, 11, 287], 18),\n",
       " ([7, 242, 11, 52, 48, 1043, 31, 11, 287, 18], 6),\n",
       " ([242, 11, 52, 48, 1043, 31, 11, 287, 18, 6], 1044),\n",
       " ([11, 52, 48, 1043, 31, 11, 287, 18, 6, 1044], 25),\n",
       " ([52, 48, 1043, 31, 11, 287, 18, 6, 1044, 25], 11),\n",
       " ([48, 1043, 31, 11, 287, 18, 6, 1044, 25, 11], 12),\n",
       " ([1043, 31, 11, 287, 18, 6, 1044, 25, 11, 12], 34),\n",
       " ([31, 11, 287, 18, 6, 1044, 25, 11, 12, 34], 37),\n",
       " ([11, 287, 18, 6, 1044, 25, 11, 12, 34, 37], 9),\n",
       " ([287, 18, 6, 1044, 25, 11, 12, 34, 37, 9], 6),\n",
       " ([18, 6, 1044, 25, 11, 12, 34, 37, 9, 6], 46),\n",
       " ([6, 1044, 25, 11, 12, 34, 37, 9, 6, 46], 59),\n",
       " ([1044, 25, 11, 12, 34, 37, 9, 6, 46, 59], 721),\n",
       " ([25, 11, 12, 34, 37, 9, 6, 46, 59, 721], 87),\n",
       " ([11, 12, 34, 37, 9, 6, 46, 59, 721, 87], 14),\n",
       " ([12, 34, 37, 9, 6, 46, 59, 721, 87, 14], 223),\n",
       " ([34, 37, 9, 6, 46, 59, 721, 87, 14, 223], 722),\n",
       " ([37, 9, 6, 46, 59, 721, 87, 14, 223, 722], 9),\n",
       " ([9, 6, 46, 59, 721, 87, 14, 223, 722, 9], 6),\n",
       " ([6, 46, 59, 721, 87, 14, 223, 722, 9, 6], 392),\n",
       " ([46, 59, 721, 87, 14, 223, 722, 9, 6, 392], 715),\n",
       " ([59, 721, 87, 14, 223, 722, 9, 6, 392, 715], 14),\n",
       " ([721, 87, 14, 223, 722, 9, 6, 392, 715, 14], 223),\n",
       " ([87, 14, 223, 722, 9, 6, 392, 715, 14, 223], 165),\n",
       " ([14, 223, 722, 9, 6, 392, 715, 14, 223, 165], 14),\n",
       " ([223, 722, 9, 6, 392, 715, 14, 223, 165, 14], 37),\n",
       " ([722, 9, 6, 392, 715, 14, 223, 165, 14, 37], 57),\n",
       " ([9, 6, 392, 715, 14, 223, 165, 14, 37, 57], 7),\n",
       " ([6, 392, 715, 14, 223, 165, 14, 37, 57, 7], 187),\n",
       " ([392, 715, 14, 223, 165, 14, 37, 57, 7, 187], 1045),\n",
       " ([715, 14, 223, 165, 14, 37, 57, 7, 187, 1045], 8),\n",
       " ([14, 223, 165, 14, 37, 57, 7, 187, 1045, 8], 6),\n",
       " ([223, 165, 14, 37, 57, 7, 187, 1045, 8, 6], 723),\n",
       " ([165, 14, 37, 57, 7, 187, 1045, 8, 6, 723], 93),\n",
       " ([14, 37, 57, 7, 187, 1045, 8, 6, 723, 93], 724),\n",
       " ([37, 57, 7, 187, 1045, 8, 6, 723, 93, 724], 61),\n",
       " ([57, 7, 187, 1045, 8, 6, 723, 93, 724, 61], 6),\n",
       " ([7, 187, 1045, 8, 6, 723, 93, 724, 61, 6], 725),\n",
       " ([187, 1045, 8, 6, 723, 93, 724, 61, 6, 725], 93),\n",
       " ([1045, 8, 6, 723, 93, 724, 61, 6, 725, 93], 23),\n",
       " ([8, 6, 723, 93, 724, 61, 6, 725, 93, 23], 1046),\n",
       " ([6, 723, 93, 724, 61, 6, 725, 93, 23, 1046], 1047),\n",
       " ([723, 93, 724, 61, 6, 725, 93, 23, 1046, 1047], 176),\n",
       " ([93, 724, 61, 6, 725, 93, 23, 1046, 1047, 176], 19),\n",
       " ([724, 61, 6, 725, 93, 23, 1046, 1047, 176, 19], 11),\n",
       " ([61, 6, 725, 93, 23, 1046, 1047, 176, 19, 11], 206),\n",
       " ([6, 725, 93, 23, 1046, 1047, 176, 19, 11, 206], 7),\n",
       " ([725, 93, 23, 1046, 1047, 176, 19, 11, 206, 7], 118),\n",
       " ([93, 23, 1046, 1047, 176, 19, 11, 206, 7, 118], 1048),\n",
       " ([23, 1046, 1047, 176, 19, 11, 206, 7, 118, 1048], 289),\n",
       " ([1046, 1047, 176, 19, 11, 206, 7, 118, 1048, 289], 329),\n",
       " ([1047, 176, 19, 11, 206, 7, 118, 1048, 289, 329], 726),\n",
       " ([176, 19, 11, 206, 7, 118, 1048, 289, 329, 726], 17),\n",
       " ([19, 11, 206, 7, 118, 1048, 289, 329, 726, 17], 725),\n",
       " ([11, 206, 7, 118, 1048, 289, 329, 726, 17, 725], 5),\n",
       " ([206, 7, 118, 1048, 289, 329, 726, 17, 725, 5], 7),\n",
       " ([7, 118, 1048, 289, 329, 726, 17, 725, 5, 7], 81),\n",
       " ([118, 1048, 289, 329, 726, 17, 725, 5, 7, 81], 10),\n",
       " ([1048, 289, 329, 726, 17, 725, 5, 7, 81, 10], 54),\n",
       " ([289, 329, 726, 17, 725, 5, 7, 81, 10, 54], 269),\n",
       " ([329, 726, 17, 725, 5, 7, 81, 10, 54, 269], 11),\n",
       " ([726, 17, 725, 5, 7, 81, 10, 54, 269, 11], 1049),\n",
       " ([17, 725, 5, 7, 81, 10, 54, 269, 11, 1049], 93),\n",
       " ([725, 5, 7, 81, 10, 54, 269, 11, 1049, 93], 552),\n",
       " ([5, 7, 81, 10, 54, 269, 11, 1049, 93, 552], 11),\n",
       " ([7, 81, 10, 54, 269, 11, 1049, 93, 552, 11], 4),\n",
       " ([153, 16, 31, 10, 1050, 8, 6, 1051, 1052, 390], 22),\n",
       " ([16, 31, 10, 1050, 8, 6, 1051, 1052, 390, 22], 185),\n",
       " ([31, 10, 1050, 8, 6, 1051, 1052, 390, 22, 185], 77),\n",
       " ([10, 1050, 8, 6, 1051, 1052, 390, 22, 185, 77], 8),\n",
       " ([1050, 8, 6, 1051, 1052, 390, 22, 185, 77, 8], 176),\n",
       " ([8, 6, 1051, 1052, 390, 22, 185, 77, 8, 176], 4),\n",
       " ([6, 1051, 1052, 390, 22, 185, 77, 8, 176, 4], 36),\n",
       " ([1051, 1052, 390, 22, 185, 77, 8, 176, 4, 36], 393),\n",
       " ([1052, 390, 22, 185, 77, 8, 176, 4, 36, 393], 5),\n",
       " ([390, 22, 185, 77, 8, 176, 4, 36, 393, 5], 93),\n",
       " ([22, 185, 77, 8, 176, 4, 36, 393, 5, 93], 12),\n",
       " ([185, 77, 8, 176, 4, 36, 393, 5, 93, 12], 34),\n",
       " ([77, 8, 176, 4, 36, 393, 5, 93, 12, 34], 188),\n",
       " ([8, 176, 4, 36, 393, 5, 93, 12, 34, 188], 11),\n",
       " ([176, 4, 36, 393, 5, 93, 12, 34, 188, 11], 8),\n",
       " ([4, 36, 393, 5, 93, 12, 34, 188, 11, 8], 224),\n",
       " ([36, 393, 5, 93, 12, 34, 188, 11, 8, 224], 119),\n",
       " ([393, 5, 93, 12, 34, 188, 11, 8, 224, 119], 124),\n",
       " ([5, 93, 12, 34, 188, 11, 8, 224, 119, 124], 1053),\n",
       " ([93, 12, 34, 188, 11, 8, 224, 119, 124, 1053], 550),\n",
       " ([12, 34, 188, 11, 8, 224, 119, 124, 1053, 550], 25),\n",
       " ([34, 188, 11, 8, 224, 119, 124, 1053, 550, 25], 7),\n",
       " ([188, 11, 8, 224, 119, 124, 1053, 550, 25, 7], 96),\n",
       " ([11, 8, 224, 119, 124, 1053, 550, 25, 7, 96], 207),\n",
       " ([8, 224, 119, 124, 1053, 550, 25, 7, 96, 207], 164),\n",
       " ([224, 119, 124, 1053, 550, 25, 7, 96, 207, 164], 12),\n",
       " ([119, 124, 1053, 550, 25, 7, 96, 207, 164, 12], 290),\n",
       " ([124, 1053, 550, 25, 7, 96, 207, 164, 12, 290], 48),\n",
       " ([1053, 550, 25, 7, 96, 207, 164, 12, 290, 48], 125),\n",
       " ([550, 25, 7, 96, 207, 164, 12, 290, 48, 125], 8),\n",
       " ([25, 7, 96, 207, 164, 12, 290, 48, 125, 8], 88),\n",
       " ([7, 96, 207, 164, 12, 290, 48, 125, 8, 88], 11),\n",
       " ([96, 207, 164, 12, 290, 48, 125, 8, 88, 11], 15),\n",
       " ([207, 164, 12, 290, 48, 125, 8, 88, 11, 15], 10),\n",
       " ([164, 12, 290, 48, 125, 8, 88, 11, 15, 10], 1054),\n",
       " ([12, 290, 48, 125, 8, 88, 11, 15, 10, 1054], 1055),\n",
       " ([290, 48, 125, 8, 88, 11, 15, 10, 1054, 1055], 553),\n",
       " ([48, 125, 8, 88, 11, 15, 10, 1054, 1055, 553], 4),\n",
       " ([125, 8, 88, 11, 15, 10, 1054, 1055, 553, 4], 6),\n",
       " ([8, 88, 11, 15, 10, 1054, 1055, 553, 4, 6], 178),\n",
       " ([88, 11, 15, 10, 1054, 1055, 553, 4, 6, 178], 14),\n",
       " ([11, 15, 10, 1054, 1055, 553, 4, 6, 178, 14], 54),\n",
       " ([15, 10, 1054, 1055, 553, 4, 6, 178, 14, 54], 330),\n",
       " ([10, 1054, 1055, 553, 4, 6, 178, 14, 54, 330], 15),\n",
       " ([1054, 1055, 553, 4, 6, 178, 14, 54, 330, 15], 6),\n",
       " ([1055, 553, 4, 6, 178, 14, 54, 330, 15, 6], 73),\n",
       " ([553, 4, 6, 178, 14, 54, 330, 15, 6, 73], 164),\n",
       " ([4, 6, 178, 14, 54, 330, 15, 6, 73, 164], 394),\n",
       " ([6, 178, 14, 54, 330, 15, 6, 73, 164, 394], 4),\n",
       " ([178, 14, 54, 330, 15, 6, 73, 164, 394, 4], 7),\n",
       " ([14, 54, 330, 15, 6, 73, 164, 394, 4, 7], 23),\n",
       " ([54, 330, 15, 6, 73, 164, 394, 4, 7, 23], 37),\n",
       " ([330, 15, 6, 73, 164, 394, 4, 7, 23, 37], 727),\n",
       " ([15, 6, 73, 164, 394, 4, 7, 23, 37, 727], 10),\n",
       " ([6, 73, 164, 394, 4, 7, 23, 37, 727, 10], 1056),\n",
       " ([73, 164, 394, 4, 7, 23, 37, 727, 10, 1056], 331),\n",
       " ([164, 394, 4, 7, 23, 37, 727, 10, 1056, 331], 15),\n",
       " ([394, 4, 7, 23, 37, 727, 10, 1056, 331, 15], 16),\n",
       " ([4, 7, 23, 37, 727, 10, 1056, 331, 15, 16], 73),\n",
       " ([7, 23, 37, 727, 10, 1056, 331, 15, 16, 73], 9),\n",
       " ([23, 37, 727, 10, 1056, 331, 15, 16, 73, 9], 118),\n",
       " ([37, 727, 10, 1056, 331, 15, 16, 73, 9, 118], 332),\n",
       " ([727, 10, 1056, 331, 15, 16, 73, 9, 118, 332], 57),\n",
       " ([10, 1056, 331, 15, 16, 73, 9, 118, 332, 57], 7),\n",
       " ([1056, 331, 15, 16, 73, 9, 118, 332, 57, 7], 394),\n",
       " ([331, 15, 16, 73, 9, 118, 332, 57, 7, 394], 15),\n",
       " ([15, 16, 73, 9, 118, 332, 57, 7, 394, 15], 4),\n",
       " ([65, 184, 15, 10, 65, 73, 4, 11, 325, 12], 30),\n",
       " ([184, 15, 10, 65, 73, 4, 11, 325, 12, 30], 10),\n",
       " ([15, 10, 65, 73, 4, 11, 325, 12, 30, 10], 144),\n",
       " ([10, 65, 73, 4, 11, 325, 12, 30, 10, 144], 327),\n",
       " ([65, 73, 4, 11, 325, 12, 30, 10, 144, 327], 328),\n",
       " ([73, 4, 11, 325, 12, 30, 10, 144, 327, 328], 123),\n",
       " ([4, 11, 325, 12, 30, 10, 144, 327, 328, 123], 454),\n",
       " ([11, 325, 12, 30, 10, 144, 327, 328, 123, 454], 144),\n",
       " ([325, 12, 30, 10, 144, 327, 328, 123, 454, 144], 327),\n",
       " ([12, 30, 10, 144, 327, 328, 123, 454, 144, 327], 328),\n",
       " ([30, 10, 144, 327, 328, 123, 454, 144, 327, 328], 123),\n",
       " ([10, 144, 327, 328, 123, 454, 144, 327, 328, 123], 45),\n",
       " ([144, 327, 328, 123, 454, 144, 327, 328, 123, 45], 143),\n",
       " ([327, 328, 123, 454, 144, 327, 328, 123, 45, 143], 178),\n",
       " ([328, 123, 454, 144, 327, 328, 123, 45, 143, 178], 331),\n",
       " ([123, 454, 144, 327, 328, 123, 45, 143, 178, 331], 5),\n",
       " ([454, 144, 327, 328, 123, 45, 143, 178, 331, 5], 25),\n",
       " ([144, 327, 328, 123, 45, 143, 178, 331, 5, 25], 11),\n",
       " ([327, 328, 123, 45, 143, 178, 331, 5, 25, 11], 14),\n",
       " ([328, 123, 45, 143, 178, 331, 5, 25, 11, 14], 225),\n",
       " ([123, 45, 143, 178, 331, 5, 25, 11, 14, 225], 15),\n",
       " ([45, 143, 178, 331, 5, 25, 11, 14, 225, 15], 22),\n",
       " ([143, 178, 331, 5, 25, 11, 14, 225, 15, 22], 185),\n",
       " ([178, 331, 5, 25, 11, 14, 225, 15, 22, 185], 8),\n",
       " ([331, 5, 25, 11, 14, 225, 15, 22, 185, 8], 176),\n",
       " ([5, 25, 11, 14, 225, 15, 22, 185, 8, 176], 154),\n",
       " ([25, 11, 14, 225, 15, 22, 185, 8, 176, 154], 1057),\n",
       " ([11, 14, 225, 15, 22, 185, 8, 176, 154, 1057], 15),\n",
       " ([14, 225, 15, 22, 185, 8, 176, 154, 1057, 15], 124),\n",
       " ([225, 15, 22, 185, 8, 176, 154, 1057, 15, 124], 82),\n",
       " ([15, 22, 185, 8, 176, 154, 1057, 15, 124, 82], 1058),\n",
       " ([22, 185, 8, 176, 154, 1057, 15, 124, 82, 1058], 4),\n",
       " ([22, 185, 455, 16, 5, 9, 11, 19, 124, 126], 5),\n",
       " ([185, 455, 16, 5, 9, 11, 19, 124, 126, 5], 25),\n",
       " ([455, 16, 5, 9, 11, 19, 124, 126, 5, 25], 93),\n",
       " ([16, 5, 9, 11, 19, 124, 126, 5, 25, 93], 52),\n",
       " ([5, 9, 11, 19, 124, 126, 5, 25, 93, 52], 26),\n",
       " ([9, 11, 19, 124, 126, 5, 25, 93, 52, 26], 455),\n",
       " ([11, 19, 124, 126, 5, 25, 93, 52, 26, 455], 11),\n",
       " ([19, 124, 126, 5, 25, 93, 52, 26, 455, 11], 8),\n",
       " ([124, 126, 5, 25, 93, 52, 26, 455, 11, 8], 48),\n",
       " ([126, 5, 25, 93, 52, 26, 455, 11, 8, 48], 10),\n",
       " ([5, 25, 93, 52, 26, 455, 11, 8, 48, 10], 226),\n",
       " ([25, 93, 52, 26, 455, 11, 8, 48, 10, 226], 1059),\n",
       " ([93, 52, 26, 455, 11, 8, 48, 10, 226, 1059], 4),\n",
       " ([15, 57, 7, 394, 15, 133, 264, 14, 1060, 728], 28),\n",
       " ([57, 7, 394, 15, 133, 264, 14, 1060, 728, 28], 7),\n",
       " ([7, 394, 15, 133, 264, 14, 1060, 728, 28, 7], 456),\n",
       " ([394, 15, 133, 264, 14, 1060, 728, 28, 7, 456], 10),\n",
       " ([15, 133, 264, 14, 1060, 728, 28, 7, 456, 10], 223),\n",
       " ([133, 264, 14, 1060, 728, 28, 7, 456, 10, 223], 9),\n",
       " ([264, 14, 1060, 728, 28, 7, 456, 10, 223, 9], 1061),\n",
       " ([14, 1060, 728, 28, 7, 456, 10, 223, 9, 1061], 9),\n",
       " ([1060, 728, 28, 7, 456, 10, 223, 9, 1061, 9], 59),\n",
       " ([728, 28, 7, 456, 10, 223, 9, 1061, 9, 59], 33),\n",
       " ([28, 7, 456, 10, 223, 9, 1061, 9, 59, 33], 729),\n",
       " ([7, 456, 10, 223, 9, 1061, 9, 59, 33, 729], 9),\n",
       " ([456, 10, 223, 9, 1061, 9, 59, 33, 729, 9], 554),\n",
       " ([10, 223, 9, 1061, 9, 59, 33, 729, 9, 554], 28),\n",
       " ([223, 9, 1061, 9, 59, 33, 729, 9, 554, 28], 6),\n",
       " ([9, 1061, 9, 59, 33, 729, 9, 554, 28, 6], 184),\n",
       " ([1061, 9, 59, 33, 729, 9, 554, 28, 6, 184], 14),\n",
       " ([9, 59, 33, 729, 9, 554, 28, 6, 184, 14], 67),\n",
       " ([59, 33, 729, 9, 554, 28, 6, 184, 14, 67], 454),\n",
       " ([33, 729, 9, 554, 28, 6, 184, 14, 67, 454], 28),\n",
       " ([729, 9, 554, 28, 6, 184, 14, 67, 454, 28], 730),\n",
       " ([9, 554, 28, 6, 184, 14, 67, 454, 28, 730], 731),\n",
       " ([554, 28, 6, 184, 14, 67, 454, 28, 730, 731], 28),\n",
       " ([28, 6, 184, 14, 67, 454, 28, 730, 731, 28], 37),\n",
       " ([6, 184, 14, 67, 454, 28, 730, 731, 28, 37], 732),\n",
       " ([184, 14, 67, 454, 28, 730, 731, 28, 37, 732], 102),\n",
       " ([14, 67, 454, 28, 730, 731, 28, 37, 732, 102], 28),\n",
       " ([67, 454, 28, 730, 731, 28, 37, 732, 102, 28], 37),\n",
       " ([454, 28, 730, 731, 28, 37, 732, 102, 28, 37], 386),\n",
       " ([28, 730, 731, 28, 37, 732, 102, 28, 37, 386], 1062),\n",
       " ([730, 731, 28, 37, 732, 102, 28, 37, 386, 1062], 28),\n",
       " ([731, 28, 37, 732, 102, 28, 37, 386, 1062, 28], 555),\n",
       " ([28, 37, 732, 102, 28, 37, 386, 1062, 28, 555], 733),\n",
       " ([37, 732, 102, 28, 37, 386, 1062, 28, 555, 733], 102),\n",
       " ([732, 102, 28, 37, 386, 1062, 28, 555, 733, 102], 286),\n",
       " ([102, 28, 37, 386, 1062, 28, 555, 733, 102, 286], 19),\n",
       " ([28, 37, 386, 1062, 28, 555, 733, 102, 286, 19], 204),\n",
       " ([37, 386, 1062, 28, 555, 733, 102, 286, 19, 204], 9),\n",
       " ([386, 1062, 28, 555, 733, 102, 286, 19, 204, 9], 1063),\n",
       " ([1062, 28, 555, 733, 102, 286, 19, 204, 9, 1063], 28),\n",
       " ([28, 555, 733, 102, 286, 19, 204, 9, 1063, 28], 7),\n",
       " ([555, 733, 102, 286, 19, 204, 9, 1063, 28, 7], 394),\n",
       " ([733, 102, 286, 19, 204, 9, 1063, 28, 7, 394], 457),\n",
       " ([102, 286, 19, 204, 9, 1063, 28, 7, 394, 457], 78),\n",
       " ([286, 19, 204, 9, 1063, 28, 7, 394, 457, 78], 458),\n",
       " ([19, 204, 9, 1063, 28, 7, 394, 457, 78, 458], 734),\n",
       " ([204, 9, 1063, 28, 7, 394, 457, 78, 458, 734], 15),\n",
       " ([9, 1063, 28, 7, 394, 457, 78, 458, 734, 15], 10),\n",
       " ([1063, 28, 7, 394, 457, 78, 458, 734, 15, 10], 184),\n",
       " ([28, 7, 394, 457, 78, 458, 734, 15, 10, 184], 7),\n",
       " ([7, 394, 457, 78, 458, 734, 15, 10, 184, 7], 9),\n",
       " ([394, 457, 78, 458, 734, 15, 10, 184, 7, 9], 7),\n",
       " ([457, 78, 458, 734, 15, 10, 184, 7, 9, 7], 227),\n",
       " ([78, 458, 734, 15, 10, 184, 7, 9, 7, 227], 1064),\n",
       " ([458, 734, 15, 10, 184, 7, 9, 7, 227, 1064], 17),\n",
       " ([734, 15, 10, 184, 7, 9, 7, 227, 1064, 17], 22),\n",
       " ([15, 10, 184, 7, 9, 7, 227, 1064, 17, 22], 333),\n",
       " ([10, 184, 7, 9, 7, 227, 1064, 17, 22, 333], 15),\n",
       " ([184, 7, 9, 7, 227, 1064, 17, 22, 333, 15], 1065),\n",
       " ([7, 9, 7, 227, 1064, 17, 22, 333, 15, 1065], 8),\n",
       " ([9, 7, 227, 1064, 17, 22, 333, 15, 1065, 8], 6),\n",
       " ([7, 227, 1064, 17, 22, 333, 15, 1065, 8, 6], 395),\n",
       " ([227, 1064, 17, 22, 333, 15, 1065, 8, 6, 395], 17),\n",
       " ([1064, 17, 22, 333, 15, 1065, 8, 6, 395, 17], 556),\n",
       " ([17, 22, 333, 15, 1065, 8, 6, 395, 17, 556], 1066),\n",
       " ([22, 333, 15, 1065, 8, 6, 395, 17, 556, 1066], 28),\n",
       " ([333, 15, 1065, 8, 6, 395, 17, 556, 1066, 28], 179),\n",
       " ([15, 1065, 8, 6, 395, 17, 556, 1066, 28, 179], 134),\n",
       " ([1065, 8, 6, 395, 17, 556, 1066, 28, 179, 134], 21),\n",
       " ([8, 6, 395, 17, 556, 1066, 28, 179, 134, 21], 459),\n",
       " ([6, 395, 17, 556, 1066, 28, 179, 134, 21, 459], 158),\n",
       " ([395, 17, 556, 1066, 28, 179, 134, 21, 459, 158], 28),\n",
       " ([17, 556, 1066, 28, 179, 134, 21, 459, 158, 28], 22),\n",
       " ([556, 1066, 28, 179, 134, 21, 459, 158, 28, 22], 185),\n",
       " ([1066, 28, 179, 134, 21, 459, 158, 28, 22, 185], 14),\n",
       " ([28, 179, 134, 21, 459, 158, 28, 22, 185, 14], 133),\n",
       " ([179, 134, 21, 459, 158, 28, 22, 185, 14, 133], 28),\n",
       " ([134, 21, 459, 158, 28, 22, 185, 14, 133, 28], 460),\n",
       " ([21, 459, 158, 28, 22, 185, 14, 133, 28, 460], 270),\n",
       " ([459, 158, 28, 22, 185, 14, 133, 28, 460, 270], 108),\n",
       " ([158, 28, 22, 185, 14, 133, 28, 460, 270, 108], 30),\n",
       " ([28, 22, 185, 14, 133, 28, 460, 270, 108, 30], 9),\n",
       " ([22, 185, 14, 133, 28, 460, 270, 108, 30, 9], 16),\n",
       " ([185, 14, 133, 28, 460, 270, 108, 30, 9, 16], 331),\n",
       " ([14, 133, 28, 460, 270, 108, 30, 9, 16, 331], 42),\n",
       " ([133, 28, 460, 270, 108, 30, 9, 16, 331, 42], 46),\n",
       " ([28, 460, 270, 108, 30, 9, 16, 331, 42, 46], 270),\n",
       " ([460, 270, 108, 30, 9, 16, 331, 42, 46, 270], 39),\n",
       " ([270, 108, 30, 9, 16, 331, 42, 46, 270, 39], 208),\n",
       " ([108, 30, 9, 16, 331, 42, 46, 270, 39, 208], 225),\n",
       " ([30, 9, 16, 331, 42, 46, 270, 39, 208, 225], 9),\n",
       " ([9, 16, 331, 42, 46, 270, 39, 208, 225, 9], 60),\n",
       " ([16, 331, 42, 46, 270, 39, 208, 225, 9, 60], 1067),\n",
       " ([331, 42, 46, 270, 39, 208, 225, 9, 60, 1067], 48),\n",
       " ([42, 46, 270, 39, 208, 225, 9, 60, 1067, 48], 125),\n",
       " ([46, 270, 39, 208, 225, 9, 60, 1067, 48, 125], 8),\n",
       " ([270, 39, 208, 225, 9, 60, 1067, 48, 125, 8], 1068),\n",
       " ([39, 208, 225, 9, 60, 1067, 48, 125, 8, 1068], 124),\n",
       " ([208, 225, 9, 60, 1067, 48, 125, 8, 1068, 124], 228),\n",
       " ([225, 9, 60, 1067, 48, 125, 8, 1068, 124, 228], 735),\n",
       " ([9, 60, 1067, 48, 125, 8, 1068, 124, 228, 735], 392),\n",
       " ([60, 1067, 48, 125, 8, 1068, 124, 228, 735, 392], 15),\n",
       " ([1067, 48, 125, 8, 1068, 124, 228, 735, 392, 15], 75),\n",
       " ([48, 125, 8, 1068, 124, 228, 735, 392, 15, 75], 64),\n",
       " ([125, 8, 1068, 124, 228, 735, 392, 15, 75, 64], 28),\n",
       " ([1069, 22, 736, 460, 11, 396, 737, 245, 5, 1070], 14),\n",
       " ([22, 736, 460, 11, 396, 737, 245, 5, 1070, 14], 124),\n",
       " ([736, 460, 11, 396, 737, 245, 5, 1070, 14, 124], 738),\n",
       " ([460, 11, 396, 737, 245, 5, 1070, 14, 124, 738], 291),\n",
       " ([11, 396, 737, 245, 5, 1070, 14, 124, 738, 291], 229),\n",
       " ([396, 737, 245, 5, 1070, 14, 124, 738, 291, 229], 206),\n",
       " ([737, 245, 5, 1070, 14, 124, 738, 291, 229, 206], 63),\n",
       " ([245, 5, 1070, 14, 124, 738, 291, 229, 206, 63], 16),\n",
       " ([5, 1070, 14, 124, 738, 291, 229, 206, 63, 16], 548),\n",
       " ([1070, 14, 124, 738, 291, 229, 206, 63, 16, 548], 82),\n",
       " ([14, 124, 738, 291, 229, 206, 63, 16, 548, 82], 184),\n",
       " ([124, 738, 291, 229, 206, 63, 16, 548, 82, 184], 102),\n",
       " ([738, 291, 229, 206, 63, 16, 548, 82, 184, 102], 121),\n",
       " ([291, 229, 206, 63, 16, 548, 82, 184, 102, 121], 1071),\n",
       " ([229, 206, 63, 16, 548, 82, 184, 102, 121, 1071], 4),\n",
       " ([206, 63, 16, 548, 82, 184, 102, 121, 1071, 4], 11),\n",
       " ([63, 16, 548, 82, 184, 102, 121, 1071, 4, 11], 14),\n",
       " ([16, 548, 82, 184, 102, 121, 1071, 4, 11, 14], 76),\n",
       " ([548, 82, 184, 102, 121, 1071, 4, 11, 14, 76], 739),\n",
       " ([82, 184, 102, 121, 1071, 4, 11, 14, 76, 739], 9),\n",
       " ([184, 102, 121, 1071, 4, 11, 14, 76, 739, 9], 164),\n",
       " ([102, 121, 1071, 4, 11, 14, 76, 739, 9, 164], 1072),\n",
       " ([121, 1071, 4, 11, 14, 76, 739, 9, 164, 1072], 93),\n",
       " ([1071, 4, 11, 14, 76, 739, 9, 164, 1072, 93], 451),\n",
       " ([4, 11, 14, 76, 739, 9, 164, 1072, 93, 451], 557),\n",
       " ([11, 14, 76, 739, 9, 164, 1072, 93, 451, 557], 17),\n",
       " ([14, 76, 739, 9, 164, 1072, 93, 451, 557, 17], 176),\n",
       " ([76, 739, 9, 164, 1072, 93, 451, 557, 17, 176], 119),\n",
       " ([739, 9, 164, 1072, 93, 451, 557, 17, 176, 119], 17),\n",
       " ([9, 164, 1072, 93, 451, 557, 17, 176, 119, 17], 11),\n",
       " ([164, 1072, 93, 451, 557, 17, 176, 119, 17, 11], 4),\n",
       " ([22, 185, 77, 397, 16, 331, 246, 396, 245, 142], 93),\n",
       " ([185, 77, 397, 16, 331, 246, 396, 245, 142, 93], 453),\n",
       " ([77, 397, 16, 331, 246, 396, 245, 142, 93, 453], 11),\n",
       " ([397, 16, 331, 246, 396, 245, 142, 93, 453, 11], 9),\n",
       " ([16, 331, 246, 396, 245, 142, 93, 453, 11, 9], 11),\n",
       " ([331, 246, 396, 245, 142, 93, 453, 11, 9, 11], 12),\n",
       " ([246, 396, 245, 142, 93, 453, 11, 9, 11, 12], 34),\n",
       " ([396, 245, 142, 93, 453, 11, 9, 11, 12, 34], 110),\n",
       " ([245, 142, 93, 453, 11, 9, 11, 12, 34, 110], 266),\n",
       " ([142, 93, 453, 11, 9, 11, 12, 34, 110, 266], 146),\n",
       " ([93, 453, 11, 9, 11, 12, 34, 110, 266, 146], 6),\n",
       " ([453, 11, 9, 11, 12, 34, 110, 266, 146, 6], 1073),\n",
       " ([11, 9, 11, 12, 34, 110, 266, 146, 6, 1073], 334),\n",
       " ([9, 11, 12, 34, 110, 266, 146, 6, 1073, 334], 19),\n",
       " ([11, 12, 34, 110, 266, 146, 6, 1073, 334, 19], 6),\n",
       " ([12, 34, 110, 266, 146, 6, 1073, 334, 19, 6], 83),\n",
       " ([34, 110, 266, 146, 6, 1073, 334, 19, 6, 83], 740),\n",
       " ([110, 266, 146, 6, 1073, 334, 19, 6, 83, 740], 4),\n",
       " ([266, 146, 6, 1073, 334, 19, 6, 83, 740, 4], 11),\n",
       " ([146, 6, 1073, 334, 19, 6, 83, 740, 4, 11], 12),\n",
       " ([6, 1073, 334, 19, 6, 83, 740, 4, 11, 12], 34),\n",
       " ([1073, 334, 19, 6, 83, 740, 4, 11, 12, 34], 741),\n",
       " ([334, 19, 6, 83, 740, 4, 11, 12, 34, 741], 178),\n",
       " ([19, 6, 83, 740, 4, 11, 12, 34, 741, 178], 28),\n",
       " ([6, 83, 740, 4, 11, 12, 34, 741, 178, 28], 93),\n",
       " ([83, 740, 4, 11, 12, 34, 741, 178, 28, 93], 267),\n",
       " ([740, 4, 11, 12, 34, 741, 178, 28, 93, 267], 10),\n",
       " ([4, 11, 12, 34, 741, 178, 28, 93, 267, 10], 108),\n",
       " ([11, 12, 34, 741, 178, 28, 93, 267, 10, 108], 30),\n",
       " ([12, 34, 741, 178, 28, 93, 267, 10, 108, 30], 9),\n",
       " ([34, 741, 178, 28, 93, 267, 10, 108, 30, 9], 11),\n",
       " ([741, 178, 28, 93, 267, 10, 108, 30, 9, 11], 12),\n",
       " ([178, 28, 93, 267, 10, 108, 30, 9, 11, 12], 34),\n",
       " ([28, 93, 267, 10, 108, 30, 9, 11, 12, 34], 54),\n",
       " ([93, 267, 10, 108, 30, 9, 11, 12, 34, 54], 1074),\n",
       " ([267, 10, 108, 30, 9, 11, 12, 34, 54, 1074], 124),\n",
       " ([10, 108, 30, 9, 11, 12, 34, 54, 1074, 124], 1075),\n",
       " ([108, 30, 9, 11, 12, 34, 54, 1074, 124, 1075], 5),\n",
       " ([30, 9, 11, 12, 34, 54, 1074, 124, 1075, 5], 9),\n",
       " ([9, 11, 12, 34, 54, 1074, 124, 1075, 5, 9], 77),\n",
       " ([11, 12, 34, 54, 1074, 124, 1075, 5, 9, 77], 10),\n",
       " ([12, 34, 54, 1074, 124, 1075, 5, 9, 77, 10], 82),\n",
       " ([34, 54, 1074, 124, 1075, 5, 9, 77, 10, 82], 226),\n",
       " ([54, 1074, 124, 1075, 5, 9, 77, 10, 82, 226], 17),\n",
       " ([1074, 124, 1075, 5, 9, 77, 10, 82, 226, 17], 735),\n",
       " ([124, 1075, 5, 9, 77, 10, 82, 226, 17, 735], 288),\n",
       " ([1075, 5, 9, 77, 10, 82, 226, 17, 735, 288], 5),\n",
       " ([5, 9, 77, 10, 82, 226, 17, 735, 288, 5], 335),\n",
       " ([9, 77, 10, 82, 226, 17, 735, 288, 5, 335], 7),\n",
       " ([77, 10, 82, 226, 17, 735, 288, 5, 335, 7], 12),\n",
       " ([10, 82, 226, 17, 735, 288, 5, 335, 7, 12], 81),\n",
       " ([82, 226, 17, 735, 288, 5, 335, 7, 12, 81], 37),\n",
       " ([226, 17, 735, 288, 5, 335, 7, 12, 81, 37], 36),\n",
       " ([17, 735, 288, 5, 335, 7, 12, 81, 37, 36], 207),\n",
       " ([735, 288, 5, 335, 7, 12, 81, 37, 36, 207], 31),\n",
       " ([288, 5, 335, 7, 12, 81, 37, 36, 207, 31], 159),\n",
       " ([5, 335, 7, 12, 81, 37, 36, 207, 31, 159], 31),\n",
       " ([335, 7, 12, 81, 37, 36, 207, 31, 159, 31], 558),\n",
       " ([7, 12, 81, 37, 36, 207, 31, 159, 31, 558], 33),\n",
       " ([12, 81, 37, 36, 207, 31, 159, 31, 558, 33], 336),\n",
       " ([81, 37, 36, 207, 31, 159, 31, 558, 33, 336], 4),\n",
       " ([37, 36, 207, 31, 159, 31, 558, 33, 336, 4], 25),\n",
       " ([36, 207, 31, 159, 31, 558, 33, 336, 4, 25], 1076),\n",
       " ([207, 31, 159, 31, 558, 33, 336, 4, 25, 1076], 92),\n",
       " ([31, 159, 31, 558, 33, 336, 4, 25, 1076, 92], 1077),\n",
       " ([159, 31, 558, 33, 336, 4, 25, 1076, 92, 1077], 93),\n",
       " ([31, 558, 33, 336, 4, 25, 1076, 92, 1077, 93], 460),\n",
       " ([558, 33, 336, 4, 25, 1076, 92, 1077, 93, 460], 11),\n",
       " ([33, 336, 4, 25, 1076, 92, 1077, 93, 460, 11], 5),\n",
       " ([336, 4, 25, 1076, 92, 1077, 93, 460, 11, 5], 7),\n",
       " ([4, 25, 1076, 92, 1077, 93, 460, 11, 5, 7], 12),\n",
       " ([25, 1076, 92, 1077, 93, 460, 11, 5, 7, 12], 81),\n",
       " ([1076, 92, 1077, 93, 460, 11, 5, 7, 12, 81], 37),\n",
       " ([92, 1077, 93, 460, 11, 5, 7, 12, 81, 37], 742),\n",
       " ([1077, 93, 460, 11, 5, 7, 12, 81, 37, 742], 28),\n",
       " ([93, 460, 11, 5, 7, 12, 81, 37, 742, 28], 123),\n",
       " ([460, 11, 5, 7, 12, 81, 37, 742, 28, 123], 39),\n",
       " ([559, 16, 184, 15, 22, 560, 12, 34, 74, 743], 4),\n",
       " ([16, 184, 15, 22, 560, 12, 34, 74, 743, 4], 11),\n",
       " ([184, 15, 22, 560, 12, 34, 74, 743, 4, 11], 208),\n",
       " ([15, 22, 560, 12, 34, 74, 743, 4, 11, 208], 744),\n",
       " ([22, 560, 12, 34, 74, 743, 4, 11, 208, 744], 19),\n",
       " ([560, 12, 34, 74, 743, 4, 11, 208, 744, 19], 288),\n",
       " ([12, 34, 74, 743, 4, 11, 208, 744, 19, 288], 8),\n",
       " ([34, 74, 743, 4, 11, 208, 744, 19, 288, 8], 547),\n",
       " ([74, 743, 4, 11, 208, 744, 19, 288, 8, 547], 18),\n",
       " ([743, 4, 11, 208, 744, 19, 288, 8, 547, 18], 4),\n",
       " ([4, 11, 208, 744, 19, 288, 8, 547, 18, 4], 7),\n",
       " ([11, 208, 744, 19, 288, 8, 547, 18, 4, 7], 12),\n",
       " ([208, 744, 19, 288, 8, 547, 18, 4, 7, 12], 81),\n",
       " ([744, 19, 288, 8, 547, 18, 4, 7, 12, 81], 67),\n",
       " ([19, 288, 8, 547, 18, 4, 7, 12, 81, 67], 561),\n",
       " ([288, 8, 547, 18, 4, 7, 12, 81, 67, 561], 19),\n",
       " ([8, 547, 18, 4, 7, 12, 81, 67, 561, 19], 11),\n",
       " ([547, 18, 4, 7, 12, 81, 67, 561, 19, 11], 9),\n",
       " ([18, 4, 7, 12, 81, 67, 561, 19, 11, 9], 60),\n",
       " ([4, 7, 12, 81, 67, 561, 19, 11, 9, 60], 268),\n",
       " ([7, 12, 81, 67, 561, 19, 11, 9, 60, 268], 55),\n",
       " ([12, 81, 67, 561, 19, 11, 9, 60, 268, 55], 18),\n",
       " ([81, 67, 561, 19, 11, 9, 60, 268, 55, 18], 1078),\n",
       " ([67, 561, 19, 11, 9, 60, 268, 55, 18, 1078], 389),\n",
       " ([561, 19, 11, 9, 60, 268, 55, 18, 1078, 389], 18),\n",
       " ([19, 11, 9, 60, 268, 55, 18, 1078, 389, 18], 6),\n",
       " ([11, 9, 60, 268, 55, 18, 1078, 389, 18, 6], 1079),\n",
       " ([9, 60, 268, 55, 18, 1078, 389, 18, 6, 1079], 4),\n",
       " ([454, 9, 76, 1080, 4, 16, 184, 14, 10, 554], 719),\n",
       " ([9, 76, 1080, 4, 16, 184, 14, 10, 554, 719], 291),\n",
       " ([76, 1080, 4, 16, 184, 14, 10, 554, 719, 291], 20),\n",
       " ([1080, 4, 16, 184, 14, 10, 554, 719, 291, 20], 287),\n",
       " ([4, 16, 184, 14, 10, 554, 719, 291, 20, 287], 54),\n",
       " ([16, 184, 14, 10, 554, 719, 291, 20, 287, 54], 53),\n",
       " ([184, 14, 10, 554, 719, 291, 20, 287, 54, 53], 6),\n",
       " ([14, 10, 554, 719, 291, 20, 287, 54, 53, 6], 337),\n",
       " ([10, 554, 719, 291, 20, 287, 54, 53, 6, 337], 4),\n",
       " ([554, 719, 291, 20, 287, 54, 53, 6, 337, 4], 11),\n",
       " ([719, 291, 20, 287, 54, 53, 6, 337, 4, 11], 287),\n",
       " ([291, 20, 287, 54, 53, 6, 337, 4, 11, 287], 54),\n",
       " ([20, 287, 54, 53, 6, 337, 4, 11, 287, 54], 448),\n",
       " ([287, 54, 53, 6, 337, 4, 11, 287, 54, 448], 24),\n",
       " ([54, 53, 6, 337, 4, 11, 287, 54, 448, 24], 461),\n",
       " ([53, 6, 337, 4, 11, 287, 54, 448, 24, 461], 82),\n",
       " ([6, 337, 4, 11, 287, 54, 448, 24, 461, 82], 745),\n",
       " ([337, 4, 11, 287, 54, 448, 24, 461, 82, 745], 4),\n",
       " ([16, 23, 10, 398, 15, 10, 133, 147, 117, 9], 10),\n",
       " ([23, 10, 398, 15, 10, 133, 147, 117, 9, 10], 462),\n",
       " ([10, 398, 15, 10, 133, 147, 117, 9, 10, 462], 147),\n",
       " ([398, 15, 10, 133, 147, 117, 9, 10, 462, 147], 117),\n",
       " ([15, 10, 133, 147, 117, 9, 10, 462, 147, 117], 4),\n",
       " ([10, 133, 147, 117, 9, 10, 462, 147, 117, 4], 6),\n",
       " ([133, 147, 117, 9, 10, 462, 147, 117, 4, 6], 244),\n",
       " ([147, 117, 9, 10, 462, 147, 117, 4, 6, 244], 1081),\n",
       " ([117, 9, 10, 462, 147, 117, 4, 6, 244, 1081], 562),\n",
       " ([9, 10, 462, 147, 117, 4, 6, 244, 1081, 562], 463),\n",
       " ([10, 462, 147, 117, 4, 6, 244, 1081, 562, 463], 6),\n",
       " ([462, 147, 117, 4, 6, 244, 1081, 562, 463, 6], 209),\n",
       " ([147, 117, 4, 6, 244, 1081, 562, 463, 6, 209], 5),\n",
       " ([117, 4, 6, 244, 1081, 562, 463, 6, 209, 5], 59),\n",
       " ([4, 6, 244, 1081, 562, 463, 6, 209, 5, 59], 1082),\n",
       " ([6, 244, 1081, 562, 463, 6, 209, 5, 59, 1082], 6),\n",
       " ([244, 1081, 562, 463, 6, 209, 5, 59, 1082, 6], 264),\n",
       " ([1081, 562, 463, 6, 209, 5, 59, 1082, 6, 264], 5),\n",
       " ([562, 463, 6, 209, 5, 59, 1082, 6, 264, 5], 247),\n",
       " ([463, 6, 209, 5, 59, 1082, 6, 264, 5, 247], 156),\n",
       " ([6, 209, 5, 59, 1082, 6, 264, 5, 247, 156], 24),\n",
       " ([209, 5, 59, 1082, 6, 264, 5, 247, 156, 24], 5),\n",
       " ([5, 59, 1082, 6, 264, 5, 247, 156, 24, 5], 9),\n",
       " ([59, 1082, 6, 264, 5, 247, 156, 24, 5, 9], 388),\n",
       " ([1082, 6, 264, 5, 247, 156, 24, 5, 9, 388], 156),\n",
       " ([6, 264, 5, 247, 156, 24, 5, 9, 388, 156], 6),\n",
       " ([264, 5, 247, 156, 24, 5, 9, 388, 156, 6], 746),\n",
       " ([5, 247, 156, 24, 5, 9, 388, 156, 6, 746], 17),\n",
       " ([247, 156, 24, 5, 9, 388, 156, 6, 746, 17], 6),\n",
       " ([156, 24, 5, 9, 388, 156, 6, 746, 17, 6], 245),\n",
       " ([24, 5, 9, 388, 156, 6, 746, 17, 6, 245], 4),\n",
       " ([5, 9, 388, 156, 6, 746, 17, 6, 245, 4], 6),\n",
       " ([9, 388, 156, 6, 746, 17, 6, 245, 4, 6], 264),\n",
       " ([388, 156, 6, 746, 17, 6, 245, 4, 6, 264], 464),\n",
       " ([156, 6, 746, 17, 6, 245, 4, 6, 264, 464], 8),\n",
       " ([6, 746, 17, 6, 245, 4, 6, 264, 464, 8], 48),\n",
       " ([746, 17, 6, 245, 4, 6, 264, 464, 8, 48], 76),\n",
       " ([17, 6, 245, 4, 6, 264, 464, 8, 48, 76], 102),\n",
       " ([6, 245, 4, 6, 264, 464, 8, 48, 76, 102], 5),\n",
       " ([245, 4, 6, 264, 464, 8, 48, 76, 102, 5], 9),\n",
       " ([4, 6, 264, 464, 8, 48, 76, 102, 5, 9], 44),\n",
       " ([6, 264, 464, 8, 48, 76, 102, 5, 9, 44], 747),\n",
       " ([264, 464, 8, 48, 76, 102, 5, 9, 44, 747], 51),\n",
       " ([464, 8, 48, 76, 102, 5, 9, 44, 747, 51], 8),\n",
       " ([8, 48, 76, 102, 5, 9, 44, 747, 51, 8], 1083),\n",
       " ([48, 76, 102, 5, 9, 44, 747, 51, 8, 1083], 95),\n",
       " ([76, 102, 5, 9, 44, 747, 51, 8, 1083, 95], 82),\n",
       " ([102, 5, 9, 44, 747, 51, 8, 1083, 95, 82], 1084),\n",
       " ([5, 9, 44, 747, 51, 8, 1083, 95, 82, 1084], 4),\n",
       " ([9, 44, 747, 51, 8, 1083, 95, 82, 1084, 4], 7),\n",
       " ([44, 747, 51, 8, 1083, 95, 82, 1084, 4, 7], 179),\n",
       " ([747, 51, 8, 1083, 95, 82, 1084, 4, 7, 179], 286),\n",
       " ([51, 8, 1083, 95, 82, 1084, 4, 7, 179, 286], 264),\n",
       " ([8, 1083, 95, 82, 1084, 4, 7, 179, 286, 264], 4),\n",
       " ([22, 1085, 117, 399, 16, 184, 331, 18, 223, 28], 23),\n",
       " ([1085, 117, 399, 16, 184, 331, 18, 223, 28, 23], 748),\n",
       " ([117, 399, 16, 184, 331, 18, 223, 28, 23, 748], 8),\n",
       " ([399, 16, 184, 331, 18, 223, 28, 23, 748, 8], 551),\n",
       " ([16, 184, 331, 18, 223, 28, 23, 748, 8, 551], 55),\n",
       " ([184, 331, 18, 223, 28, 23, 748, 8, 551, 55], 18),\n",
       " ([331, 18, 223, 28, 23, 748, 8, 551, 55, 18], 210),\n",
       " ([18, 223, 28, 23, 748, 8, 551, 55, 18, 210], 389),\n",
       " ([223, 28, 23, 748, 8, 551, 55, 18, 210, 389], 4),\n",
       " ([28, 23, 748, 8, 551, 55, 18, 210, 389, 4], 93),\n",
       " ([23, 748, 8, 551, 55, 18, 210, 389, 4, 93], 61),\n",
       " ([748, 8, 551, 55, 18, 210, 389, 4, 93, 61], 1086),\n",
       " ([8, 551, 55, 18, 210, 389, 4, 93, 61, 1086], 189),\n",
       " ([551, 55, 18, 210, 389, 4, 93, 61, 1086, 189], 16),\n",
       " ([55, 18, 210, 389, 4, 93, 61, 1086, 189, 16], 5),\n",
       " ([18, 210, 389, 4, 93, 61, 1086, 189, 16, 5], 6),\n",
       " ([210, 389, 4, 93, 61, 1086, 189, 16, 5, 6], 749),\n",
       " ([389, 4, 93, 61, 1086, 189, 16, 5, 6, 749], 465),\n",
       " ([4, 93, 61, 1086, 189, 16, 5, 6, 749, 465], 1087),\n",
       " ([93, 61, 1086, 189, 16, 5, 6, 749, 465, 1087], 18),\n",
       " ([61, 1086, 189, 16, 5, 6, 749, 465, 1087, 18], 1088),\n",
       " ([1086, 189, 16, 5, 6, 749, 465, 1087, 18, 1088], 4),\n",
       " ([189, 16, 5, 6, 749, 465, 1087, 18, 1088, 4], 206),\n",
       " ([16, 5, 6, 749, 465, 1087, 18, 1088, 4, 206], 11),\n",
       " ([5, 6, 749, 465, 1087, 18, 1088, 4, 206, 11], 12),\n",
       " ([6, 749, 465, 1087, 18, 1088, 4, 206, 11, 12], 34),\n",
       " ([749, 465, 1087, 18, 1088, 4, 206, 11, 12, 34], 1089),\n",
       " ([465, 1087, 18, 1088, 4, 206, 11, 12, 34, 1089], 18),\n",
       " ([1087, 18, 1088, 4, 206, 11, 12, 34, 1089, 18], 124),\n",
       " ([18, 1088, 4, 206, 11, 12, 34, 1089, 18, 124], 1090),\n",
       " ([1088, 4, 206, 11, 12, 34, 1089, 18, 124, 1090], 4),\n",
       " ([4, 206, 11, 12, 34, 1089, 18, 124, 1090, 4], 4),\n",
       " ([206, 11, 12, 34, 1089, 18, 124, 1090, 4, 4], 1091),\n",
       " ([11, 12, 34, 1089, 18, 124, 1090, 4, 4, 1091], 93),\n",
       " ([12, 34, 1089, 18, 124, 1090, 4, 4, 1091, 93], 388),\n",
       " ([34, 1089, 18, 124, 1090, 4, 4, 1091, 93, 388], 11),\n",
       " ([1089, 18, 124, 1090, 4, 4, 1091, 93, 388, 11], 53),\n",
       " ([18, 124, 1090, 4, 4, 1091, 93, 388, 11, 53], 108),\n",
       " ([124, 1090, 4, 4, 1091, 93, 388, 11, 53, 108], 21),\n",
       " ([1090, 4, 4, 1091, 93, 388, 11, 53, 108, 21], 157),\n",
       " ([4, 4, 1091, 93, 388, 11, 53, 108, 21, 157], 248),\n",
       " ([4, 1091, 93, 388, 11, 53, 108, 21, 157, 248], 15),\n",
       " ([1091, 93, 388, 11, 53, 108, 21, 157, 248, 15], 750),\n",
       " ([93, 388, 11, 53, 108, 21, 157, 248, 15, 750], 1092),\n",
       " ([388, 11, 53, 108, 21, 157, 248, 15, 750, 1092], 45),\n",
       " ([11, 53, 108, 21, 157, 248, 15, 750, 1092, 45], 36),\n",
       " ([53, 108, 21, 157, 248, 15, 750, 1092, 45, 36], 4),\n",
       " ([108, 21, 157, 248, 15, 750, 1092, 45, 36, 4], 292),\n",
       " ([21, 157, 248, 15, 750, 1092, 45, 36, 4, 292], 6),\n",
       " ([157, 248, 15, 750, 1092, 45, 36, 4, 292, 6], 749),\n",
       " ([248, 15, 750, 1092, 45, 36, 4, 292, 6, 749], 23),\n",
       " ([15, 750, 1092, 45, 36, 4, 292, 6, 749, 23], 17),\n",
       " ([750, 1092, 45, 36, 4, 292, 6, 749, 23, 17], 111),\n",
       " ([1092, 45, 36, 4, 292, 6, 749, 23, 17, 111], 178),\n",
       " ([45, 36, 4, 292, 6, 749, 23, 17, 111, 178], 8),\n",
       " ([36, 4, 292, 6, 749, 23, 17, 111, 178, 8], 563),\n",
       " ([4, 292, 6, 749, 23, 17, 111, 178, 8, 563], 51),\n",
       " ([292, 6, 749, 23, 17, 111, 178, 8, 563, 51], 230),\n",
       " ([6, 749, 23, 17, 111, 178, 8, 563, 51, 230], 82),\n",
       " ([749, 23, 17, 111, 178, 8, 563, 51, 230, 82], 1093),\n",
       " ([23, 17, 111, 178, 8, 563, 51, 230, 82, 1093], 176),\n",
       " ([17, 111, 178, 8, 563, 51, 230, 82, 1093, 176], 11),\n",
       " ([111, 178, 8, 563, 51, 230, 82, 1093, 176, 11], 4),\n",
       " ([178, 8, 563, 51, 230, 82, 1093, 176, 11, 4], 44),\n",
       " ([8, 563, 51, 230, 82, 1093, 176, 11, 4, 44], 12),\n",
       " ([563, 51, 230, 82, 1093, 176, 11, 4, 44, 12], 30),\n",
       " ([51, 230, 82, 1093, 176, 11, 4, 44, 12, 30], 179),\n",
       " ([230, 82, 1093, 176, 11, 4, 44, 12, 30, 179], 4),\n",
       " ([225, 15, 22, 1094, 717, 185, 1095, 28, 554, 729], 291),\n",
       " ([15, 22, 1094, 717, 185, 1095, 28, 554, 729, 291], 4),\n",
       " ([22, 1094, 717, 185, 1095, 28, 554, 729, 291, 4], 267),\n",
       " ([1094, 717, 185, 1095, 28, 554, 729, 291, 4, 267], 65),\n",
       " ([717, 185, 1095, 28, 554, 729, 291, 4, 267, 65], 9),\n",
       " ([185, 1095, 28, 554, 729, 291, 4, 267, 65, 9], 122),\n",
       " ([1095, 28, 554, 729, 291, 4, 267, 65, 9, 122], 8),\n",
       " ([28, 554, 729, 291, 4, 267, 65, 9, 122, 8], 1096),\n",
       " ([554, 729, 291, 4, 267, 65, 9, 122, 8, 1096], 28),\n",
       " ([729, 291, 4, 267, 65, 9, 122, 8, 1096, 28], 7),\n",
       " ([291, 4, 267, 65, 9, 122, 8, 1096, 28, 7], 153),\n",
       " ([4, 267, 65, 9, 122, 8, 1096, 28, 7, 153], 263),\n",
       " ([267, 65, 9, 122, 8, 1096, 28, 7, 153, 263], 55),\n",
       " ([65, 9, 122, 8, 1096, 28, 7, 153, 263, 55], 389),\n",
       " ([9, 122, 8, 1096, 28, 7, 153, 263, 55, 389], 28),\n",
       " ([120, 118, 16, 564, 21, 25, 751, 10, 85, 1097], 112),\n",
       " ([118, 16, 564, 21, 25, 751, 10, 85, 1097, 112], 6),\n",
       " ([16, 564, 21, 25, 751, 10, 85, 1097, 112, 6], 1098),\n",
       " ([564, 21, 25, 751, 10, 85, 1097, 112, 6, 1098], 62),\n",
       " ([21, 25, 751, 10, 85, 1097, 112, 6, 1098, 62], 6),\n",
       " ([25, 751, 10, 85, 1097, 112, 6, 1098, 62, 6], 1099),\n",
       " ([751, 10, 85, 1097, 112, 6, 1098, 62, 6, 1099], 23),\n",
       " ([10, 85, 1097, 112, 6, 1098, 62, 6, 1099, 23], 65),\n",
       " ([85, 1097, 112, 6, 1098, 62, 6, 1099, 23, 65], 4),\n",
       " ([1097, 112, 6, 1098, 62, 6, 1099, 23, 65, 4], 59),\n",
       " ([112, 6, 1098, 62, 6, 1099, 23, 65, 4, 59], 211),\n",
       " ([6, 1098, 62, 6, 1099, 23, 65, 4, 59, 211], 8),\n",
       " ([1098, 62, 6, 1099, 23, 65, 4, 59, 211, 8], 1100),\n",
       " ([62, 6, 1099, 23, 65, 4, 59, 211, 8, 1100], 6),\n",
       " ([6, 1099, 23, 65, 4, 59, 211, 8, 1100, 6], 564),\n",
       " ([1099, 23, 65, 4, 59, 211, 8, 1100, 6, 564], 55),\n",
       " ([23, 65, 4, 59, 211, 8, 1100, 6, 564, 55], 78),\n",
       " ([65, 4, 59, 211, 8, 1100, 6, 564, 55, 78], 265),\n",
       " ([4, 59, 211, 8, 1100, 6, 564, 55, 78, 265], 4),\n",
       " ([59, 211, 8, 1100, 6, 564, 55, 78, 265, 4], 22),\n",
       " ([211, 8, 1100, 6, 564, 55, 78, 265, 4, 22], 186),\n",
       " ([8, 1100, 6, 564, 55, 78, 265, 4, 22, 186], 23),\n",
       " ([1100, 6, 564, 55, 78, 265, 4, 22, 186, 23], 1101),\n",
       " ([6, 564, 55, 78, 265, 4, 22, 186, 23, 1101], 18),\n",
       " ([564, 55, 78, 265, 4, 22, 186, 23, 1101, 18], 10),\n",
       " ([55, 78, 265, 4, 22, 186, 23, 1101, 18, 10], 1102),\n",
       " ([78, 265, 4, 22, 186, 23, 1101, 18, 10, 1102], 1103),\n",
       " ([265, 4, 22, 186, 23, 1101, 18, 10, 1102, 1103], 109),\n",
       " ([4, 22, 186, 23, 1101, 18, 10, 1102, 1103, 109], 4),\n",
       " ([22, 186, 23, 1101, 18, 10, 1102, 1103, 109, 4], 11),\n",
       " ([186, 23, 1101, 18, 10, 1102, 1103, 109, 4, 11], 23),\n",
       " ([23, 1101, 18, 10, 1102, 1103, 109, 4, 11, 23], 10),\n",
       " ([1101, 18, 10, 1102, 1103, 109, 4, 11, 23, 10], 1104),\n",
       " ([18, 10, 1102, 1103, 109, 4, 11, 23, 10, 1104], 7),\n",
       " ([10, 1102, 1103, 109, 4, 11, 23, 10, 1104, 7], 120),\n",
       " ([1102, 1103, 109, 4, 11, 23, 10, 1104, 7, 120], 118),\n",
       " ([1103, 109, 4, 11, 23, 10, 1104, 7, 120, 118], 11),\n",
       " ([109, 4, 11, 23, 10, 1104, 7, 120, 118, 11], 15),\n",
       " ([4, 11, 23, 10, 1104, 7, 120, 118, 11, 15], 22),\n",
       " ([11, 23, 10, 1104, 7, 120, 118, 11, 15, 22], 185),\n",
       " ([23, 10, 1104, 7, 120, 118, 11, 15, 22, 185], 21),\n",
       " ([10, 1104, 7, 120, 118, 11, 15, 22, 185, 21], 11),\n",
       " ([1104, 7, 120, 118, 11, 15, 22, 185, 21, 11], 52),\n",
       " ([7, 120, 118, 11, 15, 22, 185, 21, 11, 52], 17),\n",
       " ([120, 118, 11, 15, 22, 185, 21, 11, 52, 17], 446),\n",
       " ([118, 11, 15, 22, 185, 21, 11, 52, 17, 446], 65),\n",
       " ([11, 15, 22, 185, 21, 11, 52, 17, 446, 65], 19),\n",
       " ([15, 22, 185, 21, 11, 52, 17, 446, 65, 19], 124),\n",
       " ([22, 185, 21, 11, 52, 17, 446, 65, 19, 124], 390),\n",
       " ([185, 21, 11, 52, 17, 446, 65, 19, 124, 390], 15),\n",
       " ([21, 11, 52, 17, 446, 65, 19, 124, 390, 15], 1105),\n",
       " ([11, 52, 17, 446, 65, 19, 124, 390, 15, 1105], 4),\n",
       " ([52, 17, 446, 65, 19, 124, 390, 15, 1105, 4], 1106),\n",
       " ...]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([ 16,  14,  10,  65, 184,   9,  49,  10,  70,  65]),\n",
       "  tensor([73]),\n",
       "  10),\n",
       " torch.Size([10]),\n",
       " (tensor([33, 89, 90, 91,  4, 13, 21, 34, 50,  4]), tensor([4]), 10),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0], train_dataset[0][0].shape, \\\n",
    "valid_dataset[0], valid_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ATBQ4WaJR93"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfNGrams(nn.Module):\n",
    "    def init_layers(self):\n",
    "        for l in self.layers:\n",
    "            if getattr(l, 'weight', None) is not None:\n",
    "                torch.nn.init.xavier_uniform_(l.weight)\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim=300, hidden_size=256, out_size=128, reduce='sum', nlayers=2, activation='ReLU', dropout=0.1, batch_norm=False):\n",
    "        super(BagOfNGrams, self).__init__()\n",
    "       \n",
    "        self.emb_dim = emb_dim\n",
    "        self.reduce = reduce\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = getattr(nn, activation)\n",
    "        \n",
    "        self.embedding = nn.EmbeddingBag(num_embeddings=vocab_size, embedding_dim=emb_dim, mode=reduce)\n",
    "        if batch_norm is True:\n",
    "            self.batch_norm = nn.BatchNorm1d(self.emb_dim)\n",
    "        self.layers = nn.ModuleList([nn.Linear(self.emb_dim, self.hidden_size)])\n",
    "        self.layers.append(self.activation())\n",
    "        self.layers.append(nn.Dropout(p=dropout))\n",
    "        \n",
    "        for i in range(self.nlayers-2):\n",
    "            self.layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            self.layers.append(self.activation())\n",
    "            self.layers.append(nn.Dropout(p=dropout)) \n",
    "        self.layers.append(nn.Linear(self.hidden_size, self.out_size))\n",
    "        self.init_layers()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        postemb = self.embedding(x)\n",
    "        if hasattr(self, 'batch_norm'):\n",
    "            x = self.batch_norm(postemb)\n",
    "        else:\n",
    "            x = postemb\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderMLP(nn.Module):\n",
    "    \"\"\"Generates a token in response to context.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size=128, output_size=1024, hidden_size=256):\n",
    "        \"\"\"Initialize decoder.\n",
    "        :param input_size: size of embedding\n",
    "        :param output_size: size of vocabulary\n",
    "        :param hidden_size: size of the linear layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "            \n",
    "        self.linear = nn.Linear(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Return encoded state.\n",
    "        :param input: batch_size x 1 tensor of token indices.\n",
    "        :param hidden: past (e.g. encoder) hidden state\n",
    "        \"\"\"\n",
    "        output = F.relu(self.linear(input))\n",
    "        scores = self.softmax(self.out(output))\n",
    "        return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, bag_of_ngrams, decoder, lr = 1e-3, use_cuda = True, \n",
    "                        longest_label = 20, \n",
    "                        clip = 0.3):\n",
    "        super(seq2seq, self).__init__()\n",
    "\n",
    "        device = torch.device(\"cuda\" if (torch.cuda.is_available() and use_cuda) else \"cpu\")\n",
    "        self.device = device;\n",
    "        self.bag_of_ngrams = bag_of_ngrams.to(device);\n",
    "        self.decoder = decoder.to(device)\n",
    "\n",
    "        self.longest_label = longest_label\n",
    "\n",
    "        # set up the criterion\n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "        self.optims = {\n",
    "             'nmt': optim.SGD(self.parameters(), lr=lr, nesterov=True, momentum = 0.99)\n",
    "        }\n",
    "\n",
    "        self.longest_label = longest_label\n",
    "        self.clip = clip;\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Zero out optimizer.\"\"\"\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def update_params(self):\n",
    "        \"\"\"Do one optimization step.\"\"\"\n",
    "        if self.clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.bag_of_ngrams.parameters(), self.clip)\n",
    "            torch.nn.utils.clip_grad_norm_(self.decoder.parameters(), self.clip)\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "    \n",
    "    def v2t(self, vector):\n",
    "        return [train_id2token_unigram[i] for i in vector]\n",
    "        \n",
    "    def train_step(self, xs, ys):\n",
    "        \"\"\"Train model to produce ys given xs.\n",
    "        :param batch: parlai.core.torch_agent.Batch, contains tensorized\n",
    "                      version of observations.\n",
    "        Return estimated responses, with teacher forcing on the input sequence\n",
    "        (list of strings of length batchsize).\n",
    "        \"\"\"\n",
    "        if xs is None:\n",
    "            return\n",
    "        xs = xs.to(self.device)\n",
    "        ys = ys.to(self.device)\n",
    "\n",
    "        self.zero_grad()\n",
    "        self.bag_of_ngrams.train()\n",
    "        self.decoder.train()\n",
    "    \n",
    "        bow_output = self.bag_of_ngrams(xs)\n",
    "        decoder_output = self.decoder(bow_output)\n",
    "            \n",
    "        loss = self.criterion(decoder_output, ys.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "\n",
    "        _max_score, predictions = decoder_output.max(1)\n",
    "        \n",
    "        return self.v2t(predictions), loss.item() \n",
    "\n",
    "    def eval_step(self):\n",
    "        \"\"\"Generate a response to the input tokens.\n",
    "        :param batch: parlai.core.torch_agent.Batch, contains tensorized\n",
    "                      version of observations.\n",
    "        Return predicted responses (list of strings of length batchsize).\n",
    "        \"\"\"\n",
    "        # just predict\n",
    "        self.bag_of_ngrams.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        predictions = []\n",
    "        encoder_input = torch.LongTensor([BOS_IDX] * N).unsqueeze(0)\n",
    "\n",
    "        for _ in range(self.longest_label):\n",
    "            decoder_input = self.bag_of_ngrams(encoder_input)\n",
    "            decoder_output = self.decoder(decoder_input)\n",
    "            _max_score, next_token = decoder_output.max(1)\n",
    "            \n",
    "            predictions.append(next_token)\n",
    "            \n",
    "            prev_tokens = torch.cat([encoder_input.squeeze(0)[1:N]])\n",
    "\n",
    "            encoder_input = torch.cat((prev_tokens, next_token), 0).unsqueeze(0)\n",
    "            \n",
    "            # stop if you've found the \n",
    "            if next_token.item() == EOS_IDX:\n",
    "                break\n",
    "                \n",
    "        predictions = torch.cat(predictions, 0)\n",
    "        return self.v2t(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c6c1fe837f413ca5f2642c607118c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 198.3320779800415\n",
      "Generated Sentence:  . . . , , , , , , , , , , , , , , , , ,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec037c46e8ea45cc9a51e30f8cf442e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840349e730c54740824a932577596742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b265546dec244542ab3436cbe76e54ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ea153fb76248639a3fecfdcaa03eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c431324f9084c8f8fb6707533cc65c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e511c6e145040f8b0750afdff71fcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a4c096fd8a4e7d9aad15a86d07e26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242a4e76895a4481af76991ecd7015c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39c17b66b43439892f3109694276c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a22a219f6c44b329dbd54434d359e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss 119.8496904373169\n",
      "Generated Sentence:  words words , , , , , , , is is , , , , , , , , ,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf73b2e74274c4fb797034b3fdac3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f647ac4e1ea4ac2afa5981f5771a4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0df54b158ea424088292f304dfa2c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d508331a8c42cd89a67e097670d0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a11ae878974581bd634b42b4371a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d3a383828e41f79b7a8b4b7f92186b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef242e1d3244a5e81f9b7f8d62532ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a904ee720fb744d2a80854955f815ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccd4930261240a1b4e9dd36eb8e6702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649fcb82841d4775ad05d70d09b27263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss 48.311426281929016\n",
      "Generated Sentence:  , , , , , , , , , , hear them , , , , , , , ,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8e539e96c141c1977f5725af52a28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f520ae3017c2409abefa4471acafe0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476464aca61049cbaaa6ab25ab2ffc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ac87868f5c4b00914e8763f3adfe8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccc18c9a437435488a2615834dc1988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4be838f1d3460cbb53be69b3dc7169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc1451645554c3ab414df70e96c95ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef05e398e5bf4c30b2d5b4e266f63fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3f53cb6a9743e793370b6d4807dcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c213a7c29a439581f7d6d0b3983c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss 37.4304758310318\n",
      "Generated Sentence:  language , , language unit unit unit and three girls 4 classes classes 1 do most level lot of of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a27f447a6c146ab9bf14f76bdb46aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92ab251b75a41fdb7acffb7d941e75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca9574e74a54f4b99f23958504d8a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97e6a9c52934841a0e2c4425580656e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d1f86882e5486f965269fac2c145fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791f93eba31343cf818c8a0caedbf066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf319a1486f94ee19f6198229a3cc87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a23c918914a7087a306a8568cfc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834b0cee92324628bb957096aa5e16fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b910b864dc7b48caa88e9102e784f238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Loss 28.72671866416931\n",
      "Generated Sentence:  , italian easy easy \" ( ( . than the had program french of $ $ haven ' s very\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f707415e514b41d898965341beb3b79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969cd84c6267484ebddb17ff29933d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cf847f25f84f29baec4752a903398a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3dc5a2461f41b89c89075c8bf2599b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3851657f2e04985ac6f87f31ad8331d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe0d5c11ee04dd6ac8c99b7c738dd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d99f29142a44d5929ce069b3431995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75dbba6c81e40c3bd9ffebe0ffd0462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f50664592949c4871a521a768d4382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e675b045b07743089d0f2bba75f626d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Loss 19.607262134552002\n",
      "Generated Sentence:  , , , , , , , mirandese lombard mirandese headset neapolitan although although play i i it on 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f0b2b6d3de419685367168d46e2bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9535b408c8d74944bb74d5778105dc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7932c32066d4081a090cac4c9dd2979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f57b245bda48d4b2548e75741dc3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc21ed3f43bb4bcb9d351706405d1f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af543a8550f454bbe3f98fea668dd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e674d2ab514901a4b80fa8bdd6ee00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df382ecfbbb4cd99d7b8a0469ce3a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a8fd4df9964f5eae6b82f84082ec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244da4cafd914de6b415d54c9b7a5cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Loss 13.781893640756607\n",
      "Generated Sentence:  , , , , , but piedmontese romagnolo price and is the people the of product practice very , course\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f6514b818e4de6a9166417aab2d6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d98c8dc6fc44472925e72442ff92812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226d918e232d4b1c8cd865b6880427b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5054d148fa74fffb5627c1237b83121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965437031a44459e90a945315f5e7ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c685eea04548009a38cbbb76fdd350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3908f928d6a48fa82533f072db046b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518d895e66414b0d98997bbe70a9c8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9feceb3270ba494283ec2797314810ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f77b8e45e284827bf51a3064eb0d8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Loss 13.13233931362629\n",
      "Generated Sentence:  , , , , , i , , the will little will . . work to you this work and\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5763bcdd8dc4d9ebb2e998bd1c37367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e1f8ea3ecc4dc58c983e8d0a392d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d69103f69a4ce7980fdf0c065f3aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c0588091664f81ae3f3c82b4a70cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2032e0e36f14470782033400a5a37228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33df92e248cd4fdf9bc09b280f0b482c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3e9fb91ff346428c1a99bf7b03c17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6953ad31124afb8141bd751f1a1be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373966cf05f141f0a4314a6e2f537b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e402bef3f14b09a9d3243c60568986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Loss 11.378836691379547\n",
      "Generated Sentence:  , , i i italian italian italian language . ' like can ! this with is is interested recommend recommend\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f666df863b94ff484e388ada8e81bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d595203c8d6b45539da7c84978b28980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39834ba1191404db41ad171e9785bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac04829328e4883ac0000d1fc9bb894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d0855a45d142a8b4fd30a6d14e8d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f568dbbb3eca4ca1892d3b38be014fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff85a2d4d8f94fd7b3d155af46117162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569a12ca665b49d4a72a745e34f170cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f1c317a39041aeb6546ea0984a9e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d882da968a8490db5d3c13d0a7cac72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Loss 10.812430545687675\n",
      "Generated Sentence:  , , , , , , but but i on have think on have and all the a laptop end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb15b2cdb194d1aadb093ccebb9bbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9729965afc41868b0e08bebba878c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28201180b3f946fe891c6df1b79a807b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff2f14cc9aa48b983118d0656a28126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0234e186f96646b4bc6ec19d7a510db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2e07eb4d5045df95df2bf7a3b8aa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06718c542dc435288de52f9c12a04e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f11f7bd2ed645088182882196428ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25494b9912c4930bb1732de1aa7d8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984cbde78fa14a668686ba46539fd3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss 11.678688377141953\n",
      "Generated Sentence:  . four expecting expecting expecting - - - to that a of down last the chat chat it well as\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3270ecd54743a39407197afdd8f234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9b5641b5554083922d049b56ed45c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d619ec0bc5954e8c862e17fbb370499e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d971b804fff64ba3a10d4a0cda65bbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2be87a350a4797ad8b08a036946c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9385eb8bb343a092b2534d6dad47b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711c45a8fec44816ba0471bcf1367411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea822811400843caa6a9d2254b647348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f08596b69a48b2b35332519c3036bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31f31c7af0a45a9a60173b74ad20582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: Loss 13.107194870710373\n",
      "Generated Sentence:  , , italian italian to italian language language me online . ' in times i great ] like picking program\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c0ec72182d4b24ba7aad62ead7049c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1b08bc4f714e009143cef8453ef676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c63fc9a46843ecab1d0a1497a6a89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a9574654aa446d81dfcc5e1c1ae0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994fbbdb04b9400089206d684e94959f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432c40cd403a47ec8be2a1f8a538b45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c423d021910c408f93750370736cfd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc9e3ca22ab4b1684b03d5aa668db4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5611e09f3e2f4faca77a36181127eb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd4f94f1d584fbb9cd1622bd188bf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Loss 12.108097597956657\n",
      "Generated Sentence:  , , , , i i but with the only the have never never < < level 90 90 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7369ed24cf46c48533b977b5fa33d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e70d9aa5a94ad4aa2051c145ebd468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22478e2fd66a46f5bd40f3ab99ba30bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3725bcbd5cc4f859c5acaaaf352ddbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ada2bd021794e97837151e9432007ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a3b5f663f64da5920a005a5b9ff789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaecd609ec74929ad1457b57404ad92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095c63e5392a4f43a656f70ca3c5a3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afaa86ec01104bf5acb8a422bfd0290e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753dd2e847f744a38913d5612e1e13fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: Loss 12.551973193883896\n",
      "Generated Sentence:  to , italian italian to italian . in keep in the the person however remembered in occasionally the software contents\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b284af8a6c449078314e30787365c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b04e31f218a452fa756361014fd0939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9165263c6ba14480ae503e88b75c92bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448312be3ae042d0a80557f916901eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb3be9eec3e44bcad58d5f3ac923ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a199731880944a198a94fa85af2d2578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83812afbd4424feba3a33905a6b64b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f949b0e8535f45e9b90373c3bc3eb7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12647c3dd47244a188a51e6a9a8dd0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9b87bea474438497b2a51a54f71b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: Loss 12.671340689063072\n",
      "Generated Sentence:  italian italian , , but . . thin etc then easily want wait to continue to me the well well\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5eac98e4254426a173a138c9ccfdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2d1018ffd94b28983b8c6e0288ed88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960956fc185c40e28b9428f447b364c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa09316721424fb1bdde1e05f5aff76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b40fefaa5345058f34dea7f557d979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b46156f46d4499c91fca0bf0956ef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3191616a08744896a24db91d3bbf2d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7e0d85ba0b47aeafe49fb77cb95cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32cd27918fa4ab8bc61326c00032093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01050f08c4584d2cbbfe4955152f1979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: Loss 13.724978476762772\n",
      "Generated Sentence:  italian italian italian language language language , at . times long , about as you tried reason not hard do\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58f4bd2d1c462b9bfffd10980a5268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f2d9af10d44e1ea4362b26715e653d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f20ef451554441b8cdb42d2bf383135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd01c16d5847431d9035ad361acad34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1e276be74d4c5889ae524e1a0250e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d28db65d71847a48aef98ab99558aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3307b9b4494b54b7fa3683a40a1c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f188270e6973460989945dbe8e7c1025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235abd48e8944342871ae16e2fc0bc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc79e153ae9443b9433d0c8bcdbc41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160: Loss 13.882253855466843\n",
      "Generated Sentence:  italian italian and , language language of , . as as lab if you away away you learn the seem\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8ed57567604e2daab43752e5fda8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cafbb923ff64b44bd4135e5908ef216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe37aa978fd450fac6cdf88ca779c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c3443c2b764c90a30b7f46105c67ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0af4ff178204173865ec90691027b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2335f314423d4afdae86c47e5e0cd655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eab63e417344cd9a86f7f4c3d79309b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae40e56a7df4bb1a34901799ba63e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db18e6abd658418aa79ebb41a504c7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e33645c7004983ba033d47d068349e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: Loss 13.223953276872635\n",
      "Generated Sentence:  < four four four of to instructor . < up up up . . . . . i is so\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2f8d119c9547fdb18d81e7bc54a3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369c893a7606430bbf0295e9c8685c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2770aebc14a48c3bcdd40eea54a0495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a2592a1062436fbcfdfc4ac618ae55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f93115949dd480eaa948f03fe40bb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53c7afde7ed4683b31315920364962d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a30f2977704afeb050b24d8d4ded59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c785e9133ee34e2fae2ccd1d31dc3d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9515c5bad74d42923174245242a9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef2d15f9af248049a5c9c254de03e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180: Loss 14.87006813287735\n",
      "Generated Sentence:  , , , , , but but but have ' saying disadvantages doesn t and level a . i find\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4c8a5657f746b1865646301d43a9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c46ba36d7f347ef8a250784a2cf7b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb89d065d7841eab5b70ae321b6a19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bba1b3bbff40d89b96a7b42958266c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ea611796f74037b41b69b87e5f2477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f265aa394a745bab9d2a6d4d9bcdc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cd8afd54314582a369a60dd5a90ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9223945bb474ddbb99f7c1d23dde757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e71195a47d4a898744c4a3f3d8149c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4ec9d2c9e043e7baab8f87b254287c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190: Loss 16.200992971658707\n",
      "Generated Sentence:  but but i , i not have 4 ' t a a lot lot of dictionary and i have of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80220352a6b340b58ec7a30f45ed0b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f089b1a39824e69b8e8393b5b39d146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f355ea907544a2baf9ea7a998016ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a887c37cb37d4439ae1c7204cf205367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a99c2ac2674524a0cca9caddacc050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f9b6f6cf5e419b88d6d3691e67888e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7584735a9f274929985170316764678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3b16a4813c4289a1129f6cf96671c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5123693e887c4b0aa47fd014978db616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeee28b7bed44cdbd1d35f9910fe2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Loss 15.191665083169937\n",
      "Generated Sentence:  , , , , , , , piedmontese , , a respond and kills because the next expected lot love\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c74277358a4a2fb8abc5b89d413961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668d5d6ee0194a47a61e8b22450b59e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57416694a9ea4edf9a5f380d4ba95b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd1d4a71c0b418799a88b6939103fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86e0aaf41ff4649ba59406a342d7f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c61e8f132c44addb4160a9f2688c0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3dade0ac5e43ffb2a176d516a153cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebda43fa25945c183954fe401be3a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32002fc16ba4447afb9a91d278c1bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1f7b1e5e904ddc854e978ac398c613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210: Loss 16.177113205194473\n",
      "Generated Sentence:  < < < of talking talking or , , the even even been phrases along with along with . it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b91579ceb74c82b309ac81c82bbacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e2fd74e70f4d90a489390ed879c1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431af601545e4183b24feac75b746754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2c5cd1f4d24720a09631eb9a4a6a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1c68600ac849b9858b174f3439b533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75ca97e35504f96a78c971bb93e1478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d0eee964a9435a9d8bc193b6f3b7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7308471000644aa8c2929b3933ecac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6025db7eae964ace885c0abc4fbd8ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f428abc19054e2dbe013d17d246382f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220: Loss 17.502338886260986\n",
      "Generated Sentence:  . i . < < < for like the a passport \" they much much pack sound , ts of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15139e3057246c6b6569b09d17c2576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b842469c864c58b7c2ec48ec8ea31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251647c3e54e4427bd7214410dc33c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c45d37e4ec1437ab10fb6e6e1487829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbb672725984a52b7c674ffcad1805c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fb763dcef6475ebd0f3084c2c654a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61d3836e3e448d4aa31f0425028b12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb5557f62b942668bf317ddb9806f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19000100a5a4b66b6d83863f3bb032d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2643ac617ff4ca3902df9b2eb1bfdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230: Loss 18.455471575260162\n",
      "Generated Sentence:  their their talking and , account you said are only this that practice of with and it is some go\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444d03eb03844c9fad5afc3e1dd55650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a8efffc39945d9b2660ea9fefe0c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5047dba91ae644acb9bcecc5362d09b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026cad6f960a48ddb840181129fcd72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8b057ba27d4f229bd99e4112c8940f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b8e553eb09464392ceab5741534a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16060642b04d46d5ab7cbbde662b7dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5088955fef405aa20d2d84087a8480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f933f37f52854f59a179565564d25ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680363ccc73544f3a780e72b7a7bf4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240: Loss 17.693936049938202\n",
      "Generated Sentence:  , , , , , unit i cheap boot three though into and have , , the package which could\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e47a3412b94eae845274205df671d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567d90957be94707a41ba5c970ada0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519831d144104f2da428fa8e3cff67b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d622d08798d4a6ea671266f7227fead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8bc606a8dc499dbea731eeddddc9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-575-c8ba562f86da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loss_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-567-18807f0321e7>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, xs, ys)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "bag_of_ngrams = BagOfNGrams(len(train_id2token_unigram), emb_dim=300, hidden_size=256, out_size=128, activation='Tanh', nlayers=1, reduce='mean', dropout=0.0, batch_norm=False)\n",
    "decoder = DecoderMLP(input_size=128, output_size=len(train_id2token_unigram), hidden_size=256)\n",
    "model = seq2seq(bag_of_ngrams, decoder, use_cuda=False, lr=1e-1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss_epoch = 0\n",
    "    for i, (data, labels) in _tqdm(enumerate(train_loader)):\n",
    "        prediction, loss = model.train_step(data, labels)\n",
    "        train_loss_epoch += loss\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {}: Loss {}\".format(epoch, train_loss_epoch))\n",
    "#         print(\"prediction \", prediction)\n",
    "\n",
    "        generated = model.eval_step()\n",
    "        generated_str = ' '.join([g[0] for g in generated])\n",
    "        print(\"Generated Sentence: \", generated_str)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. of of in < < well that < the the a costume . of < < is as thin'"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KenLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ngram-lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
