{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "### Goal: compute a probabilty distribution over all possible sentences:\n",
    "\n",
    "\n",
    "### $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
    "\n",
    "### This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
    "\n",
    "### $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
    "\n",
    "### If we have K sentences, where the j-th sentence has T_j words for all j frmo 1 to K, then we want to max:\n",
    "\n",
    "### $$log p(W) = \\sum_{j = 1}^K \\sum_{i=1}^{T_j} log p(w_i | w_{<i})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model\n",
    "\n",
    "### Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
    "\n",
    "### Given a sequence of words $w$, we want to compute\n",
    "\n",
    "###  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
    "\n",
    "### Where $w_i$ is the i-th word of the sequence.\n",
    "\n",
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
    "\n",
    "### Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities\n",
    "\n",
    "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('utils/')\n",
    "from utils import ngram_utils as ngram_utils\n",
    "import utils.global_variables as gl\n",
    "import torch\n",
    "import random\n",
    "from utils.ngram_utils import NgramLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H20pktPiA63a",
    "outputId": "fb38d897-e889-4451-df77-9ca98eb266a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbca43a42b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from .txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_data), len(train_data), \\\n",
    "# type(train_data[0]), len(train_data[0]), \\\n",
    "# type(train_data[0][0]), len(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " 't')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449a368e59d84149b570ad2ce8447bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d93b7b94c747fe80d97db44ee5cefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
    "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107790,\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'tutu',\n",
       "  'and',\n",
       "  'at',\n",
       "  'a',\n",
       "  'really',\n",
       "  'great',\n",
       "  'price',\n",
       "  '.'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Number of All Tokens\n",
    "# len(all_tokens_train), all_tokens_train[0], \\\n",
    "len(train_data_tokenized), train_data_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_lm = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing=None)\n",
    "valid_ngram_lm = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.9, 1623446)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_lm.n, train_ngram_lm.frac_vocab, train_ngram_lm.num_all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['organs', 'salt', 'attempted'],\n",
       " [['these', 'are', 'not', 'sized', 'right', '.'],\n",
       "  ['a',\n",
       "   '3x',\n",
       "   'is',\n",
       "   'always',\n",
       "   'big',\n",
       "   'on',\n",
       "   'me',\n",
       "   'and',\n",
       "   'these',\n",
       "   'r',\n",
       "   'cut',\n",
       "   'wrong',\n",
       "   '!'],\n",
       "  ['i', \"'\", 'm', 'returning', 'them', '.']])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocabulary[:3], valid_ngram_lm.raw_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'), ('<sos>', '<sos>', 'i'), ('<sos>', '<sos>', 'the')),\n",
       " (13625, 3635, 1425))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_ngram[:3], valid_ngram_lm.count_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.',), ('the',), ('i',)), (14883, 9408, 8000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_unigram[:3], valid_ngram_lm.count_unigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'), ('<sos>', 'i'), ('<sos>', 'the')), (13625, 3635, 1425))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_bigram[:3], valid_ngram_lm.count_bigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'), ('<sos>', 'i'), ('<sos>', 'the')), (13625, 3635, 1425))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_prev_ngram[:3], valid_ngram_lm.count_prev_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<unk>',\n",
       " '<sos>',\n",
       " '<eos>',\n",
       " ('.', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'i'),\n",
       " ('<sos>', '<sos>', 'the'),\n",
       " ('<sos>', '<sos>', 'it'),\n",
       " ('!', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'this')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.id2token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id[('.', '<eos>', '<eos>')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 23115 words\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
    "vocabulary = train_ngram_lm.vocabulary\n",
    "print('Word vocabulary size: {} words'.format(len(vocabulary)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS ANALYSIS (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tokens in the Corpus Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Tokens  1623446\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All Tokens \", train_ngram_lm.num_all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All UNIQUE Tokens  23115\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All UNIQUE Tokens \", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences in the Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences  107790\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Sentences \", len(train_ngram_lm.raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = train_ngram_lm.padded_data\n",
    "train_ngram = train_ngram_lm.ngram_data\n",
    "vocab_ngram = train_ngram_lm.vocab_ngram\n",
    "count_ngram = train_ngram_lm.count_ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '<sos>',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tutu',\n",
       " 'and',\n",
       " 'at',\n",
       " 'a',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " '.',\n",
       " '<eos>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for finding all N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<sos>', '<sos>', 'this'),\n",
       " ('<sos>', 'this', 'is'),\n",
       " ('this', 'is', 'a'),\n",
       " ('is', 'a', 'great'),\n",
       " ('a', 'great', 'tutu'),\n",
       " ('great', 'tutu', 'and'),\n",
       " ('tutu', 'and', 'at'),\n",
       " ('and', 'at', 'a'),\n",
       " ('at', 'a', 'really'),\n",
       " ('a', 'really', 'great'),\n",
       " ('really', 'great', 'price'),\n",
       " ('great', 'price', '.'),\n",
       " ('price', '.', '<eos>'),\n",
       " ('.', '<eos>', '<eos>')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.', '<eos>', '<eos>')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_ngram = train_ngram_lm.trie_ngram\n",
    "# trie_ngram\n",
    "# trie_prev_ngram = train_ngram_lm.trie_prev_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_ngram['./<eos>/<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trie_ngram  # (ngram, number_of_times_ngram_appears_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_ngram = train_ngram_lm.id2token\n",
    "token2id_ngram = train_ngram_lm.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 261405 ; token ('of', 'jeans', 'but')\n",
      "Token ('of', 'jeans', 'but'); token id 261405\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
    "random_token = id2token_ngram[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Count & Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the words for which the pd is nonzero !!! -- more intuitive than a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', '<sos>', 'the'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'they'),\n",
       "  ('<sos>', '<sos>', 'it'),\n",
       "  ('.', '.', '.'),\n",
       "  ('<sos>', '<sos>', 'this'),\n",
       "  ('<sos>', '<sos>', 'these'),\n",
       "  ('.', '.', '<eos>')),\n",
       " (96175, 26986, 9197, 8152, 6376, 5373, 4693, 4189, 3941, 3876))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[:10], count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.04, 0.04, 0.04, 0.0, 1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('an', 'older', 'coat'))\n",
    "p = train_ngram_lm.get_ngram_prob(('an', 'older', 'coat'))\n",
    "\n",
    "p1 = train_ngram_lm.get_ngram_prob(('an', 'older', 'pc'))\n",
    "p2 = train_ngram_lm.get_ngram_prob(('an', 'older', 'lady'))\n",
    "p3 = train_ngram_lm.get_ngram_prob(('an', 'older', 'watch'))\n",
    "\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('an', 'older'))\n",
    "\n",
    "c, p, p1, p2, p3, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.06521739130434782, 1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great', 'price'))\n",
    "p = train_ngram_lm.get_ngram_prob(('really', 'great', 'price'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('really', 'great'))\n",
    "\n",
    "c, p, sum(pd)#, pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96175, 1.0, 1.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<eos>', '<eos>'))\n",
    "p = train_ngram_lm.get_ngram_prob(('.', '<eos>', '<eos>'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('.', '<eos>'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<sos>', '<sos>'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0.9999999999999897)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "p = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 0.0680515759312321, 0.9999999999999897)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'this'))\n",
    "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'this'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 0.09761467889908257, 1.0000000000000142)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('is', 'a', 'great'))\n",
    "p = train_ngram_lm.get_ngram_prob(('is', 'a', 'great'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('is', 'a'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 0.9032258064516129, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('send', 'it', 'back'))\n",
    "p = train_ngram_lm.get_ngram_prob(('send', 'it', 'back'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('send', 'it', 'back'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'these', 'pictures'))\n",
    "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'these', 'pictures'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like', 'these'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{1 + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.806074878646609e-05"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<sos>', '<sos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.503895869927487e-05"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'pandas'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004323740035130388"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'this'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001918189229367477"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('really', 'great', 'price'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013916882618293502"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('send', 'it', 'back'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8221435776444239"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<eos>', '<eos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{\\delta + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\delta\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.806074878646609e-05"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<sos>', '<sos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.237467689308869e-05"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'pandas'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00809356328657994"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'this'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033494425570601463"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('really', 'great', 'price'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002731323973357612"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('send', 'it', 'back'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9023911952223009"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788246381634857"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837030564493178"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# large delta --> closer to add-one smoothing (0.58)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.9)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation Smoothing (Jelinek-Mercer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\alpha_n P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) + (1 - \\alpha_n) P(w|w_{i−n+2}, ..., w_{i−2}, w_{i−1})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<sos>', '<sos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'pandas'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054441260744985676"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'this'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052173913043478265"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('really', 'great', 'price'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7225806451612904"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('send', 'it', 'back'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation with Absolute Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
    "\n",
    "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
    "\n",
    "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
    "\n",
    "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
    "\n",
    "\n",
    "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
    "\n",
    "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
    "\n",
    "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
    "\n",
    "### V is the number of words in the vocabulary\n",
    "\n",
    "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to check that probabilities sum up to one:\n",
    "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1681.0120390042784"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = \"m\"\n",
    "x = \"'\"\n",
    "\n",
    "z = train_ngram_lm.get_p_bi(y, x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<sos>', '<sos>', 'this'),\n",
       "  ('<sos>', 'this', 'is'),\n",
       "  ('this', 'is', 'a'),\n",
       "  ('is', 'a', 'great'),\n",
       "  ('a', 'great', 'tutu'),\n",
       "  ('great', 'tutu', 'and'),\n",
       "  ('tutu', 'and', 'at'),\n",
       "  ('and', 'at', 'a'),\n",
       "  ('at', 'a', 'really'),\n",
       "  ('a', 'really', 'great'),\n",
       "  ('really', 'great', 'price'),\n",
       "  ('great', 'price', '.'),\n",
       "  ('price', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'it'),\n",
       "  ('<sos>', 'it', 'doesn'),\n",
       "  ('it', 'doesn', \"'\"),\n",
       "  ('doesn', \"'\", 't'),\n",
       "  (\"'\", 't', 'look'),\n",
       "  ('t', 'look', 'cheap'),\n",
       "  ('look', 'cheap', 'at'),\n",
       "  ('cheap', 'at', 'all'),\n",
       "  ('at', 'all', '.'),\n",
       "  ('all', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', 'i', \"'\"),\n",
       "  ('i', \"'\", 'm'),\n",
       "  (\"'\", 'm', 'so'),\n",
       "  ('m', 'so', 'glad'),\n",
       "  ('so', 'glad', 'i'),\n",
       "  ('glad', 'i', 'looked'),\n",
       "  ('i', 'looked', 'on'),\n",
       "  ('looked', 'on', 'amazon'),\n",
       "  ('on', 'amazon', 'and'),\n",
       "  ('amazon', 'and', 'found'),\n",
       "  ('and', 'found', 'such'),\n",
       "  ('found', 'such', 'an'),\n",
       "  ('such', 'an', 'affordable'),\n",
       "  ('an', 'affordable', 'tutu'),\n",
       "  ('affordable', 'tutu', 'that'),\n",
       "  ('tutu', 'that', 'isn'),\n",
       "  ('that', 'isn', \"'\"),\n",
       "  ('isn', \"'\", 't'),\n",
       "  (\"'\", 't', 'made'),\n",
       "  ('t', 'made', 'poorly'),\n",
       "  ('made', 'poorly', '.'),\n",
       "  ('poorly', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Smoothing (best to use in practice!) http://smithamilli.com/blog/kneser-ney/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM\n",
    "###  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood of a Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
    "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
    "\n",
    "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obviously\n",
      "obviously i\n",
      "obviously i like\n",
      "obviously i like the\n",
      "obviously i like the military\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'obviously i like the military'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers\n",
      "numbers letters\n",
      "numbers letters beside\n",
      "numbers letters beside the\n",
      "numbers letters beside the code\n",
      "numbers letters beside the code inside\n",
      "numbers letters beside the code inside the\n",
      "numbers letters beside the code inside the birkenstock\n",
      "numbers letters beside the code inside the birkenstock m\n",
      "numbers letters beside the code inside the birkenstock m width\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'numbers letters beside the code inside the birkenstock m width'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they\n",
      "they would\n",
      "they would fit\n",
      "they would fit his\n",
      "they would fit his face\n",
      "they would fit his face perfectly\n",
      "they would fit his face perfectly .\n",
      "they would fit his face perfectly . <\n",
      "they would fit his face perfectly . < fry\n",
      "they would fit his face perfectly . < fry parker\n",
      "they would fit his face perfectly . < fry parker lacked\n",
      "they would fit his face perfectly . < fry parker lacked cousteau\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors traveltime\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors traveltime doubloons\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors traveltime doubloons texsport\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors traveltime doubloons texsport racerback\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors traveltime doubloons texsport racerback invicta\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors traveltime doubloons texsport racerback invicta garner\n",
      "they would fit his face perfectly . < fry parker lacked cousteau favors traveltime doubloons texsport racerback invicta garner 32ddd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'they would fit his face perfectly . < fry parker lacked cousteau favors traveltime doubloons texsport racerback invicta garner 32ddd'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nylon\n",
      "nylon .\n",
      "nylon . <\n",
      "nylon . < sizes\n",
      "nylon . < sizes jlkasjdh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nylon . < sizes jlkasjdh'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expandable\n",
      "expandable pouch\n",
      "expandable pouch and\n",
      "expandable pouch and as\n",
      "expandable pouch and as expected\n",
      "expandable pouch and as expected .\n",
      "expandable pouch and as expected . <\n",
      "expandable pouch and as expected . < association\n",
      "expandable pouch and as expected . < association retard\n",
      "expandable pouch and as expected . < association retard recipient\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expandable pouch and as expected . < association retard recipient'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guy\n",
      "guy in\n",
      "guy in these\n",
      "guy in these shoes\n",
      "guy in these shoes .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'guy in these shoes .'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another\n",
      "another pair\n",
      "another pair of\n",
      "another pair of the\n",
      "another pair of the one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'another pair of the one'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'will', 'buy'))\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have\n",
      "have to\n",
      "have to spend\n",
      "have to spend on\n",
      "have to spend on socks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'have to spend on socks'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n",
      "like them\n",
      "like them ,\n",
      "like them , so\n",
      "like them , so maybe\n",
      "like them , so maybe i\n",
      "like them , so maybe i would\n",
      "like them , so maybe i would have\n",
      "like them , so maybe i would have been\n",
      "like them , so maybe i would have been my\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'like them , so maybe i would have been my'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "' m\n",
      "' m sending\n",
      "' m sending them\n",
      "' m sending them back\n",
      "' m sending them back .\n",
      "' m sending them back . <\n",
      "' m sending them back . < butterfly\n",
      "' m sending them back . < butterfly discount\n",
      "' m sending them back . < butterfly discount tell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"' m sending them back . < butterfly discount tell\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('this', 'is', 'the', 'best', 'i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "' d\n",
      "' d return\n",
      "' d return them\n",
      "' d return them .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"' d return them .\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('this', 'is', 'the', 'best', 'i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "really\n",
      "really have\n",
      "really have a\n",
      "really have a medical\n",
      "really have a medical tech\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'really have a medical tech'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('this', 'is', 'not', 'what', 'i'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Likelihood (n-gram)\n",
    "## $$LL = \\sum_{j=1}^{K} \\sum_{i=1}^{T_j + 1} log p_{bi}(w_{j, i} | w_{j, n - i + 1}, \\cdot, w_{j, i - 2}, w_{j, i - 1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "## $$PP = exp(-\\frac{LL}{\\sum_j(T_j + 1)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_train = train_ngram_lm.get_perplexity(train_data_tokenized)\n",
    "ppl_valid = train_ngram_lm.get_perplexity(valid_data_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.344511464794245e+16, 755.9738679208824)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_valid, ppl_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Compare Different Smoothing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.344511464794245e+16, 755.9738679208824)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No Smoothing\n",
    "train_ngram_lm_no_smoothing = NgramLM(train_data_tokenized, all_tokens_train, n=3)\n",
    "valid_ngram_lm_no_smoothing = NgramLM(valid_data_tokenized, all_tokens_valid, n=3)\n",
    "\n",
    "ppl_train_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_smoothing, ppl_train_no_smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2055.2872827189367, 1196.5775271595057)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='additive', delta=0.5)\n",
    "valid_ngram_lm_additive = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='additive', delta=0.5)\n",
    "\n",
    "ppl_train_no_additive = train_ngram_lm_additive.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_additive = train_ngram_lm_additive.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_additive, ppl_train_no_additive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1354.0482277379228, 613.5432288939794)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d2 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='additive', delta=0.2)\n",
    "valid_ngram_lm_additive_d2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='additive', delta=0.2)\n",
    "\n",
    "ppl_train_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_additive_d2, ppl_train_no_additive_d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2556.7182484112773, 1661.3470880508992)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d8 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='additive', delta=0.8)\n",
    "valid_ngram_lm_additive_d8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='additive', delta=0.8)\n",
    "\n",
    "ppl_train_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_additive_d8, ppl_train_no_additive_d8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2835.1739448877547, 1930.4604628361355)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_add1 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='add-one')\n",
    "valid_ngram_lm_add1 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='add-one')\n",
    "\n",
    "ppl_train_no_add1 = train_ngram_lm_add1.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_add1 = train_ngram_lm_add1.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_add1, ppl_train_no_add1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6102269887054972e+16, 3440.511236140074)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a2 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation', alpha=0.2)\n",
    "valid_ngram_lm_interp_a2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation', alpha=0.2)\n",
    "\n",
    "ppl_train_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp_a2, ppl_train_no_interp_a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.379670893386646e+16, 932.7257338927965)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a8 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation', alpha=0.8)\n",
    "valid_ngram_lm_interp_a8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation', alpha=0.8)\n",
    "\n",
    "ppl_train_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp_a8, ppl_train_no_interp_a8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4554610494634504e+16, 1451.9324109042982)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a5 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation', alpha=0.5)\n",
    "valid_ngram_lm_interp_a5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation', alpha=0.5)\n",
    "\n",
    "ppl_train_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp_a5, ppl_train_no_interp_a5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discounted Interpolation Smoothing\n",
    "# train_ngram_lm_discount = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='discounting')\n",
    "# valid_ngram_lm_discount = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='discounting')\n",
    "\n",
    "# ppl_train_no_discount = train_ngram_lm_discount.get_perplexity(train_data_tokenized)\n",
    "# ppl_valid_no_discount = train_ngram_lm_discount.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "# ppl_valid_no_discount, ppl_train_no_discount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary n from ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-cf839c185fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalid_ngram_lm_interp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgramLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tokens_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'interpolation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mppl_train_no_interp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ngram_lm_interp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mppl_valid_no_interp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ngram_lm_interp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ammi-2019-nlp/01-day-LM/utils/ngram_utils.py\u001b[0m in \u001b[0;36mget_perplexity\u001b[0;34m(self, test_sentences)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ammi-2019-nlp/01-day-LM/utils/ngram_utils.py\u001b[0m in \u001b[0;36mget_prob_sentence\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngram_sentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mprob_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ngram_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mprob\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mprob_ngram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ammi-2019-nlp/01-day-LM/utils/ngram_utils.py\u001b[0m in \u001b[0;36mget_ngram_prob\u001b[0;34m(self, ngram)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'interpolation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ngram_prob_interpolation_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'discounting'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ammi-2019-nlp/01-day-LM/utils/ngram_utils.py\u001b[0m in \u001b[0;36mget_ngram_prob_interpolation_smoothing\u001b[0;34m(self, ngram, alpha)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mall_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_subtrie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mprefixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mall_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefixes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall_counts\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/pygtrie.py\u001b[0m in \u001b[0;36mitems\u001b[0;34m(self, prefix, shallow)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0msee\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetailed\u001b[0m \u001b[0mdocumentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \"\"\"\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshallow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshallow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_SENTINEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshallow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/pygtrie.py\u001b[0m in \u001b[0;36miteritems\u001b[0;34m(self, prefix, shallow)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         for path, value in node.iterate(list(self.__path_from_key(prefix)),\n\u001b[0;32m--> 464\u001b[0;31m                                         shallow, self._iteritems):\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/pygtrie.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, path, shallow, iteritems)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_SENTINEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mshallow\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_SENTINEL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 2\n",
    "train_ngram_lm_interp2 = NgramLM(train_data_tokenized, all_tokens_train, n=2, smoothing='interpolation')\n",
    "valid_ngram_lm_interp2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=2, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp2 = train_ngram_lm_interp2.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp2 = train_ngram_lm_interp2.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp2, ppl_train_no_interp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 3\n",
    "train_ngram_lm_interp3 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation')\n",
    "valid_ngram_lm_interp3 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp3 = train_ngram_lm_interp3.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp3 = train_ngram_lm_interp3.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp3, ppl_train_no_interp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 5\n",
    "train_ngram_lm_interp5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='interpolation')\n",
    "valid_ngram_lm_interp5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp5 = train_ngram_lm_interp5.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp5 = train_ngram_lm_interp5.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp5, ppl_train_no_interp5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 10\n",
    "train_ngram_lm_interp10 = NgramLM(train_data_tokenized, all_tokens_train, n=10, smoothing='interpolation')\n",
    "valid_ngram_lm_interp10 = NgramLM(valid_data_tokenized, all_tokens_valid, n=10, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp10 = train_ngram_lm_interp10.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp10 = train_ngram_lm_interp10.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp10, ppl_train_no_interp10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 20\n",
    "train_ngram_lm_interp20 = NgramLM(train_data_tokenized, all_tokens_train, n=20, smoothing='interpolation')\n",
    "valid_ngram_lm_interp20 = NgramLM(valid_data_tokenized, all_tokens_valid, n=20, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp20 = train_ngram_lm_interp20.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_interp20 = train_ngram_lm_interp20.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_interp20, ppl_train_no_interp20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: do the above dor additive with delta 0.1 or smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 5\n",
    "train_ngram_lm_add5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='additive', delta=0.1)\n",
    "valid_ngram_lm_add5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='additive', delta=0.1)\n",
    "\n",
    "ppl_train_no_add5 = train_ngram_lm_add5.get_perplexity(train_data_tokenized)\n",
    "ppl_valid_no_add5 = train_ngram_lm_add5.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "ppl_valid_no_add5, ppl_train_no_add5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp3.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp5.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp10.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_add5.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp5.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp3.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_additive.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp2.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ngram-lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
