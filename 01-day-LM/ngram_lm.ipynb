{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "## Goal: compute a probabilty distribution over all possible sentences:\n",
    "\n",
    "\n",
    "## $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
    "\n",
    "## This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
    "\n",
    "## $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
    "\n",
    "## If we have N sentences, each of them with T words / tokens, then we want to max:\n",
    "\n",
    "## $$log p(W) = \\sum_{n = 1}^N \\sum_{i=1}^{T} log p(w_i | w_{<i})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model\n",
    "\n",
    "## Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
    "\n",
    "## Given a sequence of words $w$, we want to compute\n",
    "\n",
    "##  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
    "\n",
    "## Where $w_i$ is the i-th word of the sequence.\n",
    "\n",
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
    "\n",
    "## Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see this in Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "#: implement the neural LM with concat instead of summation -- so that you have a fixed input etc.\n",
    "# make a separate\n",
    "# create some slides with pictures maybe explaining the model visualizations -- line by line\n",
    "# get google cloud working\n",
    "# make it work on gpu\n",
    "# show them kenlm and how to use to do different stuff with it\n",
    "# use the same sentences to generation and testing etc.\n",
    "# explain perplexity\n",
    "# ngram, ff, rnn, rnn+attention\n",
    "# do sentence generation\n",
    "# do long sentences\n",
    "# compare different n-grams -- 2,3,more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: should we install as needed and import as needed or all at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run if you dont have it installed\n",
    "# !pip install more_itertools\n",
    "# !pip install spacy# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager\\\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCVSciOCAMZb"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/roberta/ParlAI', '/home/roberta/ParlAI', '/home/roberta/ParlAI', '/home/roberta/ammi-2019-nlp/01-day-LM', '/home/roberta/ammi-2019-nlp/01-day-LM', '/home/roberta/playground', '/home/roberta/general-value-function', '/home/roberta/general-value-function/baselines', '/home/roberta/general-value-function/mazebase', '/home/roberta/general-value-function/mazebase/mazebase', '/home/roberta/miniconda3/envs/ammi/lib/python37.zip', '/home/roberta/miniconda3/envs/ammi/lib/python3.7', '/home/roberta/miniconda3/envs/ammi/lib/python3.7/lib-dynload', '', '/home/roberta/miniconda3/envs/ammi/lib/python3.7/site-packages', '/home/roberta/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/extensions', '/home/roberta/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/roberta/ParlAI\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYs6AMs6AIre"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy\n",
    "import itertools\n",
    "from operator import itemgetter \n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "_tqdm = tqdm_notebook\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import re\n",
    "import more_itertools as mit  # not built-in package\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "from torchtext import vocab\n",
    "from collections import Counter\n",
    "import re\n",
    "from torchtext.data import TabularDataset \n",
    "import pandas\n",
    "import altair\n",
    "from parlai.core.torch_agent import TorchAgent, Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H20pktPiA63a",
    "outputId": "fb38d897-e889-4451-df77-9ca98eb266a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7dbd84f810>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create .txt files with the reviews\n",
    "\n",
    "# with open('../data/amazon_reviews_clothing_train.txt', 'w') as f:\n",
    "#     for review in train_reviews:\n",
    "#         for token in review:\n",
    "#             f.write(\"%s \" % token) \n",
    "#         f.write(\"\\n\")\n",
    "        \n",
    "# with open('../data/amazon_reviews_clothing_test.txt', 'w') as f:\n",
    "#     for review in test_reviews:\n",
    "#         for token in review:\n",
    "#             f.write(\"%s \" % token) \n",
    "#         f.write(\"\\n\")\n",
    "        \n",
    "# with open('../data/amazon_reviews_clothing_valid.txt', 'w') as f:\n",
    "#     for review in valid_reviews:\n",
    "#         for token in review:\n",
    "#             f.write(\"%s \" % token) \n",
    "#         f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from .txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "# split each review into the tokens that compose it\n",
    "# for review in reviews:\n",
    "#     train_data.append(review.split())\n",
    "    \n",
    "test_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_test.txt', 'r') as f:\n",
    "    test_data = [review for review in f.read().split('\\n') if review]\n",
    "# split each review into the tokens that compose it\n",
    "# for review in reviews:\n",
    "#     test_data.append(review.split())\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "# split each review into the tokens that compose it\n",
    "# for review in reviews:\n",
    "#     valid_data.append(review.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 222919, str, 184, str, 1)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(train_data), len(train_data), \\\n",
    "type(train_data[0]), len(train_data[0]), \\\n",
    "type(train_data[0][0]), len(train_data[0][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " 't')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')               \n",
    "punctuations = string.punctuation\n",
    "# punctuations = '\"#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~' \n",
    "TAG_RE = re.compile(r'<[^>]+>') # get rid off HTML tags from the data\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def lower_case(parsed):\n",
    "    return [token.text.lower() for token in parsed] #and (token.is_stop is False)]\n",
    "\n",
    "def remove_punc(parsed):\n",
    "    return [token.text for token in parsed if (token.text not in punctuations)]\n",
    "\n",
    "def lower_case_remove_punc(parsed):\n",
    "    return [token.text.lower() for token in parsed if (token.text not in punctuations)] #and (token.is_stop is False)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "   # tokenize each sentence -- each tokenized sentence will be an element in token_dataset\n",
    "    token_dataset = []\n",
    "    # tokenize all words -- each token will be an item in all_tokens (in the order given by the list of sentences)\n",
    "    all_tokens = []     # all the tokens -- \n",
    "\n",
    "    for sample in _tqdm(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=1)):\n",
    "#         tokens = lower_case_remove_punc(sample)\n",
    "        tokens = lower_case(sample)       # make words lower case\n",
    "#         tokens = remove_punct(tokens)     # remove punctuation\n",
    "        token_dataset.append(tokens)    \n",
    "        all_tokens += tokens\n",
    "        \n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~', '!', str, 32, str)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations, punctuations[0], \\\n",
    "type(punctuations), len(punctuations), type(punctuations[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'<[^>]+>', re.UNICODE)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAG_RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for now only work with small subset of the data -- switch to all data later\n",
    "train_data = train_data[:80]\n",
    "test_data = test_data[:10]\n",
    "valid_data = valid_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, str, str)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), type(train_data[0]), type(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f0fc13f09b4420adea03a46d49e3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bbfba88ca047b0805014be57ae8d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c8a02b696d4916954691f80aa800d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = tokenize_dataset(train_data)\n",
    "test_data_tokenized, all_tokens_test = tokenize_dataset(test_data)\n",
    "valid_data_tokenized, all_tokens_valid = tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14771,\n",
       " 'this',\n",
       " 80,\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'tutu',\n",
       "  'and',\n",
       "  'at',\n",
       "  'a',\n",
       "  'really',\n",
       "  'great',\n",
       "  'price',\n",
       "  '.',\n",
       "  'it',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'look',\n",
       "  'cheap',\n",
       "  'at',\n",
       "  'all',\n",
       "  '.',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'so',\n",
       "  'glad',\n",
       "  'i',\n",
       "  'looked',\n",
       "  'on',\n",
       "  'amazon',\n",
       "  'and',\n",
       "  'found',\n",
       "  'such',\n",
       "  'an',\n",
       "  'affordable',\n",
       "  'tutu',\n",
       "  'that',\n",
       "  'isn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'made',\n",
       "  'poorly',\n",
       "  '.',\n",
       "  'a',\n",
       "  '+',\n",
       "  '+'])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of All Tokens\n",
    "len(all_tokens_train), all_tokens_train[0], \\\n",
    "len(train_data_tokenized), train_data_tokenized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 2091 words\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
    "voc = list(set(all_tokens_train))\n",
    "print('Word vocabulary size: {} words'.format(len(voc)))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS ANALYSIS (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tokens in the Corpus Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Tokens  14771\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All Tokens \", len(all_tokens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All UNIQUE Tokens  2091\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All UNIQUE Tokens \", len(voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences in the Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences  80\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Sentences \", len(train_data_tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentences(input_list, n):\n",
    "    result_list = []\n",
    "    for l in input_list:\n",
    "        padded = [\"<bos>\" for i in range((n - 1))] + l +[\"<eos>\" for i in range((n - 1))]\n",
    "        result_list.append(padded)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sentences(train_data_tokenized, n)\n",
    "valid_padded = pad_sentences(valid_data_tokenized, n)\n",
    "test_padded = pad_sentences(test_data_tokenized, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_padded[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for finding all N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    result_list = []\n",
    "    for l in input_list:\n",
    "        result_list.append(list(zip(*[l[i:] for i in range(n)])))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ngram[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Getting N-gram counts for already tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_counts(data, n, frac_vocab=0.9):    \n",
    "    all_train_tokens = list(mit.flatten(data))\n",
    "    counted_tokens = Counter(all_train_tokens)\n",
    "    max_vocab_size = int(frac_vocab * len(counted_tokens))\n",
    "\n",
    "    vocab, count = zip(*counted_tokens.most_common(max_vocab_size))\n",
    "    \n",
    "    return vocab, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram = find_ngrams(train_padded, n)\n",
    "vocab_trigram, count_trigram = ngram_counts(train_ngram, n)\n",
    "vocab_trigram, count_trigram = ngram_counts(train_ngram, n)\n",
    "vocab_ngram, count_ngram = ngram_counts(train_ngram, n)\n",
    "# train_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_ngram[:3], count_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1 \n",
    "BOS_IDX = 2\n",
    "EOS_IDX = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Getting N-gram Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_dict(vocab):\n",
    "    PAD_IDX = 0\n",
    "    UNK_IDX = 1 \n",
    "    BOS_IDX = 2\n",
    "    EOS_IDX = 3\n",
    "    \n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(4, 4+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>', '<bos>', '<eos>'] + id2token\n",
    "\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    token2id['<bos>'] = BOS_IDX \n",
    "    token2id['<eos>'] = EOS_IDX\n",
    "\n",
    "    return id2token, token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_ngram, token2id_ngram = ngram_dict(vocab_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<pad>',\n",
       "  '<unk>',\n",
       "  '<bos>',\n",
       "  '<eos>',\n",
       "  ('.', '<eos>', '<eos>'),\n",
       "  ('it', \"'\", 's'),\n",
       "  ('.', '.', '.'),\n",
       "  ('i', \"'\", 'm'),\n",
       "  ('<bos>', '<bos>', 'i'),\n",
       "  ('don', \"'\", 't')],)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token_ngram[:10], \\\n",
    "# token2id_ngram['<unk>'], token2id_ngram['<eos>'], token2id_ngram[('rosetta', 'stone')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 10249 ; token (',', 'hello', ',')\n",
      "Token (',', 'hello', ','); token id 10249\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
    "random_token = id2token_ngram[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _text2id(doc, token2id):\n",
    "    return [token2id[t] if t in token2id else UNK_IDX for t in doc]\n",
    "\n",
    "def _id2text(vec, id2token):\n",
    "    return [id2token[i] for i in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_id(data, token2id):\n",
    "    data_id = []\n",
    "    for d in data:\n",
    "        data_id.append(_text2id(d, token2id))\n",
    "    return data_id\n",
    "\n",
    "def create_data_id_merged(data, token2id, n):\n",
    "    data_id_merged = []\n",
    "    for d in data:\n",
    "        for i in range(len(d) - n):\n",
    "            data_id_merged.append((d[i:i+n], d[i+n]))\n",
    "    return data_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "train_padded_uni = pad_sentences(train_data_tokenized, n)\n",
    "train_unigram = find_ngrams(train_padded_uni, n)\n",
    "vocab_unigram, count_unigram = ngram_counts(train_unigram, n)\n",
    "id2token_unigram, token2id_unigram = ngram_dict(vocab_unigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "data_id = create_data_id(train_unigram, token2id_unigram)\n",
    "data_id_merged = create_data_id_merged(data_id, token2id_unigram, n)\n",
    "\n",
    "train_data_id = data_id\n",
    "train_data_id_merged = data_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram = find_ngrams(valid_padded, n)\n",
    "# valid_data_id = create_data_id(valid_ngram, token2id_ngram)\n",
    "# valid_data_id_merged = create_data_id_merged(valid_data_id, token2id_ngramn, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data_id), data_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data_id_merged), data_id_merged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that combines all the aboce and goes from tokenized data to the ngram dataset\n",
    "def create_id_dataset(data, n):\n",
    "    padded_data = pad_sentences(data, n)\n",
    "    ngram_data = find_ngrams(padded_data, n)\n",
    "    \n",
    "    vocab, count = ngram_counts(ngram_data, n)    \n",
    "    id2token, token2id = ngram_dict(vocab)\n",
    "    \n",
    "    data_id = create_data_id(ngram_data, token2id)\n",
    "    data_id_merged = create_data_id_merged(data_id, token2id, n)\n",
    "    \n",
    "    return data_id, data_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_id, all_data_id_merged = create_id_dataset(train_data_tokenized, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_id[0], all_data_id_merged[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing the probability of an n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('it', \"'\", 's'),\n",
       "  ('.', '.', '.'),\n",
       "  ('i', \"'\", 'm'),\n",
       "  ('<bos>', '<bos>', 'i'),\n",
       "  ('don', \"'\", 't'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('i', \"'\", 've'),\n",
       "  ('.', 'i', \"'\"),\n",
       "  ('you', \"'\", 're')),\n",
       " (59, 40, 33, 26, 23, 23, 14, 14, 13, 13))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[:10], count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_count(ngram, vocab, count):\n",
    "    if ngram in vocab:\n",
    "        ngram_idx = vocab.index(ngram)\n",
    "        return count[ngram_idx] \n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = get_ngram_count(('.', 'i'), vocab_ngram, count_ngram)\n",
    "c\n",
    "\n",
    "# c = get_ngram_count(('baby', 'panda'), vocab_ngram, count_ngram)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = get_ngram_count(('it', \"'\", 's'), vocab_ngram, count_ngram)\n",
    "c\n",
    "\n",
    "\n",
    "# c = get_ngram_count(('baby', 'panda', 'sweet'), vocab_ngram, count_ngram)\n",
    "# c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing the probability of a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w|w_{−n}, ..., w_{−2}, w_{−1}) \\approx \\frac{c(w_{−n}, ..., w_{−2}, w_{−1}, w)}{\\sum_{w \\in V} c(w_{−n}, ..., w_{−2}, w_{−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob(ngram, vocab, count):\n",
    "    c = get_ngram_count(ngram, vocab, count)\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "#             print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    if all_counts > 0:\n",
    "        return c / all_counts\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities\n",
    "\n",
    "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.8846153846153846)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = get_ngram_prob(('rosetta', 'stone'), vocab_ngram, count_ngram)\n",
    "p, 69/(69+2+2+1+1+1+1+1)\n",
    "\n",
    "# p = get_ngram_prob(('i', 'am'), vocab_ngram, count_ngram)\n",
    "# p\n",
    "\n",
    "# p = get_ngram_prob(('it', \"'\", 's'), vocab_ngram, count_ngram)\n",
    "# p\n",
    "\n",
    "# p = get_ngram_prob(('i', \"like\", 'it'), vocab_ngram, count_ngram)\n",
    "# p, 1/(2+1+1+1+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob_add_one_smoothing(ngram, vocab, count):\n",
    "    c = get_ngram_count(ngram, vocab, count) + 1\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "            print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    all_counts += len(voc)\n",
    "    if all_counts > 0:\n",
    "        return c / all_counts\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: show examples\n",
    "p = get_ngram_prob(('am', 'rosetta', 'stone'), vocab_ngram, count_ngram)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00047824007651841227"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = get_ngram_prob_add_one_smoothing(('am', 'rosetta', 'stone'), vocab_ngram, count_ngram)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob_addditive_smoothing(ngram, vocab, count, delta=0.5):\n",
    "    c = get_ngram_count(ngram, vocab, count) + delta*1\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "#             print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    all_counts += delta*len(voc)\n",
    "    if all_counts > 0:\n",
    "        return c / all_counts\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004782400765184122"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = get_ngram_prob_addditive_smoothing(('am', 'rosetta', 'stone'), vocab_ngram, count_ngram, delta=0.1)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob_interpolation_smoothing(ngram, vocab, count, prev_vocab, prev_count, alpha=0.5):\n",
    "    c = get_ngram_count(ngram, vocab, count)\n",
    "    all_counts = 0\n",
    "    for t in vocab:\n",
    "        if t[:-1] == ngram[:-1]:\n",
    "#             print(t, get_ngram_count(t, vocab, count))\n",
    "            all_counts += get_ngram_count(t, vocab, count)\n",
    "    if all_counts > 0:\n",
    "        prob_ngram = c / all_counts\n",
    "    else:\n",
    "        prob_ngram = 0\n",
    "    \n",
    "    prev_ngram = tuple(list(ngram[1:]))\n",
    "    prev_c = get_ngram_count(prev_ngram, prev_vocab, prev_count)\n",
    "#     print(prev_c)\n",
    "    prev_all_counts = 0\n",
    "    for prev_t in prev_vocab:\n",
    "        if prev_t[:-1] == prev_ngram[:-1]:\n",
    "#             print(prev_t, get_ngram_count(prev_t, prev_vocab, prev_count))\n",
    "            prev_all_counts += get_ngram_count(prev_t, prev_vocab, prev_count)\n",
    "    if prev_all_counts > 0:\n",
    "        prob_prev_ngram = prev_c / prev_all_counts\n",
    "    else:\n",
    "        0\n",
    "    return alpha*(prob_ngram) + (1-alpha)*prob_prev_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sentences(train_data_tokenized, 3)\n",
    "train_trigram = find_ngrams(train_padded, 3)\n",
    "vocab_trigram, count_trigram = ngram_counts(train_trigram, 3)\n",
    "\n",
    "\n",
    "train_padded = pad_sentences(train_data_tokenized, 2)\n",
    "train_bigram = find_ngrams(train_padded, 2)\n",
    "vocab_bigram, count_bigram = ngram_counts(train_bigram, 2)\n",
    "\n",
    "train_padded = pad_sentences(train_data_tokenized, 1)\n",
    "train_unigram = find_ngrams(train_padded, 1)\n",
    "vocab_unigram, count_unigram = ngram_counts(train_unigram, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing: Linear Interpolation with Absolute Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
    "\n",
    "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
    "\n",
    "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
    "\n",
    "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
    "\n",
    "\n",
    "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
    "\n",
    "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
    "\n",
    "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
    "\n",
    "### V is the number of words in the vocabulary\n",
    "\n",
    "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_count(r):\n",
    "    return np.sum([1 for i in range(len(vocab_unigram)) if count_unigram[i] == r])\n",
    "\n",
    "def get_bigram_count(r):\n",
    "    return np.sum([1 for i in range(len(vocab_bigram)) if count_bigram[i] == r])\n",
    "\n",
    "def get_biunigram_count(r, token):\n",
    "    cc = 0\n",
    "    for other_token in vocab_unigram:\n",
    "        bigram = tuple([token] + [other_token])\n",
    "        if bigram in vocab_bigram:\n",
    "            bigram_idx = vocab_bigram.index(bigram) \n",
    "            if count_bigram[bigram_idx] == r:\n",
    "                cc += 1\n",
    "                \n",
    "#     for bigram in vocab_bigram:\n",
    "#         print(token, bigram[0])\n",
    "#         if token == bigram[0]:\n",
    "#             bigram_idx = vocab_bigram.index(bigram) \n",
    "#             if count_bigram[bigram_idx] == r:\n",
    "#                 cc += 1\n",
    "    return cc\n",
    "\n",
    "def get_b_bi():\n",
    "    bbi = get_bigram_count(1) / (get_bigram_count(1) + 2 * get_bigram_count(2))\n",
    "    return bbi\n",
    "    \n",
    "def get_b_uni():\n",
    "    buni = get_unigram_count(1) / (get_unigram_count(1) + 2 * get_unigram_count(2))\n",
    "    return buni\n",
    "\n",
    "def get_p_uni(w):\n",
    "    if w in vocab_unigram:\n",
    "        w_idx = vocab_unigram.index(w)\n",
    "        N_w = count_unigram[w_idx]\n",
    "    else:\n",
    "        N_w = 0\n",
    "        \n",
    "    b_uni = get_b_uni()\n",
    "    \n",
    "    W = len(voc)\n",
    "    N_0 = get_unigram_count(0)\n",
    "    \n",
    "    \n",
    "    N = len(all_tokens_train) # TODO: double check the meaning of N \n",
    "    \n",
    "    p_uni = max((N_w - b_uni / N), 0) + b_uni * (W - N_0) / N * 1 / W\n",
    "    \n",
    "    return p_uni\n",
    "\n",
    "def get_p_bi(w, v):   # w given v\n",
    "    if tuple([v] + [w]) in vocab_bigram:\n",
    "        vw_idx = vocab_bigram.index(tuple([v] + [w]))\n",
    "        N_vw = count_bigram[vw_idx]\n",
    "    else:\n",
    "        N_vw = 0\n",
    "        \n",
    "    if tuple([v]) in vocab_unigram:\n",
    "        v_idx = vocab_unigram.index(tuple([v]))\n",
    "        N_v = count_unigram[v_idx]\n",
    "    else:\n",
    "        N_v = 0  \n",
    "        \n",
    "    b_bi = get_b_bi()\n",
    "    b_uni = get_b_uni()\n",
    "    \n",
    "    p_uni = get_p_uni(tuple([w]))\n",
    "    \n",
    "    W = len(voc)\n",
    "    N_0 = get_biunigram_count(0, v)\n",
    "    \n",
    "    \n",
    "    p_bi =  max((N_vw - b_bi) / N_v,  0) + \\\n",
    "         b_bi * (W - N_0) / N_v * p_uni\n",
    "    \n",
    "    return p_bi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1744.7693023255813"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'stone'\n",
    "y = 'rosetta'\n",
    "\n",
    "z = get_p_bi(y, x)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check that the probabilities sum up to one\n",
    "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram LM\n",
    "##  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood of a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_sentence(sentence, vocab, count):\n",
    "    padded_sentence = pad_sentences(sentence, n)  # needs a list\n",
    "#     print(padded_sentence)\n",
    "    ngram_sentence = find_ngrams(padded_sentence, n)[0] # only one element in list\n",
    "#     print(ngram_sentence)\n",
    "    prob = 1\n",
    "    for ngram in ngram_sentence:\n",
    "        prob_ngram = get_ngram_prob(ngram, vocab, count)\n",
    "#         print(ngram, prob_ngram)\n",
    "        prob *= prob_ngram\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.', 'it', 'doesn', \"'\", 't', 'look', 'cheap', 'at', 'all', '.', 'i', \"'\", 'm', 'so', 'glad', 'i', 'looked', 'on', 'amazon', 'and', 'found', 'such', 'an', 'affordable', 'tutu', 'that', 'isn', \"'\", 't', 'made', 'poorly', '.', 'a', '+', '+']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0055998183675866e-17"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [train_data_tokenized[0]]\n",
    "# sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = get_prob_sentence(sentence, vocab_ngram, count_ngram)\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
    "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
    "\n",
    "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example -- where this approach usually fails\n",
    "\n",
    "### Bigram LM: $$ p(john \\; went \\; to \\; the \\; moon) = p(john|\\cdot) p(went|john) p(to|went) p(the|to) p(moon|the)$$ \n",
    "\n",
    "### Trigram LM: $$ pp(john \\; went \\; to \\; the \\; moon = p(john|\\cdot, \\cdot) p(went|\\cdot, john) p(to|john, went) p(the|went, to) p(moon|to, the)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_distr_ngram(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=False):\n",
    "    pd = [0 for v in voc]\n",
    "    for idx, token in enumerate(voc):\n",
    "#         print(\"token: \", token)\n",
    "#         print(\"prev ngram: \", prev_tokens)\n",
    "#         print(\"both: \", tuple(list(prev_tokens) + [token]))\n",
    "#         print(\"\")\n",
    "        token_ngram = tuple(list(prev_tokens) + [token])\n",
    "        pd[idx] = get_ngram_prob(token_ngram, vocab_ngram, count_ngram)\n",
    "#         if pd[idx] > 0 and print_nonzero_probs:\n",
    "#             print(token_ngram, \" \", pd[idx])\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"'\", 'm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prob distr for the word following prev_tokens (i.e. tutu) \n",
    "# over all the words in the vocabulary \n",
    "\n",
    "# prev_tokens = train_data_tokenized[0][4] #[0]\n",
    "prev_tokens = vocab_ngram[3][1:] #[0]   # need frmo 1 on so that this is a correct prev token\n",
    "print(prev_tokens)\n",
    "pd = get_prob_distr_ngram(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=True)\n",
    "sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_pd(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=False):\n",
    "    pd = get_prob_distr_ngram(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=print_nonzero_probs)\n",
    "    idx_next_token = np.random.choice(len(voc), 1, p=pd)[0]\n",
    "    return voc[idx_next_token]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"'\", 'm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'not'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prev_tokens)\n",
    "next_token = sample_from_pd(prev_tokens, vocab_ngram, count_ngram, voc, print_nonzero_probs=True)\n",
    "next_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(num_tokens, vocab_ngram, count_ngram, voc, n):\n",
    "    sentence = []\n",
    "    prev_tokens = tuple(['<bos>'] * (n - 1))\n",
    "#     print(prev_tokens)\n",
    "    for i in range(num_tokens):\n",
    "        next_token = sample_from_pd(prev_tokens, vocab_ngram, count_ngram, voc)\n",
    "#         print(i, next_token)\n",
    "#         print(i, prev_tokens[1:])\n",
    "        prev_tokens = tuple(list(prev_tokens[1:]) + [next_token])\n",
    "#         print(i, prev_tokens)\n",
    "        sentence.append(next_token)\n",
    "        print(' '.join(sentence))\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never\n",
      "never having\n",
      "never having studied\n",
      "never having studied italian\n",
      "never having studied italian before\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'never having studied italian before'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = generate_sentence(num_tokens, vocab_ngram, count_ngram, voc, n)\n",
    "generated_sentence\n",
    "\n",
    "# TODO: make this owkr for general ngram -- double check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the sums\n",
    "# show rank for each word in a sentence\n",
    "# explain perplexity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Likelihood\n",
    "### $LL = \\sum_{k=1}^{K} \\sum_{n=1}^{N_k + 1} log p_{bi}(w_{k,n} | w_{k,n-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $PP = exp(-\\frac{LL}{\\sum_k(N_k + 1)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(test_sentences, vocab_ngram, count_ngram):\n",
    "    ll = 0\n",
    "    num_tokens = 0\n",
    "    for s in (test_sentences):\n",
    "        ll += get_prob_sentence([s], vocab_ngram, count_ngram)\n",
    "        num_tokens += len(s) + 1\n",
    "\n",
    "    ppl = np.exp(-ll/num_tokens)\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_test = get_perplexity(test_data_tokenized, vocab_ngram, count_ngram)\n",
    "ppl_valid = get_perplexity(valid_data_tokenized, vocab_ngram, count_ngram)\n",
    "ppl_train = get_perplexity(train_data_tokenized, vocab_ngram, count_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.9999999993885841)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_test, ppl_valid, ppl_train\n",
    "# TODO check whether this makes sense -- maybe it seems too good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at some examples and see if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a PyTorch Dataset out of our set of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, data_list, max_inp_length=None, cuda=True):\n",
    "        \"\"\"\n",
    "        data_list is a list of tuples: (x,y) where x is a list of ids and y is a label\n",
    "        \"\"\"\n",
    "        self.data = data_list\n",
    "        self.max_len = max_inp_length\n",
    "        self.data_tensors = []\n",
    "        for (i, t) in tqdm_notebook(self.data):\n",
    "            if cuda:\n",
    "                self.data_tensors.append((torch.LongTensor(i[:self.max_len]).cuda(), \\\n",
    "                                            torch.LongTensor([t]).cuda()))\n",
    "            else:\n",
    "                self.data_tensors.append((torch.LongTensor(i[:self.max_len]), \\\n",
    "                                          torch.LongTensor([t])))\n",
    "                \n",
    "    def __getitem__(self, key):\n",
    "        (inp, tgt) = self.data_tensors[key]\n",
    "        \n",
    "        return inp, tgt, len(inp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def pad(tensor, length, dim=0, pad=0):\n",
    "    \"\"\"Pad tensor to a specific length.\n",
    "    :param tensor: vector to pad\n",
    "    :param length: new length\n",
    "    :param dim: (default 0) dimension to pad\n",
    "    :returns: padded tensor if the tensor is shorter than length\n",
    "    \"\"\"\n",
    "    if tensor.size(dim) < length:\n",
    "        return torch.cat(\n",
    "            [tensor, tensor.new(*tensor.size()[:dim],\n",
    "                                length - tensor.size(dim),\n",
    "                                *tensor.size()[dim + 1:]).fill_(pad)],\n",
    "            dim=dim)\n",
    "    else:\n",
    "        return tensor\n",
    "    \n",
    "def batchify(batch):\n",
    "    maxlen = max(batch, key = itemgetter(2))[-1]\n",
    "    batch_list = []\n",
    "    target_list = []\n",
    "    for b in batch:\n",
    "        batch_list.append(pad(b[0], maxlen, dim=0, pad=PAD_IDX))\n",
    "        target_list.append(b[1])\n",
    "    input_batch = torch.stack(batch_list, 0)\n",
    "    target_batch = torch.stack(target_list, 0)\n",
    "    \n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_id(data, token2id):\n",
    "    data_id = []\n",
    "    for d in data:\n",
    "        data_id.append(_text2id(d, token2id))\n",
    "    return data_id\n",
    "\n",
    "def create_data_id_merged(data, token2id, n):\n",
    "    data_id_merged = []\n",
    "    for d in data:\n",
    "        for i in range(len(d) - n):\n",
    "            data_id_merged.append((d[i:i+n], d[i+n]))\n",
    "    return data_id_merged\n",
    "\n",
    "n = 1\n",
    "train_padded_uni = pad_sentences(train_data_tokenized, n)\n",
    "train_unigram = find_ngrams(train_padded_uni, n)\n",
    "train_vocab_unigram, train_count_unigram = ngram_counts(train_unigram, n)\n",
    "train_id2token_unigram, train_token2id_unigram = ngram_dict(train_vocab_unigram)\n",
    "\n",
    "n = 1\n",
    "valid_padded_uni = pad_sentences(valid_data_tokenized, n)\n",
    "valid_unigram = find_ngrams(valid_padded_uni, n)\n",
    "valid_vocab_unigram, count_unigram = ngram_counts(valid_unigram, n)\n",
    "valid_id2token_unigram, valid_token2id_unigram = ngram_dict(valid_vocab_unigram)\n",
    "\n",
    "N = 10\n",
    "train_data_id = create_data_id(train_unigram, train_token2id_unigram)\n",
    "train_data_id_merged = create_data_id_merged(train_data_id, train_token2id_unigram, N)\n",
    "\n",
    "valid_data_id = create_data_id(valid_unigram, valid_token2id_unigram)\n",
    "valid_data_id_merged = create_data_id_merged(valid_data_id, valid_token2id_unigram, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5037cbd7115a48ab9ce70d2fa6f76fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-375-5ec431ac5718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmazonDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_id_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_inp_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmazonDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_id_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_inp_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-373-3de50e31394a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_list, max_inp_length, cuda)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 self.data_tensors.append((torch.LongTensor(i[:self.max_len]).cuda(), \\\n\u001b[0m\u001b[1;32m     12\u001b[0m                                             torch.LongTensor([t]).cuda()))\n\u001b[1;32m     13\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "train_dataset = AmazonDataset(train_data_id_merged, max_inp_length=None, cuda=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, collate_fn=batchify, shuffle=True)\n",
    "\n",
    "valid_dataset = AmazonDataset(valid_data_id_merged, max_inp_length=None, cuda=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, collate_fn=batchify, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_default_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "train_dataset[0], train_dataset[0][0].shape, \\\n",
    "valid_dataset[0], valid_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ATBQ4WaJR93"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-369-afb49e2b80e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBagOfNGrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_id2token_unigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "class BagOfNGrams(nn.Module):\n",
    "    def init_layers(self):\n",
    "        for l in self.layers:\n",
    "            if getattr(l, 'weight', None) is not None:\n",
    "                torch.nn.init.xavier_uniform_(l.weight)\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim=300, hidden_size=256, out_size=128, reduce='sum', nlayers=2, activation='ReLU', dropout=0.1, batch_norm=False):\n",
    "        super(BagOfNGrams, self).__init__()\n",
    "       \n",
    "        self.emb_dim = emb_dim\n",
    "        self.reduce = reduce\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = getattr(nn, activation)\n",
    "        \n",
    "        self.embedding = nn.EmbeddingBag(num_embeddings=vocab_size, embedding_dim=emb_dim, mode=reduce)\n",
    "        if batch_norm is True:\n",
    "            self.batch_norm = nn.BatchNorm1d(self.emb_dim)\n",
    "        self.layers = nn.ModuleList([nn.Linear(self.emb_dim, self.hidden_size)])\n",
    "        self.layers.append(self.activation())\n",
    "        self.layers.append(nn.Dropout(p=dropout))\n",
    "        \n",
    "        for i in range(self.nlayers-2):\n",
    "            self.layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            self.layers.append(self.activation())\n",
    "            self.layers.append(nn.Dropout(p=dropout)) \n",
    "        self.layers.append(nn.Linear(self.hidden_size, self.out_size))\n",
    "        self.init_layers()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        postemb = self.embedding(x)\n",
    "        if hasattr(self, 'batch_norm'):\n",
    "            x = self.batch_norm(postemb)\n",
    "        else:\n",
    "            x = postemb\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = BagOfNGrams(len(train_id2token_unigram), emb_dim=300, hidden_size=256, out_size=128, activation='Tanh', nlayers=1, reduce='mean', dropout=0.0, batch_norm=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderMLP(nn.Module):\n",
    "    \"\"\"Generates a token in response to context.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size=128, output_size=1024, hidden_size=256):\n",
    "        \"\"\"Initialize decoder.\n",
    "        :param input_size: size of embedding\n",
    "        :param output_size: size of vocabulary\n",
    "        :param hidden_size: size of the linear layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"Return encoded state.\n",
    "        :param input: batch_size x 1 tensor of token indices.\n",
    "        :param hidden: past (e.g. encoder) hidden state\n",
    "        \"\"\"\n",
    "        emb = self.embedding(input)\n",
    "        rel = F.relu(emb)\n",
    "        output = self.linear(rel)\n",
    "        scores = self.softmax(self.out(output))\n",
    "        return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, bag_of_ngrams, decoder, lr = 1e-3, use_cuda = True, \n",
    "                        hiddensize = 128, numlayers = 2, target_lang = None, longest_label = 20, \n",
    "                        clip = 0.3):\n",
    "        super(seq2seq, self).__init__()\n",
    "\n",
    "        device = torch.device(\"cuda\" if (torch.cuda.is_available() and use_cuda) else \"cpu\")\n",
    "        self.device = device;\n",
    "        self.bag_of_ngrams = bag_of_ngrams.to(device);\n",
    "        self.decoder = decoder.to(device)\n",
    "\n",
    "        self.target_lang = target_lang;\n",
    "\n",
    "        self.bl = bleu_score.BLEU_SCORE()\n",
    "\n",
    "        # set up the criterion\n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "        self.optims = {\n",
    "             'nmt': optim.SGD(self.parameters(), lr=lr, nesterov=True, momentum = 0.99)\n",
    "        }\n",
    "\n",
    "        self.scheduler = {};\n",
    "        for x in self.optims.keys():\n",
    "            self.scheduler[x] = ReduceLROnPlateau(self.optims[x], mode = 'max', min_lr=1e-4,  patience=0, verbose = True);\n",
    "\n",
    "        self.longest_label = longest_label\n",
    "        self.hiddensize = hiddensize\n",
    "        self.numlayers = numlayers\n",
    "        self.clip = clip;\n",
    "        self.START = torch.LongTensor([global_variables.SOS_token]).to(device)\n",
    "        self.END_IDX = global_variables.EOS_token;\n",
    "\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Zero out optimizer.\"\"\"\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def update_params(self):\n",
    "        \"\"\"Do one optimization step.\"\"\"\n",
    "        if self.clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.bag_of_ngrams.parameters(), self.clip)\n",
    "            torch.nn.utils.clip_grad_norm_(self.decoder.parameters(), self.clip)\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "\n",
    "    def scheduler_step(self, val_bleu):\n",
    "        for scheduler in self.scheduler.values():\n",
    "            scheduler.step(val_bleu)\n",
    "\n",
    "\n",
    "    def v2t(self, vector):\n",
    "        \"\"\"Convert vector to text.\n",
    "        :param vector: tensor of token indices.\n",
    "            1-d tensors will return a string, 2-d will return a list of strings\n",
    "        \"\"\"\n",
    "        if vector.dim() == 1:\n",
    "            output_tokens = []\n",
    "            # Remove the final END_TOKEN that is appended to predictions\n",
    "            for token in vector:\n",
    "                if token == self.END_IDX:\n",
    "                    break\n",
    "                else:\n",
    "                    output_tokens.append(token)\n",
    "            return self.target_lang.vec2txt(output_tokens)\n",
    "\n",
    "        elif vector.dim() == 2:\n",
    "            return [self.v2t(vector[i]) for i in range(vector.size(0))]\n",
    "        raise RuntimeError('Improper input to v2t with dimensions {}'.format(\n",
    "            vector.size()))\n",
    "        \n",
    "    def train_step(self, data, labels):\n",
    "        \"\"\"Train model to produce ys given xs.\n",
    "        :param batch: parlai.core.torch_agent.Batch, contains tensorized\n",
    "                      version of observations.\n",
    "        Return estimated responses, with teacher forcing on the input sequence\n",
    "        (list of strings of length batchsize).\n",
    "        \"\"\"\n",
    "        xs = data\n",
    "        ys = labels\n",
    "        \n",
    "        if xs is None:\n",
    "            return\n",
    "        xs = xs.to(self.device)\n",
    "        ys = ys.to(self.device)\n",
    "\n",
    "        bsz = xs.size(0)\n",
    "        starts = self.START.expand(bsz, 1)  # expand to batch size\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.bag_of_ngrams.train()\n",
    "        self.decoder.train()\n",
    "        target_length = ys.size(1)\n",
    "        # save largest seen label for later\n",
    "        self.longest_label = max(target_length, self.longest_label)\n",
    "\n",
    "        _encoder_output, encoder_hidden = self.bad_ngrams(xs)\n",
    "\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        y_in = ys.narrow(1, 0, ys.size(1) - 1)\n",
    "        decoder_input = torch.cat([starts, y_in], 1)\n",
    "        decoder_output, decoder_hidden = self.decoder(decoder_input,\n",
    "                                                      encoder_hidden)\n",
    "\n",
    "        scores = decoder_output.view(-1, decoder_output.size(-1))\n",
    "        loss = self.criterion(scores, ys.view(-1))\n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "\n",
    "        _max_score, predictions = decoder_output.max(2)\n",
    "        return self.v2t(predictions), loss.item() \n",
    "\n",
    "    def eval_step(self, data, labels):\n",
    "        \"\"\"Generate a response to the input tokens.\n",
    "        :param batch: parlai.core.torch_agent.Batch, contains tensorized\n",
    "                      version of observations.\n",
    "        Return predicted responses (list of strings of length batchsize).\n",
    "        \"\"\"\n",
    "        xs = data\n",
    "\n",
    "        if xs is None:\n",
    "            return\n",
    "\n",
    "        xs = xs.to(self.device)\n",
    "\n",
    "        bsz = xs.size(0)\n",
    "        starts = self.START.expand(bsz, 1)  # expand to batch size\n",
    "        # just predict\n",
    "        self.bag_of_ngrams.eval()\n",
    "        self.decoder.eval()\n",
    "        _encoder_output = self.bag_of_ngrams(xs)\n",
    "\n",
    "        predictions = []\n",
    "        done = [False for _ in range(bsz)]\n",
    "        total_done = 0\n",
    "        decoder_input = starts\n",
    "\n",
    "        for _ in range(self.longest_label):\n",
    "            # generate at most longest_label tokens\n",
    "            decoder_output = self.decoder(decoder_input)\n",
    "            _max_score, preds = decoder_output.max(2)\n",
    "            predictions.append(preds)\n",
    "            decoder_input = preds  # set input to next step\n",
    "\n",
    "            # check if we've produced the end token\n",
    "            for b in range(bsz):\n",
    "                if not done[b]:\n",
    "                    # only add more tokens for examples that aren't done\n",
    "                    if preds[b].item() == self.END_IDX:\n",
    "                        # if we produced END, we're done\n",
    "                        done[b] = True\n",
    "                        total_done += 1\n",
    "            if total_done == bsz:\n",
    "                # no need to generate any more\n",
    "                break\n",
    "        predictions = torch.cat(predictions, 1)\n",
    "        return self.v2t(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-372-a8c0f67d8e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbag_of_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBagOfNGrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_id2token_unigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_id2token_unigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag_of_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-371-418159da8c9d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bag_of_ngrams, decoder, lr, use_cuda, hiddensize, numlayers, target_lang, longest_label, clip)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbag_of_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_ngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "bag_of_ngrams = BagOfNGrams(len(train_id2token_unigram), emb_dim=300, hidden_size=256, out_size=128, activation='Tanh', nlayers=1, reduce='mean', dropout=0.0, batch_norm=False)\n",
    "decoder = DecoderMLP(input_size=128, output_size=len(train_id2token_unigram), hidden_size=256)\n",
    "model = seq2seq(bag_of_ngrams, decoder)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in _tqdm(enumerate(eval_loader)):\n",
    "        model.eval_step(data, labels)\n",
    "    for i, (data, labels) in _tqdm(enumerate(train_loader)):\n",
    "        model.train_step(data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1d5beb8f3945cdaebba7f1beff6fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1549633347309/work/aten/src/THC/THCGeneral.cpp:405",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-f443d4d3449c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ammi/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-230-3de50e31394a>\u001b[0m in \u001b[0;36mbatchify\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mbatch_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPAD_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtarget_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1549633347309/work/aten/src/THC/THCGeneral.cpp:405"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs=100\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in _tqdm(enumerate(train_loader)): \n",
    "        data.cuda()\n",
    "        labels.cuda()\n",
    "        model.cuda()\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        \n",
    "        loss = criterion(outputs, labels.view(-1))\n",
    "        loss.backward()\n",
    "#         print(loss.item())\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 and epoch > 0:\n",
    "        print(\"Epoch {}: \".format(epoch), loss.item())\n",
    "#         val_acc = test_model(loader=valid_loader, model=model)\n",
    "#         print('Epoch: [{}/{}], Step: [{}/{}], Train loss: {}, Validation Acc: {}'.format( \n",
    "#                            epoch+1, num_epochs, i+1, len(train_loader), loss.item(), val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleSeq2seqAgent(TorchAgent):\n",
    "    \"\"\"Agent which takes an input sequence and produces an output sequence.\n",
    "    This model is based on Sean Robertson's `seq2seq tutorial\n",
    "    <http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html>`_.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def add_cmdline_args(cls, argparser):\n",
    "        \"\"\"Add command-line arguments specifically for this agent.\"\"\"\n",
    "        super(ExampleSeq2seqAgent, cls).add_cmdline_args(argparser)\n",
    "        agent = argparser.add_argument_group('Seq2Seq Arguments')\n",
    "        agent.add_argument('-hs', '--hiddensize', type=int, default=128,\n",
    "                           help='size of the hidden layers')\n",
    "        agent.add_argument('-esz', '--embeddingsize', type=int, default=128,\n",
    "                           help='size of the token embeddings')\n",
    "        agent.add_argument('-nl', '--numlayers', type=int, default=2,\n",
    "                           help='number of hidden layers')\n",
    "        agent.add_argument('-lr', '--learningrate', type=float, default=1,\n",
    "                           help='learning rate')\n",
    "        agent.add_argument('-dr', '--dropout', type=float, default=0.1,\n",
    "                           help='dropout rate')\n",
    "        agent.add_argument('--gpu', type=int, default=-1,\n",
    "                           help='which GPU device to use')\n",
    "        agent.add_argument('-rf', '--report-freq', type=float, default=0.001,\n",
    "                           help='Report frequency of prediction during eval.')\n",
    "        agent.add_argument('-rf', '--report-freq', type=float, default=0.001,\n",
    "                           help='Report frequency of prediction during eval.')\n",
    "        ExampleSeq2seqAgent.dictionary_class().add_cmdline_args(argparser)\n",
    "        return agent\n",
    "\n",
    "    def __init__(self, opt, shared=None):\n",
    "        \"\"\"Initialize example seq2seq agent.\n",
    "        :param opt: options dict generated by parlai.core.params:ParlaiParser\n",
    "        :param shared: optional shared dict with preinitialized model params\n",
    "        \"\"\"\n",
    "        super().__init__(opt, shared)\n",
    "\n",
    "        self.id = 'Seq2Seq'\n",
    "\n",
    "        if not shared:\n",
    "            # set up model from scratch\n",
    "            hsz = opt['hiddensize']\n",
    "            nl = opt['numlayers']\n",
    "            act = opt['activation']\n",
    "            \n",
    "            self.bag_of_words = BagOfNGrams(len(train_id2token_unigram), emb_dim=30, hidden_size=hsz, activation=act, nlayers=1, reduce='mean', dropout=0.0, batch_norm=False)\n",
    "\n",
    "            # encoder captures the input text\n",
    "            self.encoder = EncoderRNN(len(self.dict), hsz, nl)\n",
    "            # decoder produces our output states\n",
    "            self.decoder = DecoderRNN(len(self.dict), hsz, nl)\n",
    "\n",
    "            if self.use_cuda:  # set in parent class\n",
    "                self.encoder.cuda()\n",
    "                self.decoder.cuda()\n",
    "\n",
    "            if opt.get('numthreads', 1) > 1:\n",
    "                self.encoder.share_memory()\n",
    "                self.decoder.share_memory()\n",
    "        elif 'encoder' in shared:\n",
    "            # copy initialized data from shared table\n",
    "            self.encoder = shared['encoder']\n",
    "            self.decoder = shared['decoder']\n",
    "\n",
    "        # set up the criterion\n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "        # set up optims for each module\n",
    "        lr = opt['learningrate']\n",
    "        self.optims = {\n",
    "            'encoder': optim.SGD(self.encoder.parameters(), lr=lr),\n",
    "            'decoder': optim.SGD(self.decoder.parameters(), lr=lr),\n",
    "        }\n",
    "\n",
    "        self.longest_label = 1\n",
    "        self.hiddensize = opt['hiddensize']\n",
    "        self.numlayers = opt['numlayers']\n",
    "        self.START = torch.LongTensor([self.START_IDX])\n",
    "        if self.use_cuda:\n",
    "            self.START = self.START.cuda()\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Zero out optimizer.\"\"\"\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def update_params(self):\n",
    "        \"\"\"Do one optimization step.\"\"\"\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "\n",
    "    def share(self):\n",
    "        \"\"\"Share internal states.\"\"\"\n",
    "        shared = super().share()\n",
    "        shared['encoder'] = self.encoder\n",
    "        shared['decoder'] = self.decoder\n",
    "        return shared\n",
    "\n",
    "    def v2t(self, vector):\n",
    "        \"\"\"Convert vector to text.\n",
    "        :param vector: tensor of token indices.\n",
    "            1-d tensors will return a string, 2-d will return a list of strings\n",
    "        \"\"\"\n",
    "        if vector.dim() == 1:\n",
    "            output_tokens = []\n",
    "            # Remove the final END_TOKEN that is appended to predictions\n",
    "            for token in vector:\n",
    "                if token == self.END_IDX:\n",
    "                    break\n",
    "                else:\n",
    "                    output_tokens.append(token)\n",
    "            return self.dict.vec2txt(output_tokens)\n",
    "        elif vector.dim() == 2:\n",
    "            return [self.v2t(vector[i]) for i in range(vector.size(0))]\n",
    "        raise RuntimeError('Improper input to v2t with dimensions {}'.format(\n",
    "            vector.size()))\n",
    "\n",
    "    def vectorize(self, *args, **kwargs):\n",
    "        \"\"\"Call vectorize without adding start tokens to labels.\"\"\"\n",
    "        kwargs['add_start'] = False\n",
    "        return super().vectorize(*args, **kwargs)\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Train model to produce ys given xs.\n",
    "        :param batch: parlai.core.torch_agent.Batch, contains tensorized\n",
    "                      version of observations.\n",
    "        Return estimated responses, with teacher forcing on the input sequence\n",
    "        (list of strings of length batchsize).\n",
    "        \"\"\"\n",
    "        xs, ys = batch.text_vec, batch.label_vec\n",
    "        if xs is None:\n",
    "            return\n",
    "        bsz = xs.size(0)\n",
    "        starts = self.START.expand(bsz, 1)  # expand to batch size\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        target_length = ys.size(1)\n",
    "        # save largest seen label for later\n",
    "        self.longest_label = max(target_length, self.longest_label)\n",
    "\n",
    "        _encoder_output, encoder_hidden = self.encoder(xs)\n",
    "\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        y_in = ys.narrow(1, 0, ys.size(1) - 1)\n",
    "        decoder_input = torch.cat([starts, y_in], 1)\n",
    "        decoder_output, decoder_hidden = self.decoder(decoder_input,\n",
    "                                                      encoder_hidden)\n",
    "\n",
    "        scores = decoder_output.view(-1, decoder_output.size(-1))\n",
    "        loss = self.criterion(scores, ys.view(-1))\n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "\n",
    "        _max_score, predictions = decoder_output.max(2)\n",
    "        return Output(self.v2t(predictions))\n",
    "\n",
    "    def eval_step(self, batch):\n",
    "        \"\"\"Generate a response to the input tokens.\n",
    "        :param batch: parlai.core.torch_agent.Batch, contains tensorized\n",
    "                      version of observations.\n",
    "        Return predicted responses (list of strings of length batchsize).\n",
    "        \"\"\"\n",
    "        xs = batch.text_vec\n",
    "        if xs is None:\n",
    "            return\n",
    "        bsz = xs.size(0)\n",
    "        starts = self.START.expand(bsz, 1)  # expand to batch size\n",
    "        # just predict\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "        _encoder_output, encoder_hidden = self.encoder(xs)\n",
    "\n",
    "        predictions = []\n",
    "        done = [False for _ in range(bsz)]\n",
    "        total_done = 0\n",
    "        decoder_input = starts\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for _ in range(self.longest_label):\n",
    "            # generate at most longest_label tokens\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input,\n",
    "                                                          decoder_hidden)\n",
    "            _max_score, preds = decoder_output.max(2)\n",
    "            predictions.append(preds)\n",
    "            decoder_input = preds  # set input to next step\n",
    "\n",
    "            # check if we've produced the end token\n",
    "            for b in range(bsz):\n",
    "                if not done[b]:\n",
    "                    # only add more tokens for examples that aren't done\n",
    "                    if preds[b].item() == self.END_IDX:\n",
    "                        # if we produced END, we're done\n",
    "                        done[b] = True\n",
    "                        total_done += 1\n",
    "            if total_done == bsz:\n",
    "                # no need to generate any more\n",
    "                break\n",
    "        predictions = torch.cat(predictions, 1)\n",
    "        return Output(self.v2t(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_epochs = 20 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99, nesterov=True)\n",
    "#optimizer = torch.optim.Adagrad(params=model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, labels in loader:\n",
    "        outputs = torch.sigmoid(model(data))\n",
    "        predicted = (outputs > 0.5).long()\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxfi7ruGHZu3"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744c1afe9d1f4bfbbc3952fb722f6402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   8,   63,    1,  ...,    0,    0,    0],\n",
      "        [  62, 1752, 1753,  ...,    0,    0,    0],\n",
      "        [  98, 3294, 3295,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1055, 1056, 1057,  ...,    0,    0,    0],\n",
      "        [   8,   63,   47,  ...,    0,    0,    0],\n",
      "        [1434, 1435, 1436,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48490445812e485282a03127f18e3673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[  20,    1,    1,  ...,    0,    0,    0],\n",
      "        [   8,  373,  156,  ...,    0,    0,    0],\n",
      "        [  98, 2926, 2927,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   8,  373, 9000,  ...,    0,    0,    0],\n",
      "        [   8,    1,    1,  ...,    0,    0,    0],\n",
      "        [   8,  112,   11,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [2/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c17aa72e724814a0cb4a53c93cc790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[ 362,  363, 2301,  ...,    0,    0,    0],\n",
      "        [  62, 2323, 2324,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   8,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        [   8, 6962, 6963,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [3/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c2aee72ce84ee892823df05f50e7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   8,  112,   11,  ...,    0,    0,    0],\n",
      "        [   8,    1,    1,  ...,    0,    0,    0],\n",
      "        [  20,  253,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   8, 6962, 6963,  ...,    0,    0,    0],\n",
      "        [ 344, 5627, 5628,  ...,    0,    0,    0],\n",
      "        [ 330,  331,  942,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [4/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451d26313c8944fc9ac7585ada31362e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   1,    1,    1,  ...,    0,    0,    0],\n",
      "        [   8,  112,   11,  ...,    0,    0,    0],\n",
      "        [6477, 6478, 6479,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  62,  255,    1,  ...,    0,    0,    0],\n",
      "        [ 785,  786,  787,  ...,    0,    0,    0],\n",
      "        [   8,   63,   47,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [5/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3edc02e9d6d4611a8f7c75304e680f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   8,  112,   11,  ...,    0,    0,    0],\n",
      "        [   8,  613,  614,  ...,    0,    0,    0],\n",
      "        [  20,  314, 1463,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   8,   63,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        [1434, 1435, 1436,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [6/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f671435422948c0b5881b30b3efd496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[  20,  253,    1,  ...,    0,    0,    0],\n",
      "        [2116, 2117, 2118,  ...,    0,    0,    0],\n",
      "        [  98, 3294, 3295,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   8,  112,   11,  ...,    0,    0,    0],\n",
      "        [  98, 2209, 2210,  ...,    0,    0,    0],\n",
      "        [  62,  255,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [7/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6067b42b6134419db8dbd4b2ad8170fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[  98, 2926, 2927,  ...,    0,    0,    0],\n",
      "        [6477, 6478, 6479,  ...,    0,    0,    0],\n",
      "        [  62, 2323, 2324,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   8, 1295, 1296,  ...,    0,    0,    0],\n",
      "        [   8,  373, 9000,  ...,    0,    0,    0],\n",
      "        [1434, 1435, 1436,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [8/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c70aaa72b5e4ded99ab01025010c447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[1055, 1056, 1057,  ...,    0,    0,    0],\n",
      "        [  20,  253,    1,  ...,    0,    0,    0],\n",
      "        [  20, 2020, 2021,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  98, 4207,   14,  ...,    0,    0,    0],\n",
      "        [1434, 1435, 1436,  ...,    0,    0,    0],\n",
      "        [  20,  314, 1463,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [9/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c58dba9bdb446e8f423aec6dd3f6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[1055, 1056, 1057,  ...,    0,    0,    0],\n",
      "        [1434, 1435, 1436,  ...,    0,    0,    0],\n",
      "        [   8,  613,  614,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1590, 1591, 1592,  ...,    0,    0,    0],\n",
      "        [  20,    1,    1,  ...,    0,    0,    0],\n",
      "        [   8,  752, 7714,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [10/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3691ec1844c94a068d7fb3c5cf4b0b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   8, 2354, 2355,  ...,    0,    0,    0],\n",
      "        [  20,  314,  298,  ...,    0,    0,    0],\n",
      "        [  20,  253,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 362,  363,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 362,  363, 2301,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [11/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a99a72500a4460aab7ddea95384cac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   8,  632, 9622,  ...,    0,    0,    0],\n",
      "        [   8,    1,    1,  ...,    0,    0,    0],\n",
      "        [6477, 6478, 6479,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1880, 1881,  312,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 330,  331,  942,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [12/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108dd94efb734d90bfa3581880225fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[  20,  314,  298,  ...,    0,    0,    0],\n",
      "        [  98, 2209, 2210,  ...,    0,    0,    0],\n",
      "        [   1,    1,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 362,  363,    1,  ...,    0,    0,    0],\n",
      "        [   8,  373,  156,  ...,    0,    0,    0],\n",
      "        [1055, 1056, 1057,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [13/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dedc1695d0d4fcc8670ee63c20c8dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   8, 1295, 1296,  ...,    0,    0,    0],\n",
      "        [ 296,  297,  135,  ...,    0,    0,    0],\n",
      "        [1880, 1881,  312,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1723, 1724, 1725,  ...,    0,    0,    0],\n",
      "        [1590, 1591, 1592,  ...,    0,    0,    0],\n",
      "        [  20,  253,    1,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [14/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0057b1fac34a349e9fa2ff569b41d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   8,  613,  614,  ...,    0,    0,    0],\n",
      "        [6993, 6994, 6995,  ...,    0,    0,    0],\n",
      "        [   8,  112,   11,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [3526, 3527, 3528,  ...,    0,    0,    0],\n",
      "        [1974, 1975, 1976,  ...,    0,    0,    0],\n",
      "        [1590, 1591, 1592,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [15/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2fd040eb3948b2aa5f75d25b0cf29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[ 296,  297,  135,  ...,    0,    0,    0],\n",
      "        [  62, 1752, 1753,  ...,    0,    0,    0],\n",
      "        [ 271, 1118, 1119,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  20,  253,    1,  ...,    0,    0,    0],\n",
      "        [3814, 3815, 3816,  ...,    0,    0,    0],\n",
      "        [   8, 6962, 6963,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [16/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa168cf912140ddac9f67cbcf82d85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[  20, 2020, 2021,  ...,    0,    0,    0],\n",
      "        [   8,   63,   47,  ...,    0,    0,    0],\n",
      "        [   8, 1295, 1296,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  62, 2323, 2324,  ...,    0,    0,    0],\n",
      "        [   8,  752,  414,  ...,    0,    0,    0],\n",
      "        [5370, 5371, 5372,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [17/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e405bddaaa3492e9615679d4ec68f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[2552, 2553, 2554,  ...,    0,    0,    0],\n",
      "        [  62,    1,  930,  ...,    0,    0,    0],\n",
      "        [   8,   63,   47,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 330,  331, 1691,  ...,    0,    0,    0],\n",
      "        [   8,  112,   11,  ...,    0,    0,    0],\n",
      "        [4640, 4641, 4642,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [18/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d2e55e99e34e7fa0cf09da73cf9712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[   62,   255,     1,  ...,     0,     0,     0],\n",
      "        [    8,   632,  9622,  ...,     0,     0,     0],\n",
      "        [ 1723,  1724,  1725,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  785,   786,    26,  ..., 11617, 11618,    10],\n",
      "        [ 1202,  1203,  1204,  ...,     0,     0,     0],\n",
      "        [    8,  6962,  6963,  ...,     0,     0,     0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [19/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36e93107f6c48c0babab986442e2aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  tensor([[ 344, 1904, 1905,  ...,    0,    0,    0],\n",
      "        [   8,  112,   11,  ...,    0,    0,    0],\n",
      "        [1055, 1056, 1057,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   8,  613,  614,  ...,    0,    0,    0],\n",
      "        [  20,  314, 1463,  ...,    0,    0,    0],\n",
      "        [2075, 2076, 2077,  ...,    0,    0,    0]], device='cuda:0')\n",
      "labels  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "0.0\n",
      "\n",
      "Epoch: [20/20], Step: [1/1], Train loss: 0.0, Validation Acc: 100.0\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "num_epochs=20\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in _tqdm(enumerate(train_loader)): \n",
    "        if i < 5:\n",
    "            print(\"data \", data)\n",
    "            print(\"labels \", labels)\n",
    "        data.cuda()\n",
    "        labels.cuda()\n",
    "        model.cuda()\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs.view(-1), labels.float().view(-1))\n",
    "        loss.backward()\n",
    "        print(loss.item())\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    if epoch % 1 == 0 and epoch > 0:\n",
    "        val_acc = test_model(loader=valid_loader, model=model)\n",
    "        print('Epoch: [{}/{}], Step: [{}/{}], Train loss: {}, Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), loss.item(), val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-fbe2eca6a9020c1748d6b1fbf4e31200"
       },
       "datasets": {
        "data-fbe2eca6a9020c1748d6b1fbf4e31200": [
         {
          "loss": 0.7269389629364014,
          "step": 0
         },
         {
          "loss": 1.4901160305669237e-09,
          "step": 1
         },
         {
          "loss": 0,
          "step": 2
         },
         {
          "loss": 0,
          "step": 3
         },
         {
          "loss": 0,
          "step": 4
         },
         {
          "loss": 0,
          "step": 5
         },
         {
          "loss": 0,
          "step": 6
         },
         {
          "loss": 0,
          "step": 7
         },
         {
          "loss": 0,
          "step": 8
         },
         {
          "loss": 0,
          "step": 9
         },
         {
          "loss": 0,
          "step": 10
         },
         {
          "loss": 0,
          "step": 11
         },
         {
          "loss": 0,
          "step": 12
         },
         {
          "loss": 0,
          "step": 13
         },
         {
          "loss": 0,
          "step": 14
         },
         {
          "loss": 0,
          "step": 15
         },
         {
          "loss": 0,
          "step": 16
         },
         {
          "loss": 0,
          "step": 17
         },
         {
          "loss": 0,
          "step": 18
         },
         {
          "loss": 0,
          "step": 19
         }
        ]
       },
       "encoding": {
        "x": {
         "field": "step",
         "scale": {},
         "type": "quantitative"
        },
        "y": {
         "field": "loss",
         "scale": {
          "type": "log"
         },
         "type": "quantitative"
        }
       },
       "height": 400,
       "mark": "line",
       "width": 800
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install altair\n",
    "import altair as alt\n",
    "import pandas\n",
    "\n",
    "batch_loss = []\n",
    "for i,l in enumerate(train_losses):\n",
    "    batch_loss.append((i,l))\n",
    "\n",
    "df = pandas.DataFrame(batch_loss, columns=['step', 'loss'])\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('step', scale=alt.Scale()),\n",
    "    alt.Y('loss', scale=alt.Scale(type='log'))).properties(\n",
    "        width=800,\n",
    "        height=400\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lhi0Ww8JKEkk"
   },
   "source": [
    "## Analysis & Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare N-gram LM to Neural LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KenLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/wiki.en.vec:  19%|█▉        | 1.25G/6.60G [11:49<50:35, 1.76MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url)\u001b[0m\n\u001b[1;32m    260\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3abfa44c94ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.vector_cache'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url)\u001b[0m\n\u001b[1;32m    261\u001b[0m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting vectors into {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = vocab.FastText(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(dataset, max_size=30000, vectors=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a batch iterator\n",
    "train_loader = data.BucketIterator(dataset=dataset, batch_size=4, sort_key=lambda x: len(x.reviewText), device=torch.device('cpu'), sort_within_batch=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vec2txt(vec):\n",
    "    return [text_field.vocab.itos[t] for t in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch.reviewText[0][0])\n",
    "print(_vec2txt(batch.reviewText[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jzyCRhtBNit"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFDnznsFJRMI"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ngram-lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
