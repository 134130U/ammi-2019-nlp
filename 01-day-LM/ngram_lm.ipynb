{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "### Goal: compute a probabilty distribution over all possible sentences:\n",
    "\n",
    "\n",
    "### $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
    "\n",
    "### This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
    "\n",
    "### $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
    "\n",
    "### If we have N sentences, each of them with T words / tokens, then we want to max:\n",
    "\n",
    "### $$log p(W) = \\sum_{n = 1}^N \\sum_{i=1}^{T} log p(w_i | w_{<i})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model\n",
    "\n",
    "### Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
    "\n",
    "### Given a sequence of words $w$, we want to compute\n",
    "\n",
    "###  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
    "\n",
    "### Where $w_i$ is the i-th word of the sequence.\n",
    "\n",
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
    "\n",
    "### Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "#: implement the neural LM with concat instead of summation -- so that you have a fixed input etc.\n",
    "# make a separate\n",
    "# create some slides with pictures maybe explaining the model visualizations -- line by line\n",
    "# get google cloud working\n",
    "# make it work on gpu\n",
    "# show them kenlm and how to use to do different stuff with it\n",
    "# use the same sentences to generation and testing etc.\n",
    "# explain perplexity\n",
    "# ngram, ff, rnn, rnn+attention\n",
    "# do sentence generation\n",
    "# do long sentences\n",
    "# compare different n-grams -- 2,3,more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('utils/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: should we install as needed and import as needed or all at once?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCVSciOCAMZb"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ngram_utils as ngram_utils\n",
    "import utils.global_variables as gl\n",
    "import torch\n",
    "import random\n",
    "from utils.ngram_utils import NgramLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H20pktPiA63a",
    "outputId": "fb38d897-e889-4451-df77-9ca98eb266a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fab2e21d510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from .txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_reviews_clothing_valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_data), len(train_data), \\\n",
    "# type(train_data[0]), len(train_data[0]), \\\n",
    "# type(train_data[0][0]), len(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " 't')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: for now only work with small subset of the data -- switch to all data later\n",
    "train_data = train_data[:100]\n",
    "valid_data = valid_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, str, str)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), type(train_data[0]), type(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 563.56it/s]\n",
      "10it [00:00, 1171.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
    "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of All Tokens\n",
    "# len(all_tokens_train), all_tokens_train[0], \\\n",
    "# len(train_data_tokenized), train_data_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_lm = NgramLM(train_data_tokenized, all_tokens_train, n=3)\n",
    "valid_ngram_lm = NgramLM(valid_data_tokenized, all_tokens_valid, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ngram_lm.n, train_ngram_lm.frac_vocab, train_ngram_lm.num_all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram_lm.vocabulary[:3], valid_ngram_lm.raw_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram_lm.vocab_ngram[:3], valid_ngram_lm.count_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram_lm.vocab_unigram[:3], valid_ngram_lm.count_unigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram_lm.vocab_bigram[:3], valid_ngram_lm.count_bigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram_lm.vocab_prev_ngram[:3], valid_ngram_lm.count_prev_ngram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ngram_lm.id2token[:3], valid_ngram_lm.token2id['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 2214 words\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
    "vocabulary = train_ngram_lm.vocabulary\n",
    "print('Word vocabulary size: {} words'.format(len(vocabulary)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS ANALYSIS (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tokens in the Corpus Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Tokens  16129\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All Tokens \", train_ngram_lm.num_all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All UNIQUE Tokens  2214\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All UNIQUE Tokens \", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences in the Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Sentences \", len(train_ngram_lm.raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = train_ngram_lm.padded_data\n",
    "train_ngram = train_ngram_lm.ngram_data\n",
    "vocab_ngram = train_ngram_lm.vocab_ngram\n",
    "count_ngram = train_ngram_lm.count_ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for finding all N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_trie['./<eos>/<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_ngram = train_ngram_lm.trie_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ngram_trie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Getting N-gram counts for already tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_padded, train_ngram, vocab_ngram, count_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigrams, Bigrams, Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_unigram = train_ngram_lm.vocab_unigram\n",
    "vocab_bigram = train_ngram_lm.vocab_bigram\n",
    "vocab_trigram = train_ngram_lm.vocab_trigram\n",
    "\n",
    "count_unigram = train_ngram_lm.count_unigram\n",
    "count_bigram = train_ngram_lm.count_bigram\n",
    "count_trigram = train_ngram_lm.count_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_bigram[:3], count_bigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_unigram[:3], count_unigram[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_unigram = train_ngram_lm.trie_unigram\n",
    "trie_bigram = train_ngram_lm.trie_bigram\n",
    "trie_trigram = train_ngram_lm.trie_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram_trie, bigram_trie, trigram_trie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Getting N-gram Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_ngram = train_ngram_lm.id2token\n",
    "token2id_ngram = train_ngram_lm.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2token_ngram[:10], \\\n",
    "# token2id_ngram['<unk>'], token2id_ngram['<eos>'], token2id_ngram[('rosetta', 'stone', 'is')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 12427 ; token ('gave', 'him', 'this')\n",
      "Token ('gave', 'him', 'this'); token id 12427\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
    "random_token = id2token_ngram[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_ngram[:10], count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'this'))\n",
    "c = train_ngram_lm.get_ngram_count(('.', '<eos>', '<eos>'))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing the probability of a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w|w_{−n}, ..., w_{−2}, w_{−1}) \\approx \\frac{c(w_{−n}, ..., w_{−2}, w_{−1}, w)}{\\sum_{w \\in V} c(w_{−n}, ..., w_{−2}, w_{−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities\n",
    "\n",
    "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob(('rosetta', 'stone', 'is'))\n",
    "p = train_ngram_lm.get_ngram_prob(('i', 'am', 'very'))\n",
    "p\n",
    "\n",
    "# p = get_ngram_prob(('i', 'am', 'rosetta'), vocab_ngram, count_ngram)\n",
    "# p\n",
    "\n",
    "# p = get_ngram_prob(('it', \"'\", 's'), vocab_ngram, count_ngram)\n",
    "# p\n",
    "\n",
    "# p = get_ngram_prob(('i', \"like\", 'this'), vocab_ngram, count_ngram)\n",
    "# p, 1/(2+1+1+1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob(('am', 'rosetta', 'stone'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00045167118337850043"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('am', 'rosetta', 'stone'), delta=0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031616982836495033"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'am', 'very'), delta=0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00045167118337850043"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('am', 'rosetta', 'stone'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018066847335140017"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'am', 'very'))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: add formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('am', 'rosetta', 'stone'), alpha=0.5)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'am', 'very'), alpha=0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing: Linear Interpolation with Absolute Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
    "\n",
    "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
    "\n",
    "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
    "\n",
    "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
    "\n",
    "\n",
    "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
    "\n",
    "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
    "\n",
    "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
    "\n",
    "### V is the number of words in the vocabulary\n",
    "\n",
    "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206.01654553995797"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = \"m\"\n",
    "x = \"'\"\n",
    "\n",
    "z = train_ngram_lm.get_p_bi(y, x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check that the probabilities sum up to one\n",
    "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add this check or leave as homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM\n",
    "###  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood of a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
    "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
    "\n",
    "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"'\", 'm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prob distr for the word following prev_tokens (i.e. tutu) \n",
    "# over all the words in the vocabulary \n",
    "\n",
    "# prev_tokens = train_data_tokenized[0][4] #[0]\n",
    "prev_tokens = vocab_ngram[3][1:] #[0]   # need frmo 1 on so that this is a correct prev token\n",
    "print(prev_tokens)\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(prev_tokens)\n",
    "sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rosetta', 'stone')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prob distr for the word following prev_tokens (i.e. tutu) \n",
    "# over all the words in the vocabulary \n",
    "\n",
    "# prev_tokens = train_data_tokenized[0][4] #[0]\n",
    "prev_tokens = ('rosetta', 'stone') #[0]   # need frmo 1 on so that this is a correct prev token\n",
    "print(prev_tokens)\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(prev_tokens)\n",
    "sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across\n",
      "across bandana\n",
      "across bandana pouch\n",
      "across bandana pouch thought\n",
      "across bandana pouch thought enunciate\n",
      "across bandana pouch thought enunciate same\n",
      "across bandana pouch thought enunciate same leaves\n",
      "across bandana pouch thought enunciate same leaves than\n",
      "across bandana pouch thought enunciate same leaves than disneyland\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened picture\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened picture apart\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened picture apart upset\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened picture apart upset imac\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened picture apart upset imac hardly\n",
      "across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened picture apart upset imac hardly believe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'across bandana pouch thought enunciate same leaves than disneyland smaller fingers will pc opened picture apart upset imac hardly believe'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tokens = 5\n",
    "# generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "# generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# show rank for each word in a sentence\n",
    "# explain perplexity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Likelihood\n",
    "### $LL = \\sum_{k=1}^{K} \\sum_{n=1}^{N_k + 1} log p_{bi}(w_{k,n} | w_{k,n-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $PP = exp(-\\frac{LL}{\\sum_k(N_k + 1)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_valid = train_ngram_lm.get_perplexity(valid_data_tokenized)\n",
    "ppl_train = train_ngram_lm.get_perplexity(train_data_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266669.1406237607, 78.64967546583712)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_valid, ppl_train\n",
    "# TODO check whether this makes sense -- maybe it seems too good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at some examples and see if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ngram-lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
